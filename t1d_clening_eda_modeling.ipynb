{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Type 1 Diabetes Classification System Using Gene Expression Biomarkers**\n",
    "\n",
    "This project develops a specialized machine learning pipeline for the accurate classification of Type 1 Diabetes (T1D) using gene expression biomarkers. Leveraging RNA-seq datasets, the system incorporates advanced preprocessing, feature selection, and model optimization techniques to identify key genetic signatures associated with T1D. Ensemble learning strategies are applied to improve robustness and predictive accuracy, enabling the model to distinguish T1D cases from healthy controls with high reliability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Import Libraries**\n",
    "\n",
    "Before beginning any data analysis or modeling, it is essential to import all required libraries. This project leverages a wide range of tools for data manipulation, visualization, machine learning, and hyperparameter optimization. Libraries such as pandas and numpy handle data structures and numerical operations, while matplotlib and seaborn enable effective data visualization. For machine learning, classifiers like RandomForest, XGBoost, and SVM are imported, along with preprocessing tools like StandardScaler and KNNImputer. Feature selection methods including LassoCV and statistical tests (ttest_ind) are used to identify biologically relevant genes. Additionally, Optuna supports efficient hyperparameter tuning, and imblearn helps manage potential class imbalances. The tqdm library provides progress bars for long-running loops, improving user experience during model training and cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import joblib\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ttest_ind\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "from sklearn.metrics import make_scorer, precision_score, recall_score, f1_score\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Load and Merge Datasets**\n",
    "\n",
    "The foundation of this study lies in integrating gene expression data from two publicly available RNA-seq datasets: GSE151610 and GSE169221, sourced from the Gene Expression Omnibus (GEO). These datasets provide gene-level count matrices and corresponding metadata for individuals with Type 1 Diabetes and healthy controls. By combining data from multiple studies, we increase statistical power and improve the generalizability of our findings. The count matrices contain gene expression levels across samples, while the metadata files include sample conditions and experimental details. Loading both datasets simultaneously allows for consistent preprocessing and harmonization before downstream analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and merge T1D datasets\n",
    "data_paths = {\n",
    "\n",
    "    \"t1d_counts\": [\"Data/GSE151610_GeneLevel_Raw_data.csv\", \"Data/GSE169221_GeneLevel_Raw_data.csv\"],\n",
    "    \"t1d_metadata\": [\"Data/GSE151610_filtered_metadata.csv\", \"Data/GSE169221_filtered_metadata.csv\"],\n",
    "}\n",
    "\n",
    "t1d_counts_0 = pd.read_csv(data_paths[\"t1d_counts\"][0], index_col=0)\n",
    "t1d_counts_1 = pd.read_csv(data_paths[\"t1d_counts\"][1], index_col=0)\n",
    "t1d_metadata_0 = pd.read_csv(data_paths[\"t1d_metadata\"][0])\n",
    "t1d_metadata_1 = pd.read_csv(data_paths[\"t1d_metadata\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>characteristics</th>\n",
       "      <th>emp2 expression</th>\n",
       "      <th>replicate</th>\n",
       "      <th>emp2.expression.ch1</th>\n",
       "      <th>replicate.ch1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GSM4586567</td>\n",
       "      <td>hypoxia_KD_1</td>\n",
       "      <td>knock down</td>\n",
       "      <td>1</td>\n",
       "      <td>knock down</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GSM4586568</td>\n",
       "      <td>hypoxia_OE_1</td>\n",
       "      <td>overexpressing</td>\n",
       "      <td>1</td>\n",
       "      <td>overexpressing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GSM4586569</td>\n",
       "      <td>hypoxia_VC_1</td>\n",
       "      <td>vector control</td>\n",
       "      <td>1</td>\n",
       "      <td>vector control</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GSM4586570</td>\n",
       "      <td>hypoxia_WT_1</td>\n",
       "      <td>wild type</td>\n",
       "      <td>1</td>\n",
       "      <td>wild type</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GSM4586571</td>\n",
       "      <td>normoxia_KD_1</td>\n",
       "      <td>knock down</td>\n",
       "      <td>1</td>\n",
       "      <td>knock down</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 characteristics emp2 expression  replicate emp2.expression.ch1  \\\n",
       "0  GSM4586567    hypoxia_KD_1      knock down          1          knock down   \n",
       "1  GSM4586568    hypoxia_OE_1  overexpressing          1      overexpressing   \n",
       "2  GSM4586569    hypoxia_VC_1  vector control          1      vector control   \n",
       "3  GSM4586570    hypoxia_WT_1       wild type          1           wild type   \n",
       "4  GSM4586571   normoxia_KD_1      knock down          1          knock down   \n",
       "\n",
       "   replicate.ch1  \n",
       "0              1  \n",
       "1              1  \n",
       "2              1  \n",
       "3              1  \n",
       "4              1  "
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1d_metadata_0.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Preprocess Metadata Labels**\n",
    "\n",
    "The metadata from the two datasets uses different terminologies to describe case and control groups. In GSE151610, “hypoxia” refers to T1D cases and “normoxia” to controls, while in GSE169221, “CYTO” denotes cases and “CONT” controls. To ensure consistency, we extract these condition labels using regular expressions and standardize them into a uniform format: 'case' for T1D patients and 'control' for healthy individuals. This harmonization step is crucial for accurate labeling during model training and prevents misclassification due to inconsistent annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>characteristics</th>\n",
       "      <th>emp2 expression</th>\n",
       "      <th>replicate</th>\n",
       "      <th>emp2.expression.ch1</th>\n",
       "      <th>replicate.ch1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GSM4586567</td>\n",
       "      <td>case</td>\n",
       "      <td>knock down</td>\n",
       "      <td>1</td>\n",
       "      <td>knock down</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GSM4586568</td>\n",
       "      <td>case</td>\n",
       "      <td>overexpressing</td>\n",
       "      <td>1</td>\n",
       "      <td>overexpressing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GSM4586569</td>\n",
       "      <td>case</td>\n",
       "      <td>vector control</td>\n",
       "      <td>1</td>\n",
       "      <td>vector control</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GSM4586570</td>\n",
       "      <td>case</td>\n",
       "      <td>wild type</td>\n",
       "      <td>1</td>\n",
       "      <td>wild type</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GSM4586571</td>\n",
       "      <td>control</td>\n",
       "      <td>knock down</td>\n",
       "      <td>1</td>\n",
       "      <td>knock down</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 characteristics emp2 expression  replicate emp2.expression.ch1  \\\n",
       "0  GSM4586567            case      knock down          1          knock down   \n",
       "1  GSM4586568            case  overexpressing          1      overexpressing   \n",
       "2  GSM4586569            case  vector control          1      vector control   \n",
       "3  GSM4586570            case       wild type          1           wild type   \n",
       "4  GSM4586571         control      knock down          1          knock down   \n",
       "\n",
       "   replicate.ch1  \n",
       "0              1  \n",
       "1              1  \n",
       "2              1  \n",
       "3              1  \n",
       "4              1  "
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract 'hypoxia' or 'normoxia' from characteristics and replace with 'case' or 'control'\n",
    "t1d_metadata_0['characteristics'] = t1d_metadata_0['characteristics'].str.extract(r'^(hypoxia|normoxia)')[0]\n",
    "t1d_metadata_0['characteristics'] = t1d_metadata_0['characteristics'].replace({'hypoxia': 'case', 'normoxia': 'control'})\n",
    "t1d_metadata_0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>characteristics</th>\n",
       "      <th>treatment</th>\n",
       "      <th>treatment.ch1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GSM5184058</td>\n",
       "      <td>CONT_1</td>\n",
       "      <td>Untreated control</td>\n",
       "      <td>Untreated control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GSM5184059</td>\n",
       "      <td>CONT_2</td>\n",
       "      <td>Untreated control</td>\n",
       "      <td>Untreated control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GSM5184060</td>\n",
       "      <td>CONT_3</td>\n",
       "      <td>Untreated control</td>\n",
       "      <td>Untreated control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GSM5184061</td>\n",
       "      <td>CONT_4</td>\n",
       "      <td>Untreated control</td>\n",
       "      <td>Untreated control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GSM5184062</td>\n",
       "      <td>CONT_5</td>\n",
       "      <td>Untreated control</td>\n",
       "      <td>Untreated control</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 characteristics          treatment      treatment.ch1\n",
       "0  GSM5184058          CONT_1  Untreated control  Untreated control\n",
       "1  GSM5184059          CONT_2  Untreated control  Untreated control\n",
       "2  GSM5184060          CONT_3  Untreated control  Untreated control\n",
       "3  GSM5184061          CONT_4  Untreated control  Untreated control\n",
       "4  GSM5184062          CONT_5  Untreated control  Untreated control"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1d_metadata_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>characteristics</th>\n",
       "      <th>treatment</th>\n",
       "      <th>treatment.ch1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GSM5184058</td>\n",
       "      <td>control</td>\n",
       "      <td>Untreated control</td>\n",
       "      <td>Untreated control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GSM5184059</td>\n",
       "      <td>control</td>\n",
       "      <td>Untreated control</td>\n",
       "      <td>Untreated control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GSM5184060</td>\n",
       "      <td>control</td>\n",
       "      <td>Untreated control</td>\n",
       "      <td>Untreated control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GSM5184061</td>\n",
       "      <td>control</td>\n",
       "      <td>Untreated control</td>\n",
       "      <td>Untreated control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GSM5184062</td>\n",
       "      <td>control</td>\n",
       "      <td>Untreated control</td>\n",
       "      <td>Untreated control</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 characteristics          treatment      treatment.ch1\n",
       "0  GSM5184058         control  Untreated control  Untreated control\n",
       "1  GSM5184059         control  Untreated control  Untreated control\n",
       "2  GSM5184060         control  Untreated control  Untreated control\n",
       "3  GSM5184061         control  Untreated control  Untreated control\n",
       "4  GSM5184062         control  Untreated control  Untreated control"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract 'CONT' or 'CYTO' from characteristics and replace with 'control' or 'case'\n",
    "t1d_metadata_1['characteristics'] = t1d_metadata_1['characteristics'].str.extract(r'^(CONT|CYTO)')[0]\n",
    "t1d_metadata_1['characteristics'] = t1d_metadata_1['characteristics'].replace({'CONT': 'control', 'CYTO': 'case'})\n",
    "t1d_metadata_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Merge Counts and Metadata**\n",
    "\n",
    "After standardizing the condition labels, the next step is to merge the gene expression matrices and metadata from both datasets. Concatenation is performed along the sample axis (rows), combining all samples into a single dataset. This integration ensures that the final dataset contains a broad representation of T1D and control samples, enhancing model robustness. The merging process retains only genes that are common across both datasets, reducing noise and avoiding excessive missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Shape of Data: (70826, 45)\n",
      "Preview of Data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene_symbol</th>\n",
       "      <th>GSM4586567</th>\n",
       "      <th>GSM4586568</th>\n",
       "      <th>GSM4586569</th>\n",
       "      <th>GSM4586570</th>\n",
       "      <th>GSM4586571</th>\n",
       "      <th>GSM4586572</th>\n",
       "      <th>GSM4586573</th>\n",
       "      <th>GSM4586574</th>\n",
       "      <th>GSM4586575</th>\n",
       "      <th>...</th>\n",
       "      <th>GSM5184068</th>\n",
       "      <th>GSM5184069</th>\n",
       "      <th>GSM5184070</th>\n",
       "      <th>GSM5184071</th>\n",
       "      <th>GSM5184072</th>\n",
       "      <th>GSM5184073</th>\n",
       "      <th>GSM5184074</th>\n",
       "      <th>GSM5184075</th>\n",
       "      <th>GSM5184076</th>\n",
       "      <th>GSM5184077</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ENSG00000000003</th>\n",
       "      <td>TSPAN6</td>\n",
       "      <td>596.0</td>\n",
       "      <td>832.0</td>\n",
       "      <td>478.0</td>\n",
       "      <td>662.0</td>\n",
       "      <td>596.0</td>\n",
       "      <td>672.0</td>\n",
       "      <td>453.0</td>\n",
       "      <td>811.0</td>\n",
       "      <td>717.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000000005</th>\n",
       "      <td>TNMD</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000000419</th>\n",
       "      <td>DPM1</td>\n",
       "      <td>335.0</td>\n",
       "      <td>450.0</td>\n",
       "      <td>569.0</td>\n",
       "      <td>412.0</td>\n",
       "      <td>521.0</td>\n",
       "      <td>547.0</td>\n",
       "      <td>697.0</td>\n",
       "      <td>591.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000000457</th>\n",
       "      <td>SCYL3</td>\n",
       "      <td>174.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000000460</th>\n",
       "      <td>C1orf112</td>\n",
       "      <td>61.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000000938</th>\n",
       "      <td>FGR</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000000971</th>\n",
       "      <td>CFH</td>\n",
       "      <td>3781.0</td>\n",
       "      <td>3829.0</td>\n",
       "      <td>910.0</td>\n",
       "      <td>4278.0</td>\n",
       "      <td>3914.0</td>\n",
       "      <td>3027.0</td>\n",
       "      <td>921.0</td>\n",
       "      <td>5018.0</td>\n",
       "      <td>4352.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000001036</th>\n",
       "      <td>FUCA2</td>\n",
       "      <td>2114.0</td>\n",
       "      <td>1305.0</td>\n",
       "      <td>1253.0</td>\n",
       "      <td>2349.0</td>\n",
       "      <td>2516.0</td>\n",
       "      <td>1254.0</td>\n",
       "      <td>1092.0</td>\n",
       "      <td>2966.0</td>\n",
       "      <td>2261.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000001084</th>\n",
       "      <td>GCLC</td>\n",
       "      <td>760.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>1510.0</td>\n",
       "      <td>635.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>718.0</td>\n",
       "      <td>728.0</td>\n",
       "      <td>459.0</td>\n",
       "      <td>863.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000001167</th>\n",
       "      <td>NFYA</td>\n",
       "      <td>731.0</td>\n",
       "      <td>842.0</td>\n",
       "      <td>1164.0</td>\n",
       "      <td>807.0</td>\n",
       "      <td>754.0</td>\n",
       "      <td>879.0</td>\n",
       "      <td>1186.0</td>\n",
       "      <td>840.0</td>\n",
       "      <td>729.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                gene_symbol  GSM4586567  GSM4586568  GSM4586569  GSM4586570  \\\n",
       "ENSG00000000003      TSPAN6       596.0       832.0       478.0       662.0   \n",
       "ENSG00000000005        TNMD         1.0         0.0         0.0         0.0   \n",
       "ENSG00000000419        DPM1       335.0       450.0       569.0       412.0   \n",
       "ENSG00000000457       SCYL3       174.0       221.0       123.0       230.0   \n",
       "ENSG00000000460    C1orf112        61.0       116.0       131.0       152.0   \n",
       "ENSG00000000938         FGR         0.0         1.0         0.0         3.0   \n",
       "ENSG00000000971         CFH      3781.0      3829.0       910.0      4278.0   \n",
       "ENSG00000001036       FUCA2      2114.0      1305.0      1253.0      2349.0   \n",
       "ENSG00000001084        GCLC       760.0       676.0      1510.0       635.0   \n",
       "ENSG00000001167        NFYA       731.0       842.0      1164.0       807.0   \n",
       "\n",
       "                 GSM4586571  GSM4586572  GSM4586573  GSM4586574  GSM4586575  \\\n",
       "ENSG00000000003       596.0       672.0       453.0       811.0       717.0   \n",
       "ENSG00000000005         0.0         0.0         0.0         0.0         0.0   \n",
       "ENSG00000000419       521.0       547.0       697.0       591.0       371.0   \n",
       "ENSG00000000457       196.0       151.0       147.0       212.0       263.0   \n",
       "ENSG00000000460        68.0       102.0       116.0       175.0        63.0   \n",
       "ENSG00000000938         0.0         0.0         0.0         0.0         0.0   \n",
       "ENSG00000000971      3914.0      3027.0       921.0      5018.0      4352.0   \n",
       "ENSG00000001036      2516.0      1254.0      1092.0      2966.0      2261.0   \n",
       "ENSG00000001084       540.0       718.0       728.0       459.0       863.0   \n",
       "ENSG00000001167       754.0       879.0      1186.0       840.0       729.0   \n",
       "\n",
       "                 ...  GSM5184068  GSM5184069  GSM5184070  GSM5184071  \\\n",
       "ENSG00000000003  ...         NaN         NaN         NaN         NaN   \n",
       "ENSG00000000005  ...         NaN         NaN         NaN         NaN   \n",
       "ENSG00000000419  ...         NaN         NaN         NaN         NaN   \n",
       "ENSG00000000457  ...         NaN         NaN         NaN         NaN   \n",
       "ENSG00000000460  ...         NaN         NaN         NaN         NaN   \n",
       "ENSG00000000938  ...         NaN         NaN         NaN         NaN   \n",
       "ENSG00000000971  ...         NaN         NaN         NaN         NaN   \n",
       "ENSG00000001036  ...         NaN         NaN         NaN         NaN   \n",
       "ENSG00000001084  ...         NaN         NaN         NaN         NaN   \n",
       "ENSG00000001167  ...         NaN         NaN         NaN         NaN   \n",
       "\n",
       "                 GSM5184072  GSM5184073  GSM5184074  GSM5184075  GSM5184076  \\\n",
       "ENSG00000000003         NaN         NaN         NaN         NaN         NaN   \n",
       "ENSG00000000005         NaN         NaN         NaN         NaN         NaN   \n",
       "ENSG00000000419         NaN         NaN         NaN         NaN         NaN   \n",
       "ENSG00000000457         NaN         NaN         NaN         NaN         NaN   \n",
       "ENSG00000000460         NaN         NaN         NaN         NaN         NaN   \n",
       "ENSG00000000938         NaN         NaN         NaN         NaN         NaN   \n",
       "ENSG00000000971         NaN         NaN         NaN         NaN         NaN   \n",
       "ENSG00000001036         NaN         NaN         NaN         NaN         NaN   \n",
       "ENSG00000001084         NaN         NaN         NaN         NaN         NaN   \n",
       "ENSG00000001167         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "                 GSM5184077  \n",
       "ENSG00000000003         NaN  \n",
       "ENSG00000000005         NaN  \n",
       "ENSG00000000419         NaN  \n",
       "ENSG00000000457         NaN  \n",
       "ENSG00000000460         NaN  \n",
       "ENSG00000000938         NaN  \n",
       "ENSG00000000971         NaN  \n",
       "ENSG00000001036         NaN  \n",
       "ENSG00000001084         NaN  \n",
       "ENSG00000001167         NaN  \n",
       "\n",
       "[10 rows x 45 columns]"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge only the common genes (index) to avoid NaN values\n",
    "t1d_counts = pd.concat([t1d_counts_0, t1d_counts_1], axis=0)\n",
    "t1d_metadata = pd.concat([t1d_metadata_0, t1d_metadata_1], axis=0)\n",
    "\n",
    "print(\"The Shape of Data:\", t1d_counts.shape)\n",
    "print(\"Preview of Data:\")\n",
    "t1d_counts.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preview of Metadata:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>characteristics</th>\n",
       "      <th>emp2 expression</th>\n",
       "      <th>replicate</th>\n",
       "      <th>emp2.expression.ch1</th>\n",
       "      <th>replicate.ch1</th>\n",
       "      <th>treatment</th>\n",
       "      <th>treatment.ch1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GSM4586567</td>\n",
       "      <td>case</td>\n",
       "      <td>knock down</td>\n",
       "      <td>1.0</td>\n",
       "      <td>knock down</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GSM4586568</td>\n",
       "      <td>case</td>\n",
       "      <td>overexpressing</td>\n",
       "      <td>1.0</td>\n",
       "      <td>overexpressing</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GSM4586569</td>\n",
       "      <td>case</td>\n",
       "      <td>vector control</td>\n",
       "      <td>1.0</td>\n",
       "      <td>vector control</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GSM4586570</td>\n",
       "      <td>case</td>\n",
       "      <td>wild type</td>\n",
       "      <td>1.0</td>\n",
       "      <td>wild type</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GSM4586571</td>\n",
       "      <td>control</td>\n",
       "      <td>knock down</td>\n",
       "      <td>1.0</td>\n",
       "      <td>knock down</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GSM4586572</td>\n",
       "      <td>control</td>\n",
       "      <td>overexpressing</td>\n",
       "      <td>1.0</td>\n",
       "      <td>overexpressing</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GSM4586573</td>\n",
       "      <td>control</td>\n",
       "      <td>vector control</td>\n",
       "      <td>1.0</td>\n",
       "      <td>vector control</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GSM4586574</td>\n",
       "      <td>control</td>\n",
       "      <td>wild type</td>\n",
       "      <td>1.0</td>\n",
       "      <td>wild type</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GSM4586575</td>\n",
       "      <td>case</td>\n",
       "      <td>knock down</td>\n",
       "      <td>2.0</td>\n",
       "      <td>knock down</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GSM4586576</td>\n",
       "      <td>case</td>\n",
       "      <td>overexpressing</td>\n",
       "      <td>2.0</td>\n",
       "      <td>overexpressing</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 characteristics emp2 expression  replicate emp2.expression.ch1  \\\n",
       "0  GSM4586567            case      knock down        1.0          knock down   \n",
       "1  GSM4586568            case  overexpressing        1.0      overexpressing   \n",
       "2  GSM4586569            case  vector control        1.0      vector control   \n",
       "3  GSM4586570            case       wild type        1.0           wild type   \n",
       "4  GSM4586571         control      knock down        1.0          knock down   \n",
       "5  GSM4586572         control  overexpressing        1.0      overexpressing   \n",
       "6  GSM4586573         control  vector control        1.0      vector control   \n",
       "7  GSM4586574         control       wild type        1.0           wild type   \n",
       "8  GSM4586575            case      knock down        2.0          knock down   \n",
       "9  GSM4586576            case  overexpressing        2.0      overexpressing   \n",
       "\n",
       "   replicate.ch1 treatment treatment.ch1  \n",
       "0            1.0       NaN           NaN  \n",
       "1            1.0       NaN           NaN  \n",
       "2            1.0       NaN           NaN  \n",
       "3            1.0       NaN           NaN  \n",
       "4            1.0       NaN           NaN  \n",
       "5            1.0       NaN           NaN  \n",
       "6            1.0       NaN           NaN  \n",
       "7            1.0       NaN           NaN  \n",
       "8            2.0       NaN           NaN  \n",
       "9            2.0       NaN           NaN  "
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Preview of Metadata:\")\n",
    "t1d_metadata.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Preprocess Counts Data**\n",
    "\n",
    "Gene expression data is typically organized with genes as rows and samples as columns. To align with machine learning conventions (where samples are rows and features are columns), the count matrix is transposed. The gene symbol is set as the row index before transposition, ensuring that each column represents a gene (feature). After transposition, the sample identifiers (GSM IDs) become row indices. Finally, the standardized condition labels from the metadata are appended as a new column, creating a complete dataset ready for quality control and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of data: (44, 70827)\n",
      "Preview of the data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TSPAN6</th>\n",
       "      <th>TNMD</th>\n",
       "      <th>DPM1</th>\n",
       "      <th>SCYL3</th>\n",
       "      <th>C1orf112</th>\n",
       "      <th>FGR</th>\n",
       "      <th>CFH</th>\n",
       "      <th>FUCA2</th>\n",
       "      <th>GCLC</th>\n",
       "      <th>NFYA</th>\n",
       "      <th>...</th>\n",
       "      <th>OR11K1P</th>\n",
       "      <th>MIR548AH</th>\n",
       "      <th>MYOCOS</th>\n",
       "      <th>MIR522</th>\n",
       "      <th>MIR6715B</th>\n",
       "      <th>MIR3116-2</th>\n",
       "      <th>MIR3202-2</th>\n",
       "      <th>HSFX3</th>\n",
       "      <th>MIR4481</th>\n",
       "      <th>characteristics</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GSM4586567</th>\n",
       "      <td>596.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>335.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3781.0</td>\n",
       "      <td>2114.0</td>\n",
       "      <td>760.0</td>\n",
       "      <td>731.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>case</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM4586568</th>\n",
       "      <td>832.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>450.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3829.0</td>\n",
       "      <td>1305.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>842.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>case</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM4586569</th>\n",
       "      <td>478.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>569.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>910.0</td>\n",
       "      <td>1253.0</td>\n",
       "      <td>1510.0</td>\n",
       "      <td>1164.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>case</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM4586570</th>\n",
       "      <td>662.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>412.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4278.0</td>\n",
       "      <td>2349.0</td>\n",
       "      <td>635.0</td>\n",
       "      <td>807.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>case</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM4586571</th>\n",
       "      <td>596.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>521.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3914.0</td>\n",
       "      <td>2516.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>754.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM4586572</th>\n",
       "      <td>672.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>547.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3027.0</td>\n",
       "      <td>1254.0</td>\n",
       "      <td>718.0</td>\n",
       "      <td>879.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM4586573</th>\n",
       "      <td>453.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>697.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>921.0</td>\n",
       "      <td>1092.0</td>\n",
       "      <td>728.0</td>\n",
       "      <td>1186.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM4586574</th>\n",
       "      <td>811.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>591.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5018.0</td>\n",
       "      <td>2966.0</td>\n",
       "      <td>459.0</td>\n",
       "      <td>840.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM4586575</th>\n",
       "      <td>717.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4352.0</td>\n",
       "      <td>2261.0</td>\n",
       "      <td>863.0</td>\n",
       "      <td>729.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>case</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM4586576</th>\n",
       "      <td>861.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>406.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2927.0</td>\n",
       "      <td>1643.0</td>\n",
       "      <td>724.0</td>\n",
       "      <td>942.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>case</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 70827 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            TSPAN6  TNMD   DPM1  SCYL3  C1orf112  FGR     CFH   FUCA2    GCLC  \\\n",
       "GSM                                                                             \n",
       "GSM4586567   596.0   1.0  335.0  174.0      61.0  0.0  3781.0  2114.0   760.0   \n",
       "GSM4586568   832.0   0.0  450.0  221.0     116.0  1.0  3829.0  1305.0   676.0   \n",
       "GSM4586569   478.0   0.0  569.0  123.0     131.0  0.0   910.0  1253.0  1510.0   \n",
       "GSM4586570   662.0   0.0  412.0  230.0     152.0  3.0  4278.0  2349.0   635.0   \n",
       "GSM4586571   596.0   0.0  521.0  196.0      68.0  0.0  3914.0  2516.0   540.0   \n",
       "GSM4586572   672.0   0.0  547.0  151.0     102.0  0.0  3027.0  1254.0   718.0   \n",
       "GSM4586573   453.0   0.0  697.0  147.0     116.0  0.0   921.0  1092.0   728.0   \n",
       "GSM4586574   811.0   0.0  591.0  212.0     175.0  0.0  5018.0  2966.0   459.0   \n",
       "GSM4586575   717.0   0.0  371.0  263.0      63.0  0.0  4352.0  2261.0   863.0   \n",
       "GSM4586576   861.0   0.0  406.0  194.0     106.0  0.0  2927.0  1643.0   724.0   \n",
       "\n",
       "              NFYA  ...  OR11K1P  MIR548AH  MYOCOS  MIR522  MIR6715B  \\\n",
       "GSM                 ...                                                \n",
       "GSM4586567   731.0  ...      NaN       NaN     NaN     NaN       NaN   \n",
       "GSM4586568   842.0  ...      NaN       NaN     NaN     NaN       NaN   \n",
       "GSM4586569  1164.0  ...      NaN       NaN     NaN     NaN       NaN   \n",
       "GSM4586570   807.0  ...      NaN       NaN     NaN     NaN       NaN   \n",
       "GSM4586571   754.0  ...      NaN       NaN     NaN     NaN       NaN   \n",
       "GSM4586572   879.0  ...      NaN       NaN     NaN     NaN       NaN   \n",
       "GSM4586573  1186.0  ...      NaN       NaN     NaN     NaN       NaN   \n",
       "GSM4586574   840.0  ...      NaN       NaN     NaN     NaN       NaN   \n",
       "GSM4586575   729.0  ...      NaN       NaN     NaN     NaN       NaN   \n",
       "GSM4586576   942.0  ...      NaN       NaN     NaN     NaN       NaN   \n",
       "\n",
       "            MIR3116-2  MIR3202-2  HSFX3  MIR4481  characteristics  \n",
       "GSM                                                                \n",
       "GSM4586567        NaN        NaN    NaN      NaN             case  \n",
       "GSM4586568        NaN        NaN    NaN      NaN             case  \n",
       "GSM4586569        NaN        NaN    NaN      NaN             case  \n",
       "GSM4586570        NaN        NaN    NaN      NaN             case  \n",
       "GSM4586571        NaN        NaN    NaN      NaN          control  \n",
       "GSM4586572        NaN        NaN    NaN      NaN          control  \n",
       "GSM4586573        NaN        NaN    NaN      NaN          control  \n",
       "GSM4586574        NaN        NaN    NaN      NaN          control  \n",
       "GSM4586575        NaN        NaN    NaN      NaN             case  \n",
       "GSM4586576        NaN        NaN    NaN      NaN             case  \n",
       "\n",
       "[10 rows x 70827 columns]"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocess PE data\n",
    "t1d_counts = t1d_counts.set_index('gene_symbol').T\n",
    "t1d_counts.index.name = 'GSM'\n",
    "t1d_counts['characteristics'] = t1d_metadata['characteristics'].values\n",
    "t1d_counts.columns = [col if isinstance(col, str) else col[0] for col in t1d_counts.columns]\n",
    "\n",
    "print(\"The shape of data:\", t1d_counts.shape)\n",
    "print(\"Preview of the data:\")\n",
    "t1d_counts.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Quality Control of the Data**\n",
    "\n",
    "Rigorous quality control is essential to ensure the reliability of downstream analysis. This step begins with checking for missing values, duplicates, and low-variance genes that may add noise without contributing meaningful information. Genes with more than 50% missing values are filtered out to maintain data integrity. Remaining missing values are imputed using KNN imputation, which estimates missing expression levels based on similar samples. Low-variance genes—those showing little variation across samples—are removed as they are unlikely to discriminate between conditions. After imputation and filtering, the dataset is inspected again to confirm data completeness and consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 44 entries, GSM4586567 to GSM5184077\n",
      "Columns: 70827 entries, TSPAN6 to characteristics\n",
      "dtypes: float64(70826), object(1)\n",
      "memory usage: 23.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# Check the basic infos of the dataset\n",
    "t1d_counts.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PE Missing Values: 70826\n",
      "Missing Values:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TSPAN6       20\n",
       "TNMD         20\n",
       "DPM1         20\n",
       "SCYL3        20\n",
       "C1orf112     20\n",
       "             ..\n",
       "MIR6715B     24\n",
       "MIR3116-2    24\n",
       "MIR3202-2    24\n",
       "HSFX3        24\n",
       "MIR4481      24\n",
       "Length: 70826, dtype: int64"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values\n",
    "def check_missing_values(df):\n",
    "    missing_values = df.isnull().sum()\n",
    "    return missing_values[missing_values > 0]\n",
    "t1d_missing = check_missing_values(t1d_counts)\n",
    "print(\"PE Missing Values:\", len(t1d_missing))\n",
    "print(\"Missing Values:\")\n",
    "t1d_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered genes to keep those with <50% missingness: 35413 genes remain.\n",
      "Filtered genes to keep those with variance > 0.01: 28920 genes remain.\n",
      "Imputing Nans ...\n",
      "Number of features with missing values after imputation: 0\n",
      "After imputation data shape is (44, 28921)\n"
     ]
    }
   ],
   "source": [
    "# Separate features and target\n",
    "features = t1d_counts.drop(columns=['characteristics'])\n",
    "target = t1d_counts['characteristics']\n",
    "\n",
    "# Step 1: Filter genes (features) with less than 50% missing values\n",
    "min_non_nan = int((1 - 0.5) * len(features))  # At least 50% non-NA values\n",
    "features_filtered = features.dropna(axis=1, thresh=min_non_nan)\n",
    "print(f\"Filtered genes to keep those with <50% missingness: {features_filtered.shape[1]} genes remain.\")\n",
    "\n",
    "# Step 2: Filter out low variance genes (near-constant)\n",
    "variance = features_filtered.var()\n",
    "high_variance_genes = variance[variance > 0.01].index  # Adjust threshold if needed\n",
    "features_filtered = features_filtered.loc[:, high_variance_genes]\n",
    "print(f\"Filtered genes to keep those with variance > 0.01: {features_filtered.shape[1]} genes remain.\")\n",
    "\n",
    "# Impute missing values using KNNImputer\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "print(\"Imputing Nans ...\")\n",
    "features_imputed_array = imputer.fit_transform(features_filtered)\n",
    "\n",
    "# Convert back to DataFrame with original indices and columns\n",
    "features_imputed = pd.DataFrame(features_imputed_array, \n",
    "                                index=features_filtered.index, \n",
    "                                columns=features_filtered.columns)\n",
    "\n",
    "# Step 4: Concatenate target column back\n",
    "t1d_counts_processed = pd.concat([features_imputed, target], axis=1)\n",
    "\n",
    "# Step 5: Check for any missing values remaining\n",
    "def check_missing_values(df):\n",
    "    missing_values = df.isnull().sum()\n",
    "    return missing_values[missing_values > 0]\n",
    "\n",
    "missing_after_imputation = check_missing_values(t1d_counts_processed)\n",
    "print(f\"Number of features with missing values after imputation: {len(missing_after_imputation)}\")\n",
    "print(\"After imputation data shape is\", t1d_counts_processed.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Check for Duplicates**\n",
    "\n",
    "Duplicate samples can bias model training and inflate performance metrics artificially. Therefore, we check for and remove any exact duplicate rows in the dataset. If duplicates are found, they are removed while preserving the original index structure. This ensures that each sample is unique, maintaining the integrity of cross-validation and statistical tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates: 18\n",
      "All duplicates are removed\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates\n",
    "def check_duplicates(df):\n",
    "    duplicates = df.duplicated().sum()\n",
    "    return duplicates\n",
    "t1d_duplicates = check_duplicates(t1d_counts_processed)\n",
    "print(\"Duplicates:\", t1d_duplicates)\n",
    "\n",
    "if t1d_duplicates > 0:\n",
    "    t1d_counts_processed.drop_duplicates(ignore_index=True)\n",
    "    print(\"All duplicates are removed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Final Inspection of Data**\n",
    "\n",
    "After preprocessing and quality control, a final inspection is performed to verify the dataset’s structure and completeness. The shape of the dataset is printed, and a preview of the first few rows is shown to confirm that all steps have been applied correctly. This cleaned dataset is then saved to disk for reproducibility and use in subsequent analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final shape: (44, 28921)\n",
      "Preview of final data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TSPAN6</th>\n",
       "      <th>TNMD</th>\n",
       "      <th>DPM1</th>\n",
       "      <th>SCYL3</th>\n",
       "      <th>C1orf112</th>\n",
       "      <th>FGR</th>\n",
       "      <th>CFH</th>\n",
       "      <th>FUCA2</th>\n",
       "      <th>GCLC</th>\n",
       "      <th>NFYA</th>\n",
       "      <th>...</th>\n",
       "      <th>LINC02009</th>\n",
       "      <th>ZDBF2</th>\n",
       "      <th>LMLN2</th>\n",
       "      <th>FRG1-DT</th>\n",
       "      <th>FRG1-DT</th>\n",
       "      <th>FRG1-DT</th>\n",
       "      <th>LOC729732</th>\n",
       "      <th>MYOCOS</th>\n",
       "      <th>HSFX3</th>\n",
       "      <th>characteristics</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GSM4586567</th>\n",
       "      <td>596.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>335.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3781.0</td>\n",
       "      <td>2114.0</td>\n",
       "      <td>760.0</td>\n",
       "      <td>731.0</td>\n",
       "      <td>...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>413.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>case</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM4586568</th>\n",
       "      <td>832.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>450.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3829.0</td>\n",
       "      <td>1305.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>842.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1639.0</td>\n",
       "      <td>379.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>case</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM4586569</th>\n",
       "      <td>478.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>569.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>910.0</td>\n",
       "      <td>1253.0</td>\n",
       "      <td>1510.0</td>\n",
       "      <td>1164.0</td>\n",
       "      <td>...</td>\n",
       "      <td>64.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>case</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM4586570</th>\n",
       "      <td>662.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>412.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4278.0</td>\n",
       "      <td>2349.0</td>\n",
       "      <td>635.0</td>\n",
       "      <td>807.0</td>\n",
       "      <td>...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>390.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>case</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM4586571</th>\n",
       "      <td>596.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>521.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3914.0</td>\n",
       "      <td>2516.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>754.0</td>\n",
       "      <td>...</td>\n",
       "      <td>85.0</td>\n",
       "      <td>370.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM4586572</th>\n",
       "      <td>672.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>547.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3027.0</td>\n",
       "      <td>1254.0</td>\n",
       "      <td>718.0</td>\n",
       "      <td>879.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2660.0</td>\n",
       "      <td>293.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM4586573</th>\n",
       "      <td>453.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>697.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>921.0</td>\n",
       "      <td>1092.0</td>\n",
       "      <td>728.0</td>\n",
       "      <td>1186.0</td>\n",
       "      <td>...</td>\n",
       "      <td>770.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM4586574</th>\n",
       "      <td>811.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>591.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5018.0</td>\n",
       "      <td>2966.0</td>\n",
       "      <td>459.0</td>\n",
       "      <td>840.0</td>\n",
       "      <td>...</td>\n",
       "      <td>44.0</td>\n",
       "      <td>395.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM4586575</th>\n",
       "      <td>717.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4352.0</td>\n",
       "      <td>2261.0</td>\n",
       "      <td>863.0</td>\n",
       "      <td>729.0</td>\n",
       "      <td>...</td>\n",
       "      <td>29.0</td>\n",
       "      <td>474.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>case</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM4586576</th>\n",
       "      <td>861.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>406.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2927.0</td>\n",
       "      <td>1643.0</td>\n",
       "      <td>724.0</td>\n",
       "      <td>942.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1829.0</td>\n",
       "      <td>348.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>case</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 28921 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            TSPAN6  TNMD   DPM1  SCYL3  C1orf112  FGR     CFH   FUCA2    GCLC  \\\n",
       "GSM                                                                             \n",
       "GSM4586567   596.0   1.0  335.0  174.0      61.0  0.0  3781.0  2114.0   760.0   \n",
       "GSM4586568   832.0   0.0  450.0  221.0     116.0  1.0  3829.0  1305.0   676.0   \n",
       "GSM4586569   478.0   0.0  569.0  123.0     131.0  0.0   910.0  1253.0  1510.0   \n",
       "GSM4586570   662.0   0.0  412.0  230.0     152.0  3.0  4278.0  2349.0   635.0   \n",
       "GSM4586571   596.0   0.0  521.0  196.0      68.0  0.0  3914.0  2516.0   540.0   \n",
       "GSM4586572   672.0   0.0  547.0  151.0     102.0  0.0  3027.0  1254.0   718.0   \n",
       "GSM4586573   453.0   0.0  697.0  147.0     116.0  0.0   921.0  1092.0   728.0   \n",
       "GSM4586574   811.0   0.0  591.0  212.0     175.0  0.0  5018.0  2966.0   459.0   \n",
       "GSM4586575   717.0   0.0  371.0  263.0      63.0  0.0  4352.0  2261.0   863.0   \n",
       "GSM4586576   861.0   0.0  406.0  194.0     106.0  0.0  2927.0  1643.0   724.0   \n",
       "\n",
       "              NFYA  ...  LINC02009  ZDBF2  LMLN2  FRG1-DT  FRG1-DT  FRG1-DT  \\\n",
       "GSM                 ...                                                       \n",
       "GSM4586567   731.0  ...       28.0  413.0    5.0      0.0      1.0      5.0   \n",
       "GSM4586568   842.0  ...     1639.0  379.0    1.0      0.0      1.0      3.0   \n",
       "GSM4586569  1164.0  ...       64.0   99.0    0.0      0.0      0.0      2.0   \n",
       "GSM4586570   807.0  ...       18.0  390.0    0.0      1.0      0.0      6.0   \n",
       "GSM4586571   754.0  ...       85.0  370.0    3.0      0.0      8.0      3.0   \n",
       "GSM4586572   879.0  ...     2660.0  293.0    0.0      1.0      0.0      2.0   \n",
       "GSM4586573  1186.0  ...      770.0   95.0    0.0      0.0      0.0      1.0   \n",
       "GSM4586574   840.0  ...       44.0  395.0    0.0      0.0      1.0      2.0   \n",
       "GSM4586575   729.0  ...       29.0  474.0    1.0      0.0      1.0      2.0   \n",
       "GSM4586576   942.0  ...     1829.0  348.0    2.0      0.0      2.0      1.0   \n",
       "\n",
       "            LOC729732  MYOCOS  HSFX3  characteristics  \n",
       "GSM                                                    \n",
       "GSM4586567       49.0     5.0    0.0             case  \n",
       "GSM4586568       54.0     3.0    0.0             case  \n",
       "GSM4586569       41.0     4.0    1.0             case  \n",
       "GSM4586570       34.0     0.0    0.0             case  \n",
       "GSM4586571       74.0     0.0    0.0          control  \n",
       "GSM4586572       47.0     0.0    0.0          control  \n",
       "GSM4586573       21.0     0.0    0.0          control  \n",
       "GSM4586574       68.0     0.0    0.0          control  \n",
       "GSM4586575       46.0     2.0    0.0             case  \n",
       "GSM4586576       19.0     1.0    0.0             case  \n",
       "\n",
       "[10 rows x 28921 columns]"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final inspection of data\n",
    "print(\"The final shape:\", t1d_counts_processed.shape)\n",
    "print(\"Preview of final data:\")\n",
    "t1d_counts_processed.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the processed datasets\n",
    "t1d_counts_processed.to_csv(\"Data/clean_t1d_counts_knnimputed.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Clean Data Loading and Inspection**\n",
    "\n",
    "To ensure reproducibility and modularity, the cleaned dataset is reloaded from the saved CSV file. This allows the pipeline to be restarted from this point without rerunning the entire preprocessing. The shape and content of the data are inspected again to confirm successful loading and consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data: (44, 28922)\n",
      "Preview of the data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GSM</th>\n",
       "      <th>TSPAN6</th>\n",
       "      <th>TNMD</th>\n",
       "      <th>DPM1</th>\n",
       "      <th>SCYL3</th>\n",
       "      <th>C1orf112</th>\n",
       "      <th>FGR</th>\n",
       "      <th>CFH</th>\n",
       "      <th>FUCA2</th>\n",
       "      <th>GCLC</th>\n",
       "      <th>...</th>\n",
       "      <th>LINC02009</th>\n",
       "      <th>ZDBF2</th>\n",
       "      <th>LMLN2</th>\n",
       "      <th>FRG1-DT.6</th>\n",
       "      <th>FRG1-DT.7</th>\n",
       "      <th>FRG1-DT.8</th>\n",
       "      <th>LOC729732</th>\n",
       "      <th>MYOCOS</th>\n",
       "      <th>HSFX3</th>\n",
       "      <th>characteristics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GSM4586567</td>\n",
       "      <td>596.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>335.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3781.0</td>\n",
       "      <td>2114.0</td>\n",
       "      <td>760.0</td>\n",
       "      <td>...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>413.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>case</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GSM4586568</td>\n",
       "      <td>832.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>450.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3829.0</td>\n",
       "      <td>1305.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1639.0</td>\n",
       "      <td>379.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>case</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GSM4586569</td>\n",
       "      <td>478.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>569.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>910.0</td>\n",
       "      <td>1253.0</td>\n",
       "      <td>1510.0</td>\n",
       "      <td>...</td>\n",
       "      <td>64.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>case</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GSM4586570</td>\n",
       "      <td>662.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>412.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4278.0</td>\n",
       "      <td>2349.0</td>\n",
       "      <td>635.0</td>\n",
       "      <td>...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>390.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>case</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GSM4586571</td>\n",
       "      <td>596.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>521.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3914.0</td>\n",
       "      <td>2516.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>...</td>\n",
       "      <td>85.0</td>\n",
       "      <td>370.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GSM4586572</td>\n",
       "      <td>672.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>547.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3027.0</td>\n",
       "      <td>1254.0</td>\n",
       "      <td>718.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2660.0</td>\n",
       "      <td>293.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GSM4586573</td>\n",
       "      <td>453.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>697.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>921.0</td>\n",
       "      <td>1092.0</td>\n",
       "      <td>728.0</td>\n",
       "      <td>...</td>\n",
       "      <td>770.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GSM4586574</td>\n",
       "      <td>811.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>591.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5018.0</td>\n",
       "      <td>2966.0</td>\n",
       "      <td>459.0</td>\n",
       "      <td>...</td>\n",
       "      <td>44.0</td>\n",
       "      <td>395.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GSM4586575</td>\n",
       "      <td>717.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4352.0</td>\n",
       "      <td>2261.0</td>\n",
       "      <td>863.0</td>\n",
       "      <td>...</td>\n",
       "      <td>29.0</td>\n",
       "      <td>474.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>case</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GSM4586576</td>\n",
       "      <td>861.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>406.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2927.0</td>\n",
       "      <td>1643.0</td>\n",
       "      <td>724.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1829.0</td>\n",
       "      <td>348.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>case</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 28922 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          GSM  TSPAN6  TNMD   DPM1  SCYL3  C1orf112  FGR     CFH   FUCA2  \\\n",
       "0  GSM4586567   596.0   1.0  335.0  174.0      61.0  0.0  3781.0  2114.0   \n",
       "1  GSM4586568   832.0   0.0  450.0  221.0     116.0  1.0  3829.0  1305.0   \n",
       "2  GSM4586569   478.0   0.0  569.0  123.0     131.0  0.0   910.0  1253.0   \n",
       "3  GSM4586570   662.0   0.0  412.0  230.0     152.0  3.0  4278.0  2349.0   \n",
       "4  GSM4586571   596.0   0.0  521.0  196.0      68.0  0.0  3914.0  2516.0   \n",
       "5  GSM4586572   672.0   0.0  547.0  151.0     102.0  0.0  3027.0  1254.0   \n",
       "6  GSM4586573   453.0   0.0  697.0  147.0     116.0  0.0   921.0  1092.0   \n",
       "7  GSM4586574   811.0   0.0  591.0  212.0     175.0  0.0  5018.0  2966.0   \n",
       "8  GSM4586575   717.0   0.0  371.0  263.0      63.0  0.0  4352.0  2261.0   \n",
       "9  GSM4586576   861.0   0.0  406.0  194.0     106.0  0.0  2927.0  1643.0   \n",
       "\n",
       "     GCLC  ...  LINC02009  ZDBF2  LMLN2  FRG1-DT.6  FRG1-DT.7  FRG1-DT.8  \\\n",
       "0   760.0  ...       28.0  413.0    5.0        0.0        1.0        5.0   \n",
       "1   676.0  ...     1639.0  379.0    1.0        0.0        1.0        3.0   \n",
       "2  1510.0  ...       64.0   99.0    0.0        0.0        0.0        2.0   \n",
       "3   635.0  ...       18.0  390.0    0.0        1.0        0.0        6.0   \n",
       "4   540.0  ...       85.0  370.0    3.0        0.0        8.0        3.0   \n",
       "5   718.0  ...     2660.0  293.0    0.0        1.0        0.0        2.0   \n",
       "6   728.0  ...      770.0   95.0    0.0        0.0        0.0        1.0   \n",
       "7   459.0  ...       44.0  395.0    0.0        0.0        1.0        2.0   \n",
       "8   863.0  ...       29.0  474.0    1.0        0.0        1.0        2.0   \n",
       "9   724.0  ...     1829.0  348.0    2.0        0.0        2.0        1.0   \n",
       "\n",
       "   LOC729732  MYOCOS  HSFX3  characteristics  \n",
       "0       49.0     5.0    0.0             case  \n",
       "1       54.0     3.0    0.0             case  \n",
       "2       41.0     4.0    1.0             case  \n",
       "3       34.0     0.0    0.0             case  \n",
       "4       74.0     0.0    0.0          control  \n",
       "5       47.0     0.0    0.0          control  \n",
       "6       21.0     0.0    0.0          control  \n",
       "7       68.0     0.0    0.0          control  \n",
       "8       46.0     2.0    0.0             case  \n",
       "9       19.0     1.0    0.0             case  \n",
       "\n",
       "[10 rows x 28922 columns]"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the datasets\n",
    "t1d_data = pd.read_csv('Data/clean_t1d_counts_knnimputed.csv')\n",
    "print(\"Shape of data:\", t1d_data.shape)\n",
    "print(\"Preview of the data:\")\n",
    "t1d_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total genes across datasets: 28921\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of total genes across datasets:\", len(set(t1d_data.columns[1:])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Label Distribution Visualization**\n",
    "\n",
    "Understanding the distribution of class labels is critical for evaluating potential class imbalance. A bar plot is generated to visualize the number of 'case' and 'control' samples. Balanced classes ensure that classifiers are not biased toward the majority class, and any imbalance can be addressed later using techniques like SMOTE (though not applied here due to sufficient balance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the distribution of labels with bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "t1d_data['characteristics'].value_counts().plot(kind='bar')\n",
    "plt.title('Label Distribution in Dataset')\n",
    "plt.xlabel('Condition')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=0)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Feature Preparation**\n",
    "\n",
    "The dataset is split into features (gene expression levels) and the target variable (case/control status). Gene expression features are standardized using StandardScaler to ensure that all genes contribute equally to distance-based models like SVM and KNN. The target labels are encoded into numerical form using LabelEncoder, converting 'case' and 'control' into 0 and 1 (or vice versa), which is required for machine learning algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (44, 28920)\n",
      "Labels shape: (44,)\n"
     ]
    }
   ],
   "source": [
    "# Split the merged dataset into features and labels\n",
    "X = t1d_data.drop(columns=['characteristics', 'GSM'])\n",
    "y = t1d_data['characteristics']\n",
    "print(\"Features shape:\", X.shape)\n",
    "print(\"Labels shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled features shape: (44, 28920)\n"
     ]
    }
   ],
   "source": [
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "print(\"Scaled features shape:\", X_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labe encode the targets\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Lasso Feature Selection**\n",
    "\n",
    "Lasso (Least Absolute Shrinkage and Selection Operator) regression performs both regularization and feature selection by shrinking less important feature coefficients to zero. Here, LassoCV automatically selects the optimal regularization strength using cross-validation. Features with non-zero coefficients above a small threshold (0.0005) are retained as potential biomarkers. This method identifies genes whose expression levels are most predictive of T1D status while reducing overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_scaled\n",
    "y = y_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Biomarkers selected by Lasso: 72\n",
      "Selected Biomarkers using Lasso:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DPM1</td>\n",
       "      <td>0.142640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FKBP4</td>\n",
       "      <td>0.052994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CYP51A1</td>\n",
       "      <td>0.039912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RAD52</td>\n",
       "      <td>0.034862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LAS1L</td>\n",
       "      <td>0.034265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>CCDC146</td>\n",
       "      <td>0.000738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>PTPRVP</td>\n",
       "      <td>0.000639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>MSH2</td>\n",
       "      <td>0.000608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>SLC22A2</td>\n",
       "      <td>0.000591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>HCST</td>\n",
       "      <td>0.000568</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Feature  Importance\n",
       "0      DPM1    0.142640\n",
       "1     FKBP4    0.052994\n",
       "2   CYP51A1    0.039912\n",
       "3     RAD52    0.034862\n",
       "4     LAS1L    0.034265\n",
       "..      ...         ...\n",
       "67  CCDC146    0.000738\n",
       "68   PTPRVP    0.000639\n",
       "69     MSH2    0.000608\n",
       "70  SLC22A2    0.000591\n",
       "71     HCST    0.000568\n",
       "\n",
       "[72 rows x 2 columns]"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Lasso model and perform feature selection s\n",
    "lasso = LassoCV(alphas=np.logspace(-4, 4, 100), cv=10, random_state=42)\n",
    "lasso.fit(X, y)\n",
    "importance = np.abs(lasso.coef_)\n",
    "# Create a DataFrame for feature importance\n",
    "feature_importance = pd.DataFrame({'Feature': X.columns, 'Importance': importance})\n",
    "# Sort the features by importance\n",
    "feature_importance = feature_importance.sort_values(by='Importance', ascending=False)\n",
    "feature_importance.reset_index(drop=True, inplace=True)\n",
    "lasso_feature_importance = feature_importance[feature_importance['Importance'] > 0.0005]\n",
    "# Print the selected features\n",
    "print(\"Number of Biomarkers selected by Lasso:\", len(lasso_feature_importance))\n",
    "print(\"Selected Biomarkers using Lasso:\")\n",
    "lasso_feature_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Random Forest Feature Selection**\n",
    "\n",
    "Random Forest provides a measure of feature importance based on how much each gene contributes to reducing impurity across decision trees. A Random Forest model is trained on the scaled data, and genes with importance scores above a threshold (0.003) are selected. This approach captures non-linear relationships and interactions between genes, complementing the linear assumptions of Lasso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Biomarkers selected by Random Forest: 69\n",
      "Selected Biomarkers using Random Forest:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SLX4IP</td>\n",
       "      <td>0.009689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FUT11</td>\n",
       "      <td>0.007673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRIM52-AS1</td>\n",
       "      <td>0.007099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PLEKHA2</td>\n",
       "      <td>0.007023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NCDN</td>\n",
       "      <td>0.006494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>BANP</td>\n",
       "      <td>0.003070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>FASTKD2</td>\n",
       "      <td>0.003039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>BCKDHB</td>\n",
       "      <td>0.003028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>WDR35</td>\n",
       "      <td>0.003012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>PMM2</td>\n",
       "      <td>0.003010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Feature  Importance\n",
       "0       SLX4IP    0.009689\n",
       "1        FUT11    0.007673\n",
       "2   TRIM52-AS1    0.007099\n",
       "3      PLEKHA2    0.007023\n",
       "4         NCDN    0.006494\n",
       "..         ...         ...\n",
       "64        BANP    0.003070\n",
       "65     FASTKD2    0.003039\n",
       "66      BCKDHB    0.003028\n",
       "67       WDR35    0.003012\n",
       "68        PMM2    0.003010\n",
       "\n",
       "[69 rows x 2 columns]"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Random Forest model and perform feature selection\n",
    "rf = RandomForestClassifier(n_estimators=500, random_state=42)\n",
    "rf.fit(X, y)\n",
    "importance = rf.feature_importances_\n",
    "# Create a DataFrame for feature importance\n",
    "feature_importance = pd.DataFrame({'Feature': X.columns, 'Importance': importance})\n",
    "# Sort the features by importance\n",
    "feature_importance = feature_importance.sort_values(by='Importance', ascending=False)\n",
    "feature_importance.reset_index(drop=True, inplace=True)\n",
    "rf_feature_importance = feature_importance[feature_importance['Importance'] > 0.003]\n",
    "# Print the selected features\n",
    "print(\"Number of Biomarkers selected by Random Forest:\", len(rf_feature_importance))\n",
    "print(\"Selected Biomarkers using Random Forest:\")\n",
    "rf_feature_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **SVM-RFE Feature Selection**\n",
    "\n",
    "Although the name suggests Recursive Feature Elimination (RFE), this implementation evaluates each gene individually using an SVM classifier. Genes that achieve high classification accuracy (greater than 70%) on their own are considered discriminative. This univariate filtering approach identifies genes with strong individual predictive power, which may be biologically significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Biomarkers selected by Single-Feature SVM: 342\n",
      "Selected Biomarkers using Single-Feature SVM:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RBM3</td>\n",
       "      <td>0.788889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PSPC1</td>\n",
       "      <td>0.788889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PRR22</td>\n",
       "      <td>0.766667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MTND2P28</td>\n",
       "      <td>0.766667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XRRA1</td>\n",
       "      <td>0.766667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>UTP11</td>\n",
       "      <td>0.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>SHLD2</td>\n",
       "      <td>0.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>TNPO2</td>\n",
       "      <td>0.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>ACOT9</td>\n",
       "      <td>0.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>NDUFS1</td>\n",
       "      <td>0.722222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>342 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Feature  Importance\n",
       "0        RBM3    0.788889\n",
       "1       PSPC1    0.788889\n",
       "2       PRR22    0.766667\n",
       "3    MTND2P28    0.766667\n",
       "4       XRRA1    0.766667\n",
       "..        ...         ...\n",
       "337     UTP11    0.722222\n",
       "338     SHLD2    0.722222\n",
       "339     TNPO2    0.722222\n",
       "340     ACOT9    0.722222\n",
       "341    NDUFS1    0.722222\n",
       "\n",
       "[342 rows x 2 columns]"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardize features (important for SVM)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# Evaluate each feature individually using SVM with cross-validation\n",
    "feature_scores = []\n",
    "for feature in X_scaled.columns:\n",
    "    X_single = X_scaled[[feature]]  # Keep it as DataFrame\n",
    "    svm = SVC(kernel='linear', random_state=42)\n",
    "    score = cross_val_score(svm, X_single, y, cv=5, scoring='accuracy').mean()\n",
    "    feature_scores.append(score)\n",
    "\n",
    "# Create a DataFrame for \"importance\" based on accuracy scores\n",
    "feature_importance = pd.DataFrame({'Feature': X.columns, 'Importance': feature_scores})\n",
    "\n",
    "# Sort the features by importance (accuracy score)\n",
    "feature_importance = feature_importance.sort_values(by='Importance', ascending=False)\n",
    "feature_importance.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Filter out features with zero importance (if any)\n",
    "svmrfe_feature_importance = feature_importance[feature_importance['Importance'] > 0.7]\n",
    "\n",
    "# Print the selected features\n",
    "print(\"Number of Biomarkers selected by Single-Feature SVM:\", len(svmrfe_feature_importance))\n",
    "print(\"Selected Biomarkers using Single-Feature SVM:\")\n",
    "svmrfe_feature_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **T-test for Feature Selection**\n",
    "\n",
    "A two-sample t-test (Welch’s t-test) is applied to each gene to assess whether its mean expression level significantly differs between T1D cases and controls. Genes with a p-value below 0.05 are considered statistically significant and retained. This classical statistical method identifies differentially expressed genes, providing a biologically interpretable list of potential biomarkers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Biomarkers selected by t-test: 5676\n",
      "Selected Biomarkers using t-test:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>p-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P4HA1</td>\n",
       "      <td>1.752273e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GCFC2</td>\n",
       "      <td>1.928272e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TIMM23B</td>\n",
       "      <td>2.500474e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DIMT1</td>\n",
       "      <td>2.834528e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TXNRD3</td>\n",
       "      <td>4.264975e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5671</th>\n",
       "      <td>SH3BGR</td>\n",
       "      <td>4.985642e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5672</th>\n",
       "      <td>TEKT4</td>\n",
       "      <td>4.986287e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5673</th>\n",
       "      <td>KCTD21</td>\n",
       "      <td>4.990732e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5674</th>\n",
       "      <td>DDHD1</td>\n",
       "      <td>4.996429e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5675</th>\n",
       "      <td>TNIK</td>\n",
       "      <td>4.996994e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5676 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Feature       p-value\n",
       "0       P4HA1  1.752273e-07\n",
       "1       GCFC2  1.928272e-07\n",
       "2     TIMM23B  2.500474e-07\n",
       "3       DIMT1  2.834528e-07\n",
       "4      TXNRD3  4.264975e-07\n",
       "...       ...           ...\n",
       "5671   SH3BGR  4.985642e-02\n",
       "5672    TEKT4  4.986287e-02\n",
       "5673   KCTD21  4.990732e-02\n",
       "5674    DDHD1  4.996429e-02\n",
       "5675     TNIK  4.996994e-02\n",
       "\n",
       "[5676 rows x 2 columns]"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardize features (optional for t-test, but can keep it consistent)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# Separate features by class\n",
    "class_labels = np.unique(y)\n",
    "group1_idx = np.where(y == class_labels[0])[0]\n",
    "group2_idx = np.where(y == class_labels[1])[0]\n",
    "\n",
    "# Perform t-test for each feature (gene)\n",
    "ttest_pvalues = []\n",
    "for feature in X_scaled.columns:\n",
    "    group1_values = X_scaled.iloc[group1_idx][feature]\n",
    "    group2_values = X_scaled.iloc[group2_idx][feature]\n",
    "    stat, pvalue = ttest_ind(group1_values, group2_values, equal_var=False)  # Welch's t-test\n",
    "    ttest_pvalues.append(pvalue)\n",
    "\n",
    "# Create a DataFrame with p-values\n",
    "ttest_feature_importance = pd.DataFrame({'Feature': X.columns, 'p-value': ttest_pvalues})\n",
    "\n",
    "# Sort features by ascending p-value (most significant first)\n",
    "ttest_feature_importance = ttest_feature_importance.sort_values(by='p-value')\n",
    "ttest_feature_importance.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Filter features with p-value < 0.05 (significant)\n",
    "ttest_feature_importance = ttest_feature_importance[ttest_feature_importance['p-value'] < 0.05]\n",
    "\n",
    "# Print results\n",
    "print(f\"Number of Biomarkers selected by t-test: {len(ttest_feature_importance)}\")\n",
    "print(\"Selected Biomarkers using t-test:\")\n",
    "ttest_feature_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Accumulation of Selected Features**\n",
    "\n",
    "To create a robust set of biomarkers, features selected by all four methods (Lasso, Random Forest, SVM, t-test) are combined into a single list. This ensemble-based feature selection approach increases confidence in the selected genes by requiring consensus across multiple methodologies. The final dataset includes only these high-confidence biomarkers and the target label, forming the basis for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Selected features: 5709\n",
      "Selected features:\n",
      "['A2ML1', 'AAAS', 'AAR2', 'AARSD1', 'AASDHPPT', 'AASS', 'ABCB10', 'ABCB6', 'ABCC6.1', 'ABCC6.3', 'ABCC6P2', 'ABCD1', 'ABCD3', 'ABCE1', 'ABCF1', 'ABCF1.12', 'ABCF1.4', 'ABCF1.8', 'ABCF2', 'ABHD11', 'ABHD12', 'ABHD13', 'ABHD17A', 'ABHD17C', 'ABHD2', 'ABHD3', 'ABITRAM', 'ABLIM3', 'ABR', 'ABR.1', 'ABR.2', 'ABR.3', 'ABR.4', 'ABR.5', 'ABR.6', 'ABR.7', 'ABR.8', 'ABRACL', 'ABRAXAS2', 'ABT1', 'ABTB1', 'ACAA1', 'ACACA', 'ACACA.2', 'ACAD10', 'ACAD8', 'ACAD9', 'ACADM', 'ACADS', 'ACADSB', 'ACAP1', 'ACAP3', 'ACAT1', 'ACAT2', 'ACBD4', 'ACBD5', 'ACBD6', 'ACCS', 'ACER2', 'ACER3', 'ACIN1', 'ACOT1', 'ACOT2', 'ACOT7', 'ACOT9', 'ACOX3', 'ACP1', 'ACP2', 'ACP6', 'ACRBP', 'ACSF2', 'ACSS2', 'ACTB', 'ACTC1', 'ACTG1', 'ACTG1P24', 'ACTG1P25', 'ACTL10', 'ACTN4', 'ACTN4P1', 'ACTR10', 'ACTR1A', 'ACTR1B', 'ACTR3', 'ACTR3B', 'ACVR1', 'ACVR1C', 'ACVR2B', 'ACVR2B-AS1', 'ACY1', 'ACYP1', 'ADAM22', 'ADAM32', 'ADAM32.2', 'ADAMTS1', 'ADAMTS12.1', 'ADAMTS12.3', 'ADAMTS9', 'ADAMTSL5', 'ADAT1', 'ADAT2', 'ADAT3', 'ADCK1', 'ADCK5', 'ADCY10P1', 'ADCY4', 'ADCY7', 'ADCYAP1', 'ADGRB2', 'ADHFE1', 'ADIPOR2', 'ADIRF-AS1', 'ADK', 'ADM', 'ADNP', 'ADNP2', 'ADO', 'ADPRS', 'ADRA1B', 'ADRA2B', 'ADRM1', 'ADSL', 'ADSS2', 'AEBP1', 'AEBP2', 'AEN', 'AFF1', 'AFG3L1P', 'AFG3L2', 'AGAP1', 'AGAP3', 'AGAP6', 'AGBL3', 'AGBL5', 'AGFG1', 'AGFG2', 'AGK', 'AGK.2', 'AGL', 'AGO2', 'AHCTF1', 'AHCYL1', 'AHDC1', 'AHNAK', 'AHNAK2', 'AHSA1', 'AHSA2P', 'AICDA', 'AIDA', 'AIFM1', 'AIM2', 'AK1', 'AK3', 'AK4', 'AK7', 'AK8', 'AK9', 'AKAP13', 'AKAP3', 'AKAP5', 'AKAP6', 'AKAP7', 'AKAP8', 'AKAP9', 'AKIRIN1', 'AKIRIN2', 'AKNA', 'AKR1A1', 'AKR1B10', 'AKR7A3', 'AKT1', 'AKT2', 'ALDH16A1', 'ALDH1A1', 'ALDH1A3', 'ALDH1B1', 'ALDH3A2', 'ALDH3B1', 'ALDH7A1', 'ALDOA', 'ALG1', 'ALG13', 'ALG14', 'ALG2', 'ALG5', 'ALG6', 'ALKBH1', 'ALKBH2', 'ALKBH3', 'ALKBH5', 'ALKBH6', 'ALKBH7', 'ALKBH8', 'ALOX12-AS1', 'ALOX5AP', 'ALPK2', 'ALYREF', 'AMBRA1', 'AMD1', 'AMDHD1', 'AMER1', 'AMER2', 'AMMECR1L', 'AMOT', 'AMPD3', 'AMZ2', 'ANAPC10', 'ANAPC13', 'ANAPC15', 'ANAPC2', 'ANAPC4', 'ANAPC5', 'ANAPC7', 'ANG', 'ANGPTL1', 'ANK1', 'ANK2', 'ANK3', 'ANKDD1A', 'ANKDD1B', 'ANKHD1-EIF4EBP3', 'ANKMY1', 'ANKRD10', 'ANKRD12', 'ANKRD13A', 'ANKRD13C', 'ANKRD16', 'ANKRD18A', 'ANKRD18B', 'ANKRD33B', 'ANKRD37', 'ANKRD39', 'ANKRD40', 'ANKRD44', 'ANKRD45', 'ANKRD50', 'ANKRD53', 'ANKRD54', 'ANKRD6', 'ANKRD7', 'ANKRD9', 'ANKS1B', 'ANKS3', 'ANKZF1', 'ANO4.1', 'ANO4.3', 'ANO6', 'ANP32E', 'ANTKMT', 'ANTXR2', 'ANXA1', 'ANXA11', 'ANXA3', 'ANXA5', 'ANXA6', 'ANXA7', 'AOC1', 'AP1B1', 'AP1M2', 'AP2A1', 'AP2A2', 'AP2A2.3', 'AP2A2.6', 'AP2S1', 'AP4E1', 'AP4M1', 'AP4S1', 'AP5B1', 'AP5S1', 'APAF1', 'APBB1', 'APBB3', 'APC', 'APC2', 'APEH', 'APEX1', 'APH1A', 'APIP', 'APOBEC3H', 'APOBR', 'APOF', 'APOH', 'APOL2', 'APOL4', 'APOM', 'APOM.1', 'APOM.3', 'APOM.4', 'APOM.6', 'APOM.7', 'APRT', 'APTR', 'ARAF', 'ARAP2', 'AREL1', 'ARF3', 'ARF4', 'ARF5', 'ARFGAP1', 'ARFGAP2', 'ARFGEF3', 'ARFIP1', 'ARFIP2', 'ARFRP1', 'ARGLU1', 'ARHGAP1', 'ARHGAP18', 'ARHGAP22', 'ARHGAP29-AS1', 'ARHGAP35', 'ARHGDIA', 'ARHGEF1', 'ARHGEF2', 'ARHGEF26', 'ARHGEF26.2', 'ARHGEF28', 'ARHGEF3', 'ARHGEF37', 'ARHGEF5', 'ARHGEF6', 'ARID3A', 'ARID3B', 'ARID4A', 'ARIH2', 'ARL13B', 'ARL15', 'ARL16', 'ARL17A', 'ARL17A.1', 'ARL17A.12', 'ARL17A.13', 'ARL17A.4', 'ARL17A.5', 'ARL17A.8', 'ARL17A.9', 'ARL2-SNX15', 'ARL3', 'ARL6IP1', 'ARL9', 'ARMC1', 'ARMC4', 'ARMC6', 'ARMC8', 'ARMC9', 'ARMCX4', 'ARMCX5', 'ARMH1', 'ARMH3', 'ARMT1', 'ARPC3', 'ARPC4', 'ARPC5', 'ARPC5L', 'ARPIN', 'ARPIN-AP3S2', 'ARRDC1', 'ARRDC1-AS1', 'ARRDC2', 'ARRDC3', 'ARRDC3-AS1', 'ARRDC4', 'ARSJ', 'ARSK', 'ARTN', 'ARV1', 'AS3MT', 'ASAP3', 'ASB1', 'ASB13', 'ASB14', 'ASB16-AS1', 'ASB4', 'ASB6', 'ASB9', 'ASF1B', 'ASH1L', 'ASH1L-AS1', 'ASH2L', 'ASMTL', 'ASNS', 'ASNSD1', 'ASPHD1', 'ASPSCR1', 'ATAD1', 'ATAD2B', 'ATAD3A', 'ATAD3B', 'ATE1', 'ATE1-AS1', 'ATF2', 'ATF4', 'ATF5', 'ATF6B.10', 'ATF6B.14', 'ATF6B.2', 'ATF6B.6', 'ATG101', 'ATG13', 'ATG14', 'ATG16L2', 'ATG2A', 'ATG4B', 'ATG4C', 'ATG7', 'ATG9A', 'ATMIN', 'ATP11C', 'ATP2A1-AS1', 'ATP2A2', 'ATP2B1', 'ATP2B1-AS1', 'ATP2B3', 'ATP2C1', 'ATP2C2-AS1', 'ATP5F1A', 'ATP5F1B', 'ATP5F1C', 'ATP5IF1', 'ATP5MC1', 'ATP5MC2', 'ATP5MC3', 'ATP5MD', 'ATP5MF-PTCD1', 'ATP5PB', 'ATP5PF', 'ATP5PO', 'ATP6', 'ATP6AP1L', 'ATP6V0A2', 'ATP6V0B', 'ATP6V0D1', 'ATP6V0E2', 'ATP6V1B1', 'ATP6V1E1', 'ATP6V1G1', 'ATP6V1H', 'ATP8', 'ATP9B', 'ATP9B.3', 'ATP9B.6', 'ATPSCKMT', 'ATR', 'ATRIP', 'ATRN', 'ATXN10', 'ATXN7', 'ATXN7L1', 'ATXN7L2', 'ATXN7L3', 'AUNIP', 'AURKAIP1', 'AURKC', 'AVPI1', 'AXIN1', 'AXIN2', 'AZIN2', 'B3GALNT1', 'B3GALNT2', 'B3GALT6', 'B3GAT1-DT', 'B3GNT2', 'B3GNT9', 'B9D1', 'BABAM1', 'BABAM2', 'BACH1', 'BAD', 'BAG1', 'BAG2', 'BAG5', 'BAG6.16', 'BAG6.2', 'BAG6.23', 'BAG6.30', 'BAG6.37', 'BAG6.44', 'BAG6.9', 'BAIAP2-DT', 'BAK1', 'BANP', 'BAP1', 'BASP1', 'BASP1-AS1', 'BATF3', 'BAX', 'BAZ1A', 'BAZ1B', 'BAZ2A', 'BAZ2B', 'BAZ2B.1', 'BAZ2B.2', 'BAZ2B.3', 'BBIP1', 'BBOF1', 'BBS1', 'BBS4', 'BBS9', 'BBX', 'BCAN', 'BCAR3', 'BCAS2', 'BCAS3', 'BCAS4', 'BCCIP', 'BCDIN3D-AS1', 'BCKDHB', 'BCL11A', 'BCL2L12', 'BCL2L13', 'BCL3', 'BCL6', 'BCL7B', 'BCL9L', 'BCLAF1', 'BCORL1', 'BCS1L', 'BDNF', 'BDNF-AS', 'BECN1', 'BEND3', 'BET1', 'BET1L', 'BHLHB9', 'BHLHE40', 'BICD1', 'BICD2', 'BIN3', 'BIRC2', 'BLMH', 'BLOC1S4', 'BLVRA', 'BMP2K', 'BMP8A', 'BMPR1A', 'BMPR1B', 'BNC2', 'BNC2-AS1', 'BNIP1', 'BNIP2', 'BNIP3', 'BNIP3L', 'BOD1L1', 'BOLA2-SMG1P6', 'BOLA2.1', 'BOLA2.3', 'BORCS7', 'BORCS8', 'BPGM', 'BPHL', 'BPTF', 'BRD8', 'BRD9', 'BRF1', 'BRI3BP', 'BRINP1', 'BRIP1', 'BRIX1', 'BRMS1', 'BRMS1L', 'BROX', 'BRPF1', 'BRSK2', 'BRWD1', 'BRWD1-AS2', 'BRWD3', 'BSDC1', 'BST1', 'BTAF1', 'BTBD1', 'BTBD11', 'BTBD8', 'BTBD9', 'BTC', 'BTF3L4', 'BTG1', 'BTG3', 'BTG3.2', 'BTN2A1', 'BUD23', 'BUD31', 'BYSL', 'C10orf126', 'C10orf143', 'C10orf88', 'C11orf24', 'C11orf49', 'C11orf58', 'C11orf71', 'C11orf91', 'C11orf94', 'C11orf95', 'C11orf98', 'C12orf29', 'C12orf43', 'C12orf45', 'C12orf65', 'C12orf66', 'C12orf73', 'C12orf76', 'C14orf119', 'C15orf40', 'C15orf61', 'C16orf46', 'C16orf72', 'C16orf86', 'C16orf91', 'C17orf67', 'C17orf75', 'C17orf97', 'C18orf32', 'C18orf54', 'C19orf38', 'C19orf47', 'C19orf48', 'C19orf53', 'C19orf54', 'C19orf73', 'C1QBP', 'C1QTNF1', 'C1QTNF5', 'C1RL', 'C1orf109', 'C1orf122', 'C1orf131', 'C1orf159', 'C1orf198', 'C1orf216', 'C1orf226', 'C1orf35', 'C1orf53', 'C20orf194', 'C20orf27', 'C20orf96', 'C22orf24', 'C22orf31', 'C2orf42', 'C2orf66', 'C2orf72', 'C2orf74', 'C2orf76', 'C2orf88', 'C3orf33', 'C3orf35', 'C3orf38', 'C4orf3', 'C4orf36', 'C4orf46', 'C4orf47', 'C5orf22', 'C5orf24', 'C6orf120', 'C6orf136.11', 'C6orf136.15', 'C6orf136.3', 'C6orf136.7', 'C6orf223', 'C6orf226', 'C7orf31', 'C7orf50', 'C7orf61', 'C7orf69', 'C8orf33', 'C8orf37', 'C8orf58', 'C8orf82', 'C8orf88', 'CA11', 'CA2', 'CA5BP1', 'CA9', 'CAAP1', 'CAB39', 'CAB39L', 'CABCOCO1', 'CABP1', 'CACNA2D1-AS1', 'CACNB1', 'CACYBP', 'CADM2', 'CALCOCO1', 'CALHM2', 'CALM2', 'CALR', 'CAMK1', 'CAMK1D', 'CAMK2G', 'CAMKK2', 'CAMKMT', 'CAMSAP1', 'CAMSAP2', 'CAMTA1', 'CAND1', 'CANT1', 'CANX', 'CAP2', 'CAPN10', 'CAPNS1', 'CAPNS2', 'CAPS2', 'CAPZA1', 'CARD6', 'CARD8', 'CARF', 'CARM1', 'CARMIL1', 'CARNMT1', 'CARS1-AS1', 'CARS1-AS1.1', 'CARS1-AS1.2', 'CARS1-AS1.3', 'CARS2', 'CASD1', 'CASKIN2', 'CASTOR2', 'CASTOR3', 'CATSPER3', 'CAV1', 'CAVIN4', 'CBFA2T2', 'CBFB', 'CBL', 'CBLN2', 'CBS', 'CBSL', 'CBWD1', 'CBX3P2', 'CBX5', 'CBX6', 'CBY3', 'CC2D1A', 'CC2D2A', 'CCAR1', 'CCAR2', 'CCDC102A', 'CCDC106', 'CCDC12', 'CCDC137', 'CCDC138', 'CCDC14', 'CCDC146', 'CCDC151', 'CCDC159', 'CCDC163', 'CCDC168', 'CCDC169', 'CCDC169-SOHLH2', 'CCDC175', 'CCDC183-AS1', 'CCDC190', 'CCDC24', 'CCDC25', 'CCDC28A', 'CCDC40', 'CCDC43', 'CCDC57', 'CCDC59', 'CCDC66', 'CCDC7', 'CCDC71', 'CCDC71L', 'CCDC74A', 'CCDC74B', 'CCDC78', 'CCDC8', 'CCDC82', 'CCDC85A', 'CCDC85B', 'CCDC87', 'CCDC90B', 'CCER2', 'CCHCR1.13', 'CCHCR1.18', 'CCHCR1.23', 'CCHCR1.3', 'CCHCR1.8', 'CCL2', 'CCL26', 'CCN1', 'CCN2', 'CCN6', 'CCNB3P1', 'CCNC', 'CCNE1', 'CCNE2', 'CCNG2', 'CCNH', 'CCNJ', 'CCNJL', 'CCNL1', 'CCNL2', 'CCNO', 'CCNP', 'CCNQ', 'CCP110', 'CCS', 'CCT2', 'CCT5P1', 'CCT6B', 'CCZ1P', 'CD160', 'CD2BP2', 'CD38', 'CD44', 'CD58', 'CD81-AS1', 'CDC123', 'CDC14A', 'CDC14B', 'CDC16', 'CDC20B', 'CDC23', 'CDC25A', 'CDC26', 'CDC37L1', 'CDC42', 'CDC42BPG', 'CDC42EP2', 'CDC42SE1', 'CDC45', 'CDC5L', 'CDC73', 'CDCA2', 'CDCA4', 'CDK10', 'CDK11B', 'CDK16', 'CDK18', 'CDK20', 'CDK2AP2', 'CDK4', 'CDK5R2', 'CDK5RAP3', 'CDK6-AS1', 'CDK7.1', 'CDK7.3', 'CDK9', 'CDKL1', 'CDKL3', 'CDKL5', 'CDKN1C.1', 'CDKN1C.3', 'CDKN2A', 'CDKN2AIPNL', 'CDKN2D', 'CDNF', 'CDV3', 'CDYL', 'CEBPA', 'CEBPD', 'CEBPZ', 'CEL', 'CENPB', 'CENPF', 'CENPH', 'CENPK', 'CENPN', 'CENPP', 'CENPT', 'CENPU', 'CEP104', 'CEP135', 'CEP152', 'CEP170B', 'CEP250', 'CEP43', 'CEP57', 'CEP70', 'CEP83-DT', 'CEPT1', 'CERS5', 'CES2', 'CETN3', 'CFAP20DC', 'CFAP300', 'CFAP410', 'CFAP46', 'CFAP53', 'CFAP58', 'CFAP70', 'CFAP91', 'CFAP94', 'CFDP1', 'CFHR1', 'CFL1P1', 'CFLAR', 'CGGBP1', 'CGN', 'CHAC2', 'CHAF1B', 'CHAMP1', 'CHCHD1', 'CHCHD5', 'CHCHD7', 'CHD2', 'CHD6', 'CHD9', 'CHERP', 'CHM', 'CHML', 'CHMP1A', 'CHMP2B', 'CHMP4B', 'CHMP4C', 'CHMP5', 'CHMP6', 'CHN1', 'CHORDC1', 'CHPF2', 'CHRAC1', 'CHRM5', 'CHRNA1', 'CHROMR', 'CHST15', 'CHST2', 'CHST4', 'CHSY1', 'CHUK', 'CHURC1', 'CIAPIN1', 'CIBAR1', 'CIITA', 'CILP2', 'CIRBP', 'CISD3', 'CITED4', 'CIZ1', 'CKLF-CMTM1', 'CKMT1A', 'CKMT2-AS1', 'CLASP1', 'CLASRP', 'CLBA1', 'CLCC1', 'CLCN4', 'CLCN5', 'CLCN7', 'CLDN1', 'CLDN12', 'CLDN9', 'CLDND2', 'CLEC11A', 'CLEC16A', 'CLEC18B', 'CLEC4A', 'CLEC4F', 'CLIC2', 'CLINT1', 'CLIP1', 'CLK1', 'CLK3', 'CLK4', 'CLN6', 'CLNS1A', 'CLP1', 'CLPX', 'CLSPN', 'CLTCL1', 'CLUH', 'CLYBL', 'CMC2', 'CMIP', 'CMPK1', 'CMPK2', 'CMTM1', 'CMTM6', 'CMTR1', 'CNBP', 'CNDP2', 'CNGA1', 'CNGA4', 'CNN2', 'CNNM2', 'CNNM3', 'CNNM4', 'CNOT11', 'CNOT2', 'CNOT6L', 'CNOT8', 'CNP', 'CNPY3', 'CNST', 'CNTF', 'CNTLN', 'COA4', 'COA6-AS1', 'COA7', 'COG2', 'COG5', 'COG6', 'COG8', 'COL17A1', 'COLGALT1', 'COLQ', 'COMMD2', 'COMMD3', 'COMMD4', 'COMMD5', 'COMTD1', 'COPG2', 'COPS3', 'COPS4', 'COPS5', 'COPS6', 'COPS7A', 'COPZ2', 'COQ10B', 'COQ3', 'COQ4', 'COQ7', 'COQ8A', 'COQ9', 'CORO1B', 'CORO1C', 'CORO2A', 'CORO7', 'COSMOC', 'COX1', 'COX10', 'COX10-AS1', 'COX11', 'COX14', 'COX18', 'COX2', 'COX3', 'COX5A', 'COX7A2', 'COX7A2L', 'CP', 'CPA2', 'CPLANE2', 'CPOX', 'CPSF4', 'CPSF6', 'CPT1A', 'CPT1C', 'CPT2', 'CPXM1', 'CRAT', 'CRCP', 'CREB1', 'CREB3L2', 'CREB3L4', 'CREB5', 'CREBBP', 'CREBRF', 'CREBZF', 'CREG2', 'CRELD1', 'CRELD2', 'CRISPLD1', 'CRK', 'CRLS1', 'CRPPA', 'CRY1', 'CRYBG2', 'CRYBG3', 'CRYL1', 'CRYM', 'CRYZ', 'CRYZL1', 'CS', 'CSDC2', 'CSGALNACT2', 'CSNK1D', 'CSNK1G2', 'CSNK2A1', 'CSNK2B.11', 'CSNK2B.17', 'CSNK2B.23', 'CSNK2B.29', 'CSNK2B.5', 'CSRNP3', 'CSRP2', 'CSTF1', 'CSTF2T', 'CSTF3', 'CT69', 'CTBP1', 'CTBP2', 'CTC-338M12.4', 'CTCF', 'CTDNEP1', 'CTDP1', 'CTDP1.2', 'CTDSP2', 'CTF1', 'CTNNAL1', 'CTNNBIP1', 'CTNS', 'CTPS1', 'CTSO', 'CTTN', 'CTU2', 'CTXN1', 'CUBN', 'CUEDC1', 'CUEDC2', 'CUL1', 'CUL2', 'CUL3', 'CUL5', 'CUTC', 'CWF19L1', 'CX3CL1', 'CXCR4', 'CXorf38', 'CXorf56', 'CYB561D2', 'CYB561D2.2', 'CYB5B', 'CYB5R4', 'CYBC1', 'CYC1', 'CYP19A1', 'CYP1A1', 'CYP1B1', 'CYP20A1', 'CYP26A1', 'CYP26B1', 'CYP2B7P', 'CYP2E1', 'CYP3A5', 'CYP4V2', 'CYP51A1', 'CYREN', 'CYSTM1', 'CYTB', 'CYTH2', 'CYTH4', 'CYYR1-AS1', 'CZIB', 'D2HGDH', 'DACH1', 'DAO', 'DAP', 'DAP3', 'DAPK3', 'DARS1', 'DARS1-AS1', 'DAZAP1', 'DAZAP2', 'DBI', 'DBN1', 'DBR1', 'DCAF1', 'DCAF11', 'DCAF13', 'DCAF16', 'DCAF17', 'DCAF4', 'DCAF6', 'DCAF8', 'DCHS1', 'DCK', 'DCLRE1B', 'DCP2', 'DCTN2', 'DCTN3', 'DCTN6', 'DCTPP1', 'DCUN1D2', 'DCUN1D4', 'DCUN1D5', 'DDA1', 'DDB1', 'DDB2', 'DDHD1', 'DDHD2', 'DDIT3', 'DDIT4', 'DDO', 'DDX1', 'DDX10', 'DDX17', 'DDX19A', 'DDX19B', 'DDX20', 'DDX21', 'DDX24', 'DDX24.1', 'DDX24.2', 'DDX24.3', 'DDX28', 'DDX31', 'DDX39B.11', 'DDX39B.19', 'DDX39B.27', 'DDX39B.3', 'DDX39B.35', 'DDX39B.43', 'DDX39B.51', 'DDX39B.59', 'DDX3X', 'DDX42', 'DDX43', 'DDX47', 'DDX5', 'DDX50', 'DDX51', 'DDX54', 'DDX55', 'DDX60', 'DEAF1', 'DEAF1.2', 'DECR1', 'DECR2', 'DEDD2', 'DEF8', 'DEK', 'DELE1', 'DENND10', 'DENND11', 'DENND1B', 'DENND2A', 'DENND4B', 'DENND5B-AS1', 'DENND6B', 'DENR', 'DEPP1', 'DERA', 'DERL2', 'DERL3', 'DEXI', 'DFFBP1', 'DGCR11', 'DGCR6', 'DGKQ', 'DGLUCY', 'DHCR7', 'DHDDS', 'DHFR2', 'DHODH', 'DHPS', 'DHRS1', 'DHRS11', 'DHRS11.1', 'DHRS11.2', 'DHRS11.3', 'DHRS12', 'DHRS13', 'DHRS3', 'DHRS7B', 'DHTKD1', 'DHX15', 'DHX16.15', 'DHX16.21', 'DHX16.27', 'DHX16.3', 'DHX16.9', 'DHX29', 'DHX30', 'DHX33', 'DHX35', 'DHX36', 'DHX36.2', 'DHX37', 'DHX57', 'DHX58', 'DIABLO', 'DIMT1', 'DIO2', 'DIP2B', 'DIPK1A', 'DIPK2A', 'DIS3', 'DISP1', 'DISP2', 'DKC1', 'DKK1', 'DLAT', 'DLD', 'DLG1', 'DLG3', 'DLG4', 'DLST', 'DMAC2L', 'DMAP1', 'DMTF1', 'DNAAF2', 'DNAAF4-CCPG1', 'DNAH14', 'DNAI4', 'DNAJA2', 'DNAJA3.1', 'DNAJB11', 'DNAJB12', 'DNAJB2', 'DNAJB5', 'DNAJB6', 'DNAJB9', 'DNAJC11', 'DNAJC13', 'DNAJC15', 'DNAJC2', 'DNAJC22', 'DNAJC24', 'DNAJC25', 'DNAJC3', 'DNAJC3-DT', 'DNAJC30', 'DNAJC8', 'DNAJC9-AS1.1', 'DNAJC9-AS1.3', 'DNASE1', 'DNASE1L2', 'DNHD1', 'DNLZ', 'DNM1L', 'DNMT3A', 'DNPEP', 'DNPH1', 'DNTTIP2', 'DOCK7', 'DOHH', 'DOK1', 'DOK3', 'DOLK', 'DOP1B', 'DOT1L', 'DPF2', 'DPH1', 'DPH2', 'DPH3', 'DPH7', 'DPM1', 'DPM2', 'DPP3', 'DPP8', 'DPP9', 'DPY19L2P2', 'DPY30', 'DPYSL2', 'DPYSL4', 'DRAXIN', 'DRG1', 'DRG2', 'DRP2', 'DSCC1', 'DSCR9', 'DSEL', 'DSP', 'DST', 'DTD1', 'DTD2', 'DTWD2', 'DTX2', 'DTX2.2', 'DTX2P1-UPK3BP1-PMS2P11', 'DTX4', 'DUBR', 'DUS1L', 'DUS2', 'DUS3L', 'DUSP11', 'DUSP12', 'DUSP14', 'DUSP14.2', 'DUSP18', 'DUSP19', 'DUSP23', 'DUSP3', 'DUSP7', 'DUXAP8', 'DVL2', 'DYNC1H1', 'DYNC1LI1', 'DYNC2I2', 'DYNC2LI1', 'DYNLL1', 'DYNLL2', 'DYNLT2B', 'DZIP1L', 'DZIP3', 'E2F1', 'E2F2', 'E2F3', 'E2F4', 'E4F1', 'EBLN3P', 'EBPL', 'ECD', 'ECH1', 'ECHDC1', 'ECHDC3', 'ECHS1', 'ECI1', 'ECI2-DT', 'ECSIT', 'EDEM1', 'EEF1AKMT1', 'EEF1AKMT2', 'EEF1AKNMT', 'EEF1E1', 'EEF2KMT', 'EFCAB2', 'EFCAB7', 'EFL1', 'EFNA1', 'EFNA3', 'EFNA4', 'EFNB2', 'EGFR', 'EGLN1', 'EHD2', 'EHMT1', 'EHMT2.1', 'EHMT2.13', 'EHMT2.14', 'EHMT2.19', 'EHMT2.2', 'EHMT2.20', 'EHMT2.25', 'EHMT2.26', 'EHMT2.31', 'EHMT2.32', 'EHMT2.7', 'EHMT2.8', 'EID1', 'EID2', 'EIF1AD', 'EIF1AX', 'EIF1B', 'EIF1B-AS1', 'EIF2B1', 'EIF2B3', 'EIF2B4', 'EIF2S1', 'EIF2S2', 'EIF3A', 'EIF3E', 'EIF3G', 'EIF3I', 'EIF3M', 'EIF4A1', 'EIF4A3', 'EIF4E', 'EIF4EBP3', 'EIF5A', 'EIF5A2', 'EIF5AL1', 'EIF6', 'ELAC1', 'ELAC2', 'ELAVL2', 'ELFN1-AS1', 'ELL2', 'ELMOD3', 'ELOA', 'ELOC', 'ELOF1', 'ELOVL1', 'ELOVL7', 'ELP3', 'ELP6', 'EMBP1', 'EMC6', 'EMC8', 'EMD', 'EME2', 'EMG1', 'EML3', 'ENAH', 'ENC1', 'ENDOG', 'ENGASE', 'ENHO', 'ENO1', 'ENO2', 'ENO4', 'ENOPH1', 'ENOX2', 'ENSA', 'EOGT', 'EOLA2', 'EP400P1', 'EPB41L4B', 'EPG5', 'EPHA5-AS1', 'EPHB3', 'EPM2A', 'EPM2AIP1', 'EPN2', 'EPOR', 'EPS15L1', 'ERCC2', 'ERCC4', 'ERCC6L2', 'ERCC8', 'ERF', 'ERG', 'ERH', 'ERI3', 'ERICH6-AS1', 'ERLIN1', 'ERMN', 'ERMP1', 'ERO1A', 'ERO1B', 'ERP44', 'ESF1', 'ESM1', 'ESRRA', 'ESYT2', 'ETAA1', 'ETF1', 'ETFA', 'ETFDH', 'ETFRF1', 'ETS2', 'ETV7', 'EVI5', 'EVI5L', 'EWSR1', 'EXD3', 'EXO1', 'EXO5', 'EXOC2', 'EXOC3-AS1', 'EXOC6', 'EXOC7', 'EXOC8', 'EXOG', 'EXOSC1', 'EXOSC10', 'EXOSC2', 'EXOSC4', 'EXOSC6', 'EXOSC7', 'EXOSC8', 'EXOSC9', 'EXT1', 'EXTL3', 'EYA3', 'EZH2', 'EZR', 'F8', 'F8A1', 'F8A3', 'FAAP100', 'FADD', 'FADS1', 'FAHD2CP', 'FAM111B', 'FAM117A', 'FAM117B', 'FAM118B', 'FAM120A', 'FAM120B', 'FAM120C', 'FAM122A', 'FAM126A', 'FAM133B', 'FAM135A', 'FAM135B', 'FAM13A', 'FAM13A-AS1', 'FAM151B', 'FAM156B', 'FAM160A1', 'FAM160A2', 'FAM160B2', 'FAM161B', 'FAM162A', 'FAM167A-AS1', 'FAM168A', 'FAM168B', 'FAM169A', 'FAM171A2', 'FAM174A', 'FAM187A', 'FAM189B', 'FAM193B', 'FAM200A', 'FAM200B', 'FAM204A', 'FAM20A', 'FAM20B', 'FAM20C.1', 'FAM20C.3', 'FAM210B', 'FAM214B', 'FAM215A', 'FAM216A', 'FAM218A', 'FAM219A', 'FAM222B', 'FAM227B', 'FAM228A', 'FAM234A', 'FAM27C', 'FAM32A', 'FAM47E', 'FAM47E-STBD1', 'FAM50B', 'FAM50B.1', 'FAM50B.2', 'FAM50B.3', 'FAM53A', 'FAM53B', 'FAM66C', 'FAM72C', 'FAM76A', 'FAM78B', 'FAM81B', 'FAM83F', 'FAM86B1', 'FAM86B2', 'FAM86B3P', 'FAM86C1P', 'FAM86C2P', 'FAM86EP', 'FAM86JP', 'FAM86KP', 'FAM98B', 'FANCA', 'FANCL', 'FARP2', 'FARSA', 'FARSB', 'FASTK', 'FASTKD1', 'FASTKD2', 'FASTKD3', 'FASTKD5', 'FAT4', 'FAXDC2', 'FBLL1', 'FBRSL1', 'FBXL12', 'FBXL15', 'FBXL2', 'FBXL20', 'FBXL5', 'FBXO15', 'FBXO21', 'FBXO30', 'FBXO30-DT', 'FBXO31', 'FBXO34', 'FBXO36', 'FBXO38', 'FBXO4', 'FBXO48', 'FBXO7', 'FBXW4', 'FBXW7', 'FBXW8', 'FBXW9', 'FCHO2', 'FCSK', 'FDFT1', 'FDPS', 'FDX1', 'FDXACB1', 'FECH', 'FEM1A', 'FEM1B', 'FEM1C', 'FEN1', 'FER', 'FERMT2', 'FEZ1', 'FEZ2', 'FGD4', 'FGD6', 'FGF11', 'FGF14-AS2', 'FGF18', 'FGF2', 'FGF5', 'FGFBP3', 'FH', 'FHDC1', 'FHL2', 'FHL3', 'FHOD1', 'FIBIN', 'FIBP', 'FICD', 'FIP1L1', 'FIS1', 'FJX1', 'FKBP2', 'FKBP3', 'FKBP4', 'FKBP5', 'FKRP', 'FKTN', 'FLACC1', 'FLAD1', 'FLJ13224', 'FLJ31104', 'FLJ31356', 'FLNC', 'FLOT1.11', 'FLOT1.17', 'FLOT1.23', 'FLOT1.29', 'FLOT1.5', 'FLT4', 'FLVCR1-DT', 'FLYWCH2', 'FMC1-LUC7L2', 'FMNL1', 'FMNL2', 'FN3KRP', 'FNBP1', 'FNBP1L', 'FNBP4', 'FNDC3B', 'FNDC8', 'FNTA', 'FNTB', 'FOLR3', 'FOS', 'FOSL2', 'FOXC1', 'FOXD1', 'FOXD2-AS1', 'FOXD4L1', 'FOXF1', 'FOXJ2', 'FOXK2', 'FOXO4', 'FOXRED1', 'FOXRED2', 'FPGS', 'FRAT1', 'FRAT2', 'FRMD1', 'FRMD6-AS1', 'FRRS1', 'FRS3', 'FRYL', 'FRZB', 'FSD1', 'FSIP2', 'FTCDNL1', 'FTX', 'FUBP1', 'FUBP3', 'FUCA1', 'FUCA2', 'FUNDC1', 'FUS', 'FUT10', 'FUT11', 'FXN', 'FYB2', 'FZD4-DT', 'FZD5', 'FZD6', 'FZD9', 'G3BP2', 'G6PC3', 'GAB1', 'GABPB1', 'GAD2', 'GADD45A', 'GAK', 'GALE', 'GALK1', 'GALNT12', 'GALNT2', 'GALNTL6', 'GALT', 'GAPDH', 'GAPVD1', 'GAR1', 'GARNL3', 'GARS1', 'GART', 'GART.2', 'GAS1', 'GATAD2A', 'GATC', 'GATD1', 'GBE1', 'GBP1', 'GBP4', 'GCA', 'GCAT', 'GCFC2', 'GCH1', 'GCLC', 'GCNA', 'GCNT3', 'GCSH', 'GDAP1', 'GDPD1', 'GDPD3', 'GDPGP1', 'GEMIN4', 'GEMIN5', 'GEMIN8', 'GFM1', 'GFOD1', 'GFRA2', 'GFUS', 'GFUS.1', 'GFUS.2', 'GFUS.3', 'GGA1', 'GGA2', 'GGACT', 'GGCT', 'GGPS1', 'GGTA2P', 'GHITM', 'GID4', 'GINS1', 'GINS2', 'GINS3', 'GINS4', 'GIPC1', 'GJD3', 'GK', 'GKAP1', 'GLB1L', 'GLE1', 'GLI1', 'GLIPR2', 'GLIS1', 'GLMN', 'GLO1', 'GLOD4', 'GLRX2', 'GLRX5', 'GLYCTK', 'GLYR1', 'GMEB1', 'GMFB', 'GMPR', 'GMPS', 'GNA11', 'GNAI1', 'GNB2', 'GNB5', 'GNG10', 'GNG12-AS1', 'GNL2', 'GNL3', 'GNL3L', 'GNPDA2', 'GNPNAT1', 'GNRH1', 'GOLGA1', 'GOLGA2P7', 'GOLGA3', 'GOLGA6L22', 'GOLGA6L22.2', 'GOLGB1', 'GOLPH3', 'GOLPH3L', 'GORAB', 'GORASP2', 'GOSR1', 'GOSR2', 'GOT1', 'GOT2', 'GOT2P3', 'GPALPP1', 'GPANK1.12', 'GPANK1.17', 'GPANK1.2', 'GPANK1.7', 'GPATCH2', 'GPATCH3', 'GPATCH4', 'GPATCH8', 'GPBAR1', 'GPBP1', 'GPCPD1', 'GPD1L', 'GPI', 'GPI.1', 'GPI.2', 'GPI.3', 'GPKOW', 'GPN2', 'GPR135', 'GPR137', 'GPR137B', 'GPR137C', 'GPR146', 'GPR150', 'GPR155', 'GPR160', 'GPR180', 'GPR199P', 'GPR3', 'GPR37', 'GPR83', 'GPR89A', 'GPRACR', 'GPRASP2', 'GPS1', 'GPSM1', 'GPSM2', 'GPT2', 'GPX1', 'GPX4', 'GPX8', 'GRAMD4P3', 'GRB7', 'GRHPR', 'GRK4', 'GRK5', 'GRM2', 'GRWD1', 'GS1-124K5.11', 'GS1-124K5.4', 'GS1-204I12.4', 'GSAP', 'GSDMD', 'GSDME', 'GSE1', 'GSKIP', 'GSPT1', 'GSPT2', 'GSR', 'GSS', 'GSTA4', 'GSTK1', 'GSTM4', 'GSTO2', 'GSTP1', 'GSTZ1', 'GTF2A1', 'GTF2A2', 'GTF2B', 'GTF2F2', 'GTF2H2', 'GTF2H2.1', 'GTF2H2.3', 'GTF2H2.4', 'GTF2H2.6', 'GTF2H2.7', 'GTF2H2C', 'GTF2H3', 'GTF2H5', 'GTF2IP12', 'GTF2IRD1', 'GTF3C2', 'GTF3C2-AS1', 'GTF3C4', 'GTF3C5', 'GTF3C6', 'GTPBP1', 'GTPBP10', 'GTPBP4', 'GTPBP6', 'GTPBP8', 'GUSBP1.1', 'GUSBP1.4', 'GUSBP1.7', 'GUSBP11', 'GXYLT2', 'GYG1', 'GYG2', 'GYS1', 'GZF1', 'H1-0', 'H1-10', 'H2AB1', 'H2AC15', 'H2AC6', 'H2AZ1', 'H2BC6', 'H2BC8', 'H3-3A', 'H3-3B', 'H3C6', 'H6PD', 'HABP4', 'HACD1', 'HACL1', 'HAGHL', 'HAMP', 'HAT1', 'HAUS5', 'HAUS7', 'HBE1', 'HBG2', 'HBP1', 'HCCS', 'HCFC2', 'HCG23', 'HCST', 'HDAC2', 'HDAC3', 'HDAC6', 'HDDC2', 'HDHD2', 'HDHD3', 'HDHD5-AS1', 'HEATR3', 'HEATR5B', 'HEATR6', 'HECA', 'HECTD2', 'HECTD3', 'HECTD4', 'HELB', 'HELLS', 'HELZ', 'HERC2P7', 'HERC2P9.1', 'HERC2P9.3', 'HERC4', 'HERC5', 'HERC6', 'HERPUD1', 'HES4', 'HES6', 'HESX1', 'HEXD', 'HGH1', 'HGSNAT', 'HHIP-AS1', 'HID1', 'HIF1A', 'HIF1AN', 'HIF3A', 'HIGD1A', 'HIGD2A', 'HIKESHI', 'HILPDA', 'HINFP', 'HINT2', 'HIP1R', 'HIRA', 'HIVEP2', 'HK1', 'HK2', 'HKDC1', 'HLA-DRB1', 'HLA-F-AS1.13', 'HLA-F-AS1.18', 'HLA-F-AS1.23', 'HLA-F-AS1.3', 'HLA-F-AS1.8', 'HLA-J', 'HLA-K', 'HLA-V', 'HLA-V.12', 'HLA-V.16', 'HLA-V.20', 'HLA-V.24', 'HLA-V.28', 'HLA-V.32', 'HLA-V.36', 'HLA-V.4', 'HLA-V.40', 'HLA-V.44', 'HLA-V.48', 'HLA-V.52', 'HLA-V.56', 'HLA-V.60', 'HLA-V.8', 'HLCS', 'HLF', 'HM13-AS1', 'HMCES', 'HMGB1', 'HMGB1P31', 'HMGB3', 'HMGB3P22', 'HMGCR', 'HMGCS1', 'HMGN1', 'HMGN2', 'HMGN3', 'HMGN3-AS1', 'HMGN5', 'HMGXB3', 'HMGXB4', 'HMOX2', 'HNRNPA0', 'HNRNPAB', 'HNRNPC', 'HNRNPD', 'HNRNPDL', 'HNRNPF', 'HNRNPH2', 'HNRNPH3', 'HNRNPR', 'HNRNPUL1', 'HOMER1', 'HOMEZ', 'HOOK1', 'HP1BP3', 'HPCAL1', 'HPF1', 'HPN', 'HPS1', 'HPS3', 'HPS4', 'HPS6', 'HR', 'HRAT17', 'HRCT1', 'HRH1', 'HROB', 'HS1BP3', 'HSBP1L1', 'HSD17B10', 'HSD17B14', 'HSD17B8', 'HSDL2', 'HSF2', 'HSF2BP', 'HSFX1', 'HSP90AA1', 'HSP90AB1', 'HSP90B1', 'HSP90B2P', 'HSPA14', 'HSPA1A', 'HSPA1A.10', 'HSPA1A.13', 'HSPA1A.15', 'HSPA1A.18', 'HSPA1A.20', 'HSPA1A.23', 'HSPA1A.3', 'HSPA1A.5', 'HSPA1A.8', 'HSPA1B', 'HSPA1B.10', 'HSPA1B.14', 'HSPA1B.15', 'HSPA1B.19', 'HSPA1B.20', 'HSPA1B.24', 'HSPA1B.4', 'HSPA1B.5', 'HSPA1B.9', 'HSPA1L.1', 'HSPA1L.2', 'HSPA1L.4', 'HSPA1L.5', 'HSPA1L.7', 'HSPA1L.8', 'HSPA2', 'HSPA4L', 'HSPA5', 'HSPA8', 'HSPA9', 'HSPB1', 'HSPB9', 'HSPD1', 'HSPE1', 'HSPE1-MOB4', 'HSPH1', 'HTD2', 'HTR7P1', 'HUNK', 'HUWE1', 'HYAL2', 'HYLS1', 'HYOU1', 'IAH1', 'IARS1', 'IBTK', 'ICA1', 'ICA1L', 'ICOSLG', 'IDE', 'IDH2', 'IDH3A', 'IDH3B', 'IDH3G', 'IDI1', 'IDI2', 'IDI2-AS1', 'IDNK', 'IER3IP1', 'IFI27L1', 'IFI35', 'IFITM10', 'IFITM10.2', 'IFNAR2.1', 'IFNAR2.3', 'IFNLR1', 'IFRD1', 'IFRD2', 'IFT122', 'IFT22', 'IFT43', 'IFT52', 'IFT57', 'IFT74', 'IFT80', 'IFT81', 'IFT88', 'IGF1R', 'IGF2R', 'IGFALS', 'IGFBP3', 'IGFL2', 'IGIP', 'IKBIP', 'IKBKG', 'IL12RB1', 'IL15RA', 'IL17RC', 'IL19', 'IL21R', 'IL24', 'IL5RA', 'IL6ST', 'IL7R', 'IL9R', 'ILF2', 'ILF3', 'ILKAP', 'ILVBL', 'IMMP2L', 'IMPA1', 'IMPA2', 'IMPACT', 'INAFM2', 'INCENP', 'ING1', 'ING3', 'ING4', 'ING5', 'INO80C', 'INO80D', 'INPP1', 'INPP5B', 'INPP5J', 'INPPL1', 'INSIG2', 'INSRR', 'INTS11', 'INTS12', 'INTS14', 'INTS2', 'INTS3', 'INTS5', 'INTS6-AS1', 'INTS7', 'INVS', 'IPMK', 'IPO9', 'IPP', 'IPPK', 'IQCB1', 'IQCK', 'IQGAP1', 'IQSEC1', 'IQSEC3P2', 'IRF2', 'IRF2BP1', 'IRF2BP2', 'IRF9', 'IRS2', 'ISCA1', 'ISCU', 'ISG20L2', 'ISM2', 'ITGA2', 'ITGA6-AS1', 'ITGAE', 'ITGB1BP1', 'ITGB3BP', 'ITPA', 'ITPKB', 'ITPR1', 'IWS1', 'JADE2', 'JAGN1', 'JMJD1C', 'JMJD4', 'JMJD7', 'JPH1', 'JRKL', 'JUN', 'KANSL1-AS1.1', 'KANSL1-AS1.3', 'KANSL1L', 'KAT5', 'KAT6B', 'KAT7', 'KAT8', 'KATNAL1', 'KATNAL2', 'KBTBD11-OT1', 'KBTBD11-OT1.1', 'KBTBD11-OT1.2', 'KBTBD11-OT1.3', 'KBTBD3', 'KCNE5', 'KCNH3', 'KCNIP2', 'KCNJ2', 'KCNJ2-AS1', 'KCNK1', 'KCNK6', 'KCNN2', 'KCNQ1.1', 'KCNQ1.3', 'KCNQ1OT1', 'KCNQ3', 'KCNS3', 'KCNT2', 'KCTD10', 'KCTD11', 'KCTD13', 'KCTD16', 'KCTD17', 'KCTD21', 'KCTD3', 'KDM1A', 'KDM2B', 'KDM3A', 'KDM4B', 'KDM4C', 'KDM4D', 'KDM5B', 'KDM6B', 'KDM8', 'KEAP1', 'KERA', 'KHDC1', 'KHDRBS1', 'KHDRBS3', 'KHSRP', 'KIAA0232', 'KIAA0513', 'KIAA0586', 'KIAA0753', 'KIAA1109', 'KIAA1217', 'KIAA1549', 'KIAA1549L', 'KIAA1586', 'KIAA1614-AS1', 'KIAA1841', 'KIF14', 'KIF16B', 'KIF18A', 'KIF1B', 'KIF20B', 'KIF22', 'KIF24', 'KIF27', 'KIF3C', 'KIF5B', 'KIF5C', 'KIF5C.2', 'KIF7', 'KIFC2', 'KIZ', 'KLC2', 'KLF11', 'KLF12', 'KLF15', 'KLF16', 'KLF2', 'KLF3', 'KLF6', 'KLHDC4', 'KLHL12', 'KLHL13', 'KLHL17', 'KLHL18', 'KLHL22', 'KLHL23', 'KLHL24', 'KLHL28', 'KLHL2P1', 'KLHL3', 'KLHL42', 'KLHL5', 'KLHL6', 'KLHL9', 'KMT2A', 'KMT2C', 'KMT2E', 'KMT5B', 'KNOP1', 'KPNA1', 'KPNA3', 'KPNA4', 'KPNA4P1', 'KPNA5', 'KPNA6', 'KPTN', 'KRBA2', 'KRBOX4', 'KRT10', 'KRT35', 'KRT39', 'KRT8P41', 'KRT8P46', 'KRT8P52', 'KRTAP1-1', 'KRTAP1-5', 'KRTAP2-2.1', 'KRTAP2-3', 'KRTAP4-12', 'KRTAP5-11', 'KTI12', 'KU-MEL-3', 'KYAT3', 'L3HYPDH', 'LACTB', 'LACTB2', 'LAMTOR1', 'LAMTOR4', 'LANCL2', 'LANCL3', 'LAP3', 'LARP1B', 'LARP4B', 'LARP7', 'LAS1L', 'LASP1', 'LCA5', 'LCA5L', 'LCMT1-AS2', 'LCOR', 'LDHA', 'LDLRAP1', 'LEAP2', 'LEKR1', 'LENG8.11', 'LENG8.15', 'LENG8.3', 'LENG8.7', 'LEPROT', 'LEPROTL1', 'LETM1', 'LGALS8', 'LGALS9B', 'LGI1', 'LHFPL2', 'LHPP', 'LIF-AS1', 'LIG1', 'LIG4', 'LILRA2', 'LILRA2.4', 'LIMA1', 'LIMCH1', 'LIMD1', 'LIMS4', 'LIN54', 'LIN7B', 'LINC00173', 'LINC00189', 'LINC00205', 'LINC00324', 'LINC00472', 'LINC00562', 'LINC00622', 'LINC00632', 'LINC00638', 'LINC00662', 'LINC00667', 'LINC00847', 'LINC00853', 'LINC00863', 'LINC00886', 'LINC00933', 'LINC00937', 'LINC00968', 'LINC01003', 'LINC01011', 'LINC01089', 'LINC01128', 'LINC01137', 'LINC01184', 'LINC01203', 'LINC01259', 'LINC01269', 'LINC01270', 'LINC01291', 'LINC01354', 'LINC01376', 'LINC01465', 'LINC01480', 'LINC01486', 'LINC01534', 'LINC01547', 'LINC01554', 'LINC01562', 'LINC01586', 'LINC01587', 'LINC01588', 'LINC01669', 'LINC01670', 'LINC01693', 'LINC01711', 'LINC01722', 'LINC01726', 'LINC01775', 'LINC01778', 'LINC01783', 'LINC01833', 'LINC01914', 'LINC02004', 'LINC02021', 'LINC02057', 'LINC02085', 'LINC02104', 'LINC02166', 'LINC02202', 'LINC02210.1', 'LINC02210.3', 'LINC02236', 'LINC02260', 'LINC02337', 'LINC02361', 'LINC02465', 'LINC02473', 'LINC02482', 'LINC02511', 'LINC02525', 'LINC02530', 'LINC02538', 'LINC02574', 'LINC02585', 'LINC02593', 'LINC02612', 'LINC02614', 'LINC02615', 'LINC02724', 'LINC02742', 'LINC02805', 'LINC02817', 'LINC02844', 'LINC02873', 'LINC02882', 'LIPE-AS1', 'LIPT1', 'LIPT2', 'LKAAEAR1', 'LLPH', 'LMAN1', 'LMAN2L', 'LMBR1', 'LMBR1L', 'LMCD1', 'LMF1', 'LMLN2', 'LMNA', 'LMO1', 'LMO7-AS1', 'LNC-LBCS', 'LNCPRESS1', 'LNCSRLR', 'LNCTAM34A', 'LNP1', 'LNPEP', 'LNPK', 'LOC100129215', 'LOC100129534', 'LOC100129917', 'LOC100130691', 'LOC100131471', 'LOC100133315', 'LOC100287036', 'LOC100287042', 'LOC100287837', 'LOC100287944', 'LOC100288073', 'LOC100288846', 'LOC100379224', 'LOC100419170', 'LOC100422398', 'LOC100506083', 'LOC100506282', 'LOC100506302', 'LOC100506422', 'LOC100507053', 'LOC100507283', 'LOC100507564', 'LOC101927151', 'LOC101927314', 'LOC101927318', 'LOC101927354', 'LOC101927468', 'LOC101927571', 'LOC101927635', 'LOC101927745', 'LOC101927751', 'LOC101927811', 'LOC101927825', 'LOC101928002', 'LOC101928063', 'LOC101928069', 'LOC101928174', 'LOC101928222', 'LOC101928335', 'LOC101928336', 'LOC101928424', 'LOC101928728', 'LOC101928739', 'LOC101928782', 'LOC101929054', 'LOC101929089', 'LOC101929099', 'LOC101929227', 'LOC101929427', 'LOC101929709', 'LOC101930370', 'LOC102606465', 'LOC102723322', 'LOC102724159', 'LOC102724250', 'LOC102724532', 'LOC102724770', 'LOC102724788', 'LOC102725254', 'LOC104968399', 'LOC105369147', 'LOC105369201', 'LOC105369779', 'LOC105371267', 'LOC105371414', 'LOC105371730', 'LOC105371824', 'LOC105372482', 'LOC105375519', 'LOC105375924', 'LOC105378721', 'LOC106660606', 'LOC107984156', 'LOC107984660', 'LOC107984784', 'LOC107986114', 'LOC112268124', 'LOC112268389', 'LOC115308161', 'LOC145694', 'LOC154761', 'LOC155060', 'LOC171391', 'LOC220729', 'LOC391741', 'LOC642361', 'LOC643630', 'LOC652276', 'LOC93622', 'LONRF1', 'LOX', 'LOXL1', 'LPAL2', 'LPAR3', 'LPCAT1', 'LPCAT1.1', 'LPCAT1.2', 'LPCAT1.3', 'LPCAT2BP', 'LPCAT3', 'LPGAT1', 'LPP', 'LPP-AS2', 'LRBA', 'LRCH4', 'LRIG2-DT', 'LRMDA', 'LRP12', 'LRRC15', 'LRRC19', 'LRRC24', 'LRRC28', 'LRRC29', 'LRRC37A15P', 'LRRC37A17P', 'LRRC37A5P', 'LRRC37B', 'LRRC4', 'LRRC40', 'LRRC41', 'LRRC47', 'LRRC4C', 'LRRC61', 'LRRC66', 'LRRC73', 'LRRC8B', 'LRRC8C', 'LRRFIP1', 'LRRIQ3', 'LRRN1', 'LRRN4CL', 'LRRTM2', 'LRSAM1', 'LRWD1', 'LSM1', 'LSM12', 'LSM4', 'LSM7', 'LSM8', 'LSMEM1', 'LTB4R2', 'LTN1', 'LTO1', 'LTV1', 'LUC7L2', 'LUC7L3', 'LURAP1L', 'LYPD6', 'LYPLA1', 'LYPLA2', 'LYPLAL1', 'LYRM2', 'LYRM4', 'LYRM9', 'LYSMD1', 'LYSMD2', 'LZIC', 'LZTS1', 'LZTS3', 'M6PR', 'MACIR', 'MACROD1', 'MAFF', 'MAFTRR', 'MAGED1', 'MAGED2', 'MAGI1', 'MAGI1-IT1', 'MAGI2', 'MAGIX', 'MAGOH', 'MAGT1', 'MAIP1', 'MAJIN', 'MAK16', 'MALAT1', 'MALSU1', 'MALT1', 'MAMDC4', 'MAMLD1', 'MAN1A2', 'MAN1B1-DT', 'MAN2C1', 'MANBAL', 'MANEA', 'MANF', 'MAP11', 'MAP1A', 'MAP2K1', 'MAP2K3', 'MAP2K4', 'MAP2K5', 'MAP2K6', 'MAP3K10', 'MAP3K12', 'MAP3K2', 'MAP3K2-DT', 'MAP3K7', 'MAP3K7CL', 'MAP3K9', 'MAP4K3-DT', 'MAPK10', 'MAPK12', 'MAPK1IP1L', 'MAPK3', 'MAPK6', 'MAPK8IP1', 'MAPK8IP3', 'MAPK9', 'MAPKAPK2', 'MAPKAPK3', 'MAPKAPK5', 'MAPRE1', 'MARCHF1', 'MARCHF4', 'MARCHF5', 'MARCHF7', 'MARCHF8.1', 'MARCHF8.3', 'MARCKSL1', 'MARF1', 'MARF1.1', 'MARF1.2', 'MARF1.3', 'MARK3', 'MARS1', 'MARS2', 'MARVELD1', 'MAST1', 'MAST3', 'MASTL', 'MAT2A', 'MAT2B', 'MATN1-AS1', 'MATN3', 'MBD3', 'MBD6', 'MBLAC1', 'MBLAC2', 'MBNL1-AS1', 'MBOAT2', 'MBTD1', 'MC5R', 'MCAT', 'MCC', 'MCCC2', 'MCCC2.3', 'MCEE', 'MCF2L', 'MCIDAS', 'MCM10', 'MCM3', 'MCM3AP-AS1', 'MCM4', 'MCM6', 'MCM7', 'MCM8', 'MCM9', 'MCMBP', 'MCOLN2', 'MCPH1', 'MCRS1', 'MCTP1', 'MDH1B', 'MDH2', 'MDP1', 'ME3', 'MECR', 'MED10', 'MED11', 'MED12', 'MED16', 'MED16.2', 'MED17', 'MED18', 'MED21', 'MED22', 'MED26', 'MED27', 'MED28', 'MED29', 'MED4', 'MEF2A', 'MEF2C', 'MEGF6', 'MEMO1', 'MEN1', 'MESD', 'MET', 'METAP1', 'METAP2', 'METRN', 'METTL1', 'METTL14', 'METTL16', 'METTL22', 'METTL23', 'METTL25', 'METTL2A', 'METTL2B', 'METTL5', 'METTL7A', 'METTL8', 'MEX3B', 'MFN1', 'MFN2', 'MFRP', 'MFSD14A', 'MFSD14B', 'MFSD3', 'MFSD5', 'MFSD8', 'MGARP', 'MGAT2', 'MGC12916', 'MGRN1', 'MGST2', 'MHENCR', 'MIA3', 'MIB1', 'MIB2', 'MICAL1', 'MICOS13', 'MICU2', 'MIDEAS', 'MIEF1', 'MIEN1', 'MIF', 'MIF4GD', 'MINAR1', 'MINCR', 'MINDY1', 'MINDY2', 'MIPEP', 'MIPOL1', 'MIR17HG', 'MIR22HG.1', 'MIR3197', 'MIR4448', 'MIR663AHG', 'MIR9-1HG', 'MIS12', 'MISP3', 'MITD1', 'MKLN1-AS', 'MKNK1', 'MKNK2', 'MKRN1', 'MKRN2', 'MLEC', 'MLF2', 'MLKL', 'MLLT3', 'MLST8', 'MMAB', 'MMACHC', 'MMADHC', 'MMGT1', 'MMP11', 'MMS19', 'MNAT1', 'MNS1', 'MNT', 'MOB1A', 'MOB4', 'MOCOS', 'MOCS2', 'MOCS3', 'MOK', 'MON1A', 'MORN1', 'MORN2', 'MOSPD3', 'MOV10', 'MPC1', 'MPC2', 'MPDU1', 'MPEG1', 'MPG', 'MPIG6B.1', 'MPIG6B.5', 'MPL', 'MPP2', 'MPP4', 'MPP7', 'MPV17L2', 'MR1', 'MRAS', 'MRFAP1', 'MRFAP1L1', 'MRGPRX3', 'MRI1', 'MRM3', 'MROH1', 'MRPL1', 'MRPL12', 'MRPL14', 'MRPL15', 'MRPL18', 'MRPL20', 'MRPL20-AS1', 'MRPL21', 'MRPL22', 'MRPL23', 'MRPL27', 'MRPL28', 'MRPL3', 'MRPL30', 'MRPL33', 'MRPL35', 'MRPL36', 'MRPL37', 'MRPL39', 'MRPL4', 'MRPL40', 'MRPL41', 'MRPL42', 'MRPL43', 'MRPL44', 'MRPL46', 'MRPL47', 'MRPL49', 'MRPL50', 'MRPL54', 'MRPL55', 'MRPL57', 'MRPL58', 'MRPS10', 'MRPS11', 'MRPS12', 'MRPS15', 'MRPS16', 'MRPS18A', 'MRPS18B', 'MRPS18C', 'MRPS21', 'MRPS22', 'MRPS23', 'MRPS25', 'MRPS26', 'MRPS27', 'MRPS28', 'MRPS35', 'MRPS36.1', 'MRPS36.3', 'MRPS6', 'MRPS7', 'MRPS9', 'MRPS9-AS1', 'MRTFA', 'MRTFA-AS1', 'MRTFB', 'MRTO4', 'MS4A7', 'MSANTD3-TMEFF1', 'MSANTD4', 'MSH2', 'MSH4', 'MSI2', 'MSMO1', 'MSTO1', 'MT1E', 'MT1JP', 'MT1X', 'MT2A', 'MTA2', 'MTAP', 'MTATP6P1', 'MTCH2', 'MTCL1', 'MTCO1P12', 'MTCO1P40', 'MTCO1P53', 'MTCYBP36', 'MTDH', 'MTERF3', 'MTERF4', 'MTFMT', 'MTG2', 'MTHFD1', 'MTHFD1L', 'MTHFD2', 'MTHFR', 'MTMR1', 'MTMR10', 'MTMR10.2', 'MTMR11', 'MTMR12', 'MTMR14', 'MTMR4', 'MTMR6', 'MTMR9', 'MTND2P28', 'MTND4P12', 'MTND4P24', 'MTO1', 'MTPAP', 'MTR', 'MTRES1', 'MTREX', 'MTX1', 'MUL1', 'MUS81', 'MUTYH', 'MVB12A', 'MVD', 'MVK', 'MVP', 'MXD4', 'MXI1', 'MYBBP1A', 'MYBL2', 'MYBPH', 'MYC', 'MYCL', 'MYCT1', 'MYH3', 'MYH7', 'MYL12A', 'MYL12B', 'MYL5', 'MYLK4', 'MYO10', 'MYO16-AS1', 'MYO19', 'MYO9A', 'MYO9B', 'MYOCOS', 'MYOM2.1', 'MYOM2.3', 'MYOM3', 'MYORG', 'MYPN', 'N4BP2L1', 'N4BP2L2', 'N4BP2L2-IT2', 'NAA10', 'NAA15', 'NAA20', 'NAA25', 'NAA35', 'NAA38', 'NAA40', 'NAA50', 'NAA60', 'NACC2', 'NADK', 'NADSYN1', 'NAE1', 'NAF1', 'NAGK', 'NAGS', 'NAIF1', 'NANOS1', 'NANP', 'NANS', 'NAP1L2', 'NAPA', 'NARF', 'NASP', 'NAT1', 'NAT14', 'NAT8L', 'NATD1', 'NAV1', 'NAV2', 'NAXD', 'NAXE', 'NBAS', 'NBEAL1', 'NBEAL2', 'NBN', 'NBPF1', 'NBPF10', 'NBPF12', 'NBPF20', 'NBPF26', 'NBR1', 'NCAPD2', 'NCAPH2', 'NCBP1', 'NCBP2AS2', 'NCBP3', 'NCDN', 'NCKIPSD', 'NCOA1', 'NCOA2', 'NCOA3', 'NCOA4', 'NCOR1', 'NCOR2', 'NCR3LG1', 'ND1', 'ND2', 'ND3', 'ND4', 'ND4L', 'ND5', 'NDNF', 'NDOR1', 'NDRG1', 'NDRG3', 'NDST1', 'NDST2', 'NDST2.2', 'NDST3', 'NDUFA11', 'NDUFA13', 'NDUFA5', 'NDUFA6.1', 'NDUFA9', 'NDUFAB1', 'NDUFAF3', 'NDUFAF4', 'NDUFAF5', 'NDUFAF6', 'NDUFB1', 'NDUFB6', 'NDUFB7', 'NDUFC2', 'NDUFS1', 'NDUFS2', 'NDUFS3', 'NDUFS4', 'NDUFS6', 'NDUFS8', 'NDUFV1', 'NDUFV3', 'NEAT1', 'NECAP1', 'NECTIN2', 'NEDD4L', 'NEDD8-MDP1', 'NEK11', 'NEK2', 'NEK8', 'NEK9', 'NELFE', 'NELFE.2', 'NEMP1', 'NEPRO', 'NEURL2', 'NEXMIF', 'NEXN', 'NEXN-AS1', 'NF2', 'NFATC2IP', 'NFIA-AS2', 'NFIL3', 'NFKB1', 'NFKB2', 'NFU1', 'NFX1', 'NGLY1', 'NHLRC1', 'NHP2', 'NIFK', 'NIM1K', 'NINL', 'NIP7', 'NIPAL3', 'NIPSNAP1', 'NIPSNAP2', 'NIPSNAP3A', 'NISCH', 'NIT2', 'NKIRAS1', 'NKRF', 'NKTR', 'NLE1', 'NLN', 'NMB', 'NMD3', 'NME3', 'NME4', 'NME5', 'NMRAL1', 'NMU', 'NOB1', 'NOC2L', 'NOC3L', 'NOL10', 'NOL11', 'NOL12', 'NOL6', 'NOL8', 'NOL9', 'NOLC1', 'NOM1', 'NOMO2', 'NOP14', 'NOP16', 'NOP2', 'NOP56', 'NOP58', 'NOS1AP', 'NOTCH1', 'NOXA1', 'NPAS1', 'NPAT', 'NPC1L1', 'NPEPL1', 'NPEPPS', 'NPHP4', 'NPIPB13', 'NPIPB15', 'NPLOC4', 'NPM1', 'NPRL2', 'NPTN-IT1', 'NQO2', 'NR1D2', 'NR2C2', 'NR2C2AP', 'NR2F2', 'NR2F2-AS1', 'NR2F6', 'NR3C1', 'NR3C2', 'NR4A2', 'NRAS', 'NRAV', 'NRBP1', 'NRBP2', 'NRDE2', 'NRF1', 'NRG3', 'NRN1', 'NRSN2', 'NSD1', 'NSDHL', 'NSF', 'NSF.2', 'NSFL1C', 'NSMAF', 'NSMCE3.1', 'NSMCE3.3', 'NSMCE4A', 'NSRP1', 'NSUN2', 'NSUN4', 'NSUN5P1', 'NSUN5P2', 'NT5C', 'NT5C2', 'NT5C3AP1', 'NT5C3B', 'NT5DC1', 'NT5E', 'NT5M', 'NTAN1P2', 'NTAQ1', 'NTMT1', 'NTNG2', 'NUB1', 'NUBP1', 'NUBP2', 'NUCKS1', 'NUDT15', 'NUDT16', 'NUDT16L1', 'NUDT19', 'NUDT3', 'NUDT4', 'NUDT8', 'NUDT9', 'NUFIP1', 'NUMA1', 'NUMB', 'NUP107', 'NUP133', 'NUP153', 'NUP155', 'NUP188', 'NUP35', 'NUP37', 'NUP50', 'NUP50-DT', 'NUP54', 'NUP85', 'NUP88', 'NUP93', 'NUP98', 'NUTF2', 'NUTM2A-AS1', 'NUTM2B', 'NUTM2B-AS1', 'NUTM2D', 'NVL', 'NXF3', 'NXNL2', 'NXT1', 'OAT', 'OBI1', 'OBI1-AS1', 'OBSCN-AS1', 'OBSL1', 'OCEL1', 'OCIAD1', 'ODC1', 'ODR4', 'OFD1', 'OGFOD1', 'OGFOD3', 'OGFRL1', 'OGG1', 'OGT', 'OLA1', 'OLMALINC', 'OMG', 'OPA1', 'OPA3', 'OPLAH', 'OPRL1.1', 'OPRL1.3', 'OPTN', 'OR2C3', 'OR2T8', 'OR2W3', 'OR7E38P', 'ORAI2', 'ORAI3', 'ORC5', 'ORMDL1', 'ORMDL2', 'OSBPL11', 'OSBPL3', 'OSCP1', 'OSER1', 'OSER1-DT', 'OSGEP', 'OSGEPL1', 'OSGIN2', 'OSR1', 'OSTF1', 'OTUB2', 'OTUB2.1', 'OTUB2.2', 'OTUB2.3', 'OTUD6B', 'OVAAL', 'OVCA2', 'OXA1L', 'OXLD1', 'OXSM', 'OXSR1', 'P2RX7', 'P2RY2', 'P4HA1', 'P4HA2', 'P4HA2-AS1', 'P4HB', 'P4HTM', 'PA2G4', 'PAAF1', 'PABPN1', 'PACC1', 'PACRG', 'PACSIN2', 'PACSIN3', 'PAFAH1B3', 'PAFAH2', 'PAG1', 'PAIP1', 'PAIP1P1', 'PAIP2', 'PAIP2B', 'PAK1IP1', 'PALB2', 'PALD1', 'PALLD', 'PAM16', 'PAMR1', 'PAN2', 'PANK1', 'PANK3', 'PAOX', 'PAQR4', 'PAQR6', 'PARD6G-AS1', 'PARL', 'PARP14', 'PARP15', 'PARP16', 'PARP4', 'PARP8', 'PARVB', 'PATJ', 'PATL1', 'PAX6-AS1', 'PAXBP1', 'PAXBP1-AS1', 'PAXIP1', 'PAXIP1-DT', 'PBDC1', 'PBLD', 'PBOV1', 'PBX2.12', 'PBX2.19', 'PBX2.26', 'PBX2.33', 'PBX2.40', 'PBX2.5', 'PC', 'PCBD1', 'PCBD2', 'PCBP4', 'PCCA-DT', 'PCCB', 'PCDH9', 'PCDHGA8', 'PCDHGB9P', 'PCED1A', 'PCF11', 'PCGF5', 'PCGF6', 'PCIF1', 'PCK2', 'PCMTD2', 'PCMTD2.2', 'PCNA', 'PCNP', 'PCNT', 'PCNX3', 'PCYOX1L', 'PCYT1B', 'PDAP1', 'PDCD2', 'PDCD2L', 'PDCD5', 'PDE10A', 'PDE12', 'PDE6D', 'PDE8A', 'PDF', 'PDHA1', 'PDHB', 'PDIA3', 'PDIA4', 'PDIA6', 'PDIK1L', 'PDK1', 'PDK2', 'PDK3', 'PDLIM7', 'PDP1', 'PDSS1', 'PDXDC1', 'PDXDC1.2', 'PDXP', 'PDZD2', 'PDZD8', 'PEA15', 'PELI2', 'PELI3', 'PEMT', 'PER1', 'PER2', 'PER3', 'PET117', 'PEX1', 'PEX10', 'PEX11A', 'PEX11G', 'PEX12', 'PEX14', 'PEX16', 'PEX19', 'PEX2', 'PEX26', 'PEX3', 'PEX6', 'PEX7', 'PFDN1', 'PFDN2', 'PFDN4', 'PFKFB2', 'PFKFB3', 'PFKFB4', 'PFKM', 'PFKP', 'PGAM1', 'PGAM5', 'PGAP3', 'PGAP4', 'PGGHG', 'PGGT1B', 'PGK1', 'PGLS', 'PGM1', 'PGM5-AS1', 'PGP', 'PHACTR2', 'PHAX', 'PHB2', 'PHC1', 'PHC3', 'PHF11', 'PHF2', 'PHF21A', 'PHF23', 'PHF3', 'PHF6', 'PHF7', 'PHF8', 'PHGDH', 'PHIP', 'PHKA1', 'PHKG2', 'PHLDB2', 'PHLPP2', 'PHOSPHO2', 'PHTF1', 'PHTF2', 'PHYHD1', 'PHYKPL', 'PI4K2A', 'PI4K2B', 'PI4KB', 'PIBF1', 'PICALM', 'PIGA', 'PIGB', 'PIGBOS1', 'PIGC', 'PIGF', 'PIGM', 'PIGQ', 'PIGS', 'PIGV', 'PIGW', 'PIGZ', 'PIH1D1', 'PIH1D2', 'PIK3C2A', 'PIK3CA', 'PIK3CD', 'PIK3IP1-DT', 'PIK3R2', 'PIK3R3', 'PIM1', 'PIN1', 'PIN4', 'PINX1', 'PINX1.2', 'PIP4K2B', 'PIP4P1', 'PISD', 'PITHD1', 'PITPNA', 'PITPNC1', 'PITRM1', 'PJA1', 'PJA2', 'PKIG', 'PKM', 'PKMP3', 'PKMYT1', 'PKN3', 'PLA2G10', 'PLA2G2D', 'PLAA', 'PLAG1', 'PLCB2', 'PLCB3', 'PLCB4', 'PLCH1', 'PLEKHA2', 'PLEKHA8P1', 'PLEKHG3', 'PLEKHG4', 'PLEKHG5', 'PLEKHG7', 'PLEKHH1', 'PLEKHH3', 'PLEKHJ1', 'PLEKHM1', 'PLEKHM1.2', 'PLEKHM3', 'PLG', 'PLGLB1', 'PLGLB2', 'PLGRKT', 'PLK3', 'PLOD1', 'PLOD2', 'PLOD3', 'PLPP1', 'PLPP3', 'PLPP6', 'PLPPR2', 'PLRG1', 'PLXNA3', 'PMF1', 'PMM2', 'PMP22', 'PMPCA', 'PMPCB', 'PMS2P1', 'PMS2P3', 'PNKD', 'PNLDC1', 'PNMA6A', 'PNO1', 'PNPLA2', 'PNPLA7', 'PNPT1', 'PNRC1', 'PODXL', 'POLDIP2', 'POLE2', 'POLE3', 'POLQ', 'POLR1B', 'POLR1C', 'POLR1E', 'POLR1G', 'POLR1H.11', 'POLR1H.18', 'POLR1H.4', 'POLR2A', 'POLR2B', 'POLR2E', 'POLR2K', 'POLR3B', 'POLR3C', 'POLR3E', 'POLR3F', 'POLR3GL', 'POLR3H', 'POLR3K', 'POM121', 'POMGNT1', 'POMP', 'POMT2', 'POMZP3', 'POP1', 'POP5', 'POP7', 'PORCN', 'POTEC', 'POU5F1B', 'POU5F1P6', 'PP2D1', 'PP7080', 'PPA2', 'PPAN', 'PPARA', 'PPAT', 'PPCS', 'PPFIA1', 'PPFIA2-AS1', 'PPFIA3', 'PPFIA4', 'PPFIBP1', 'PPHLN1', 'PPIB', 'PPID', 'PPIF', 'PPIG', 'PPIL2', 'PPIL3', 'PPIL4', 'PPM1A', 'PPM1J', 'PPM1K', 'PPP1CA', 'PPP1R12B', 'PPP1R13L', 'PPP1R14B-AS1', 'PPP1R15A', 'PPP1R15B', 'PPP1R18', 'PPP1R18.12', 'PPP1R18.14', 'PPP1R18.18', 'PPP1R18.2', 'PPP1R18.20', 'PPP1R18.24', 'PPP1R18.26', 'PPP1R18.6', 'PPP1R18.8', 'PPP1R2', 'PPP1R26', 'PPP1R26-AS1', 'PPP1R37', 'PPP1R3C', 'PPP1R42', 'PPP1R8', 'PPP2CA', 'PPP2R3A', 'PPP2R3C', 'PPP2R5B', 'PPP2R5C', 'PPP3CB', 'PPP3CB-AS1', 'PPP4C', 'PPP4R4.1', 'PPP4R4.3', 'PPP5C', 'PPP6C', 'PPP6R2', 'PPP6R3', 'PPRC1', 'PPTC7', 'PQBP1', 'PRAM1', 'PRCC', 'PRDM10', 'PRDX2', 'PRDX3', 'PRH1', 'PRH1.1', 'PRH1.10', 'PRH1.11', 'PRH1.12', 'PRH1.15', 'PRH1.16', 'PRH1.17', 'PRH1.2', 'PRH1.20', 'PRH1.21', 'PRH1.22', 'PRH1.5', 'PRH1.6', 'PRH1.7', 'PRICKLE2', 'PRIM1', 'PRKAA1', 'PRKAA2', 'PRKAB1', 'PRKAB2', 'PRKACA', 'PRKAG1', 'PRKAR1B', 'PRKAR2A', 'PRKCA', 'PRKCE', 'PRKCQ-AS1', 'PRKCSH', 'PRKCZ', 'PRKD2', 'PRKDC', 'PRKN', 'PRKRA', 'PRKRIP1', 'PRKY', 'PRLR', 'PRMT1', 'PRMT2', 'PRMT3', 'PRMT6', 'PRMT7', 'PRNCR1', 'PRORP', 'PRORP.2', 'PRPF18', 'PRPF3', 'PRPF31', 'PRPF31.3', 'PRPF31.6', 'PRPF38B', 'PRPF4', 'PRPF40A', 'PRPF40B', 'PRPF4B', 'PRPF8', 'PRPS1', 'PRR12', 'PRR13', 'PRR14', 'PRR22', 'PRR5', 'PRRC2A.10', 'PRRC2A.16', 'PRRC2A.22', 'PRRC2A.28', 'PRRC2A.34', 'PRRC2A.4', 'PRRC2B', 'PRRG3', 'PRRG4', 'PRRT3', 'PRSS27', 'PRSS53', 'PRTFDC1', 'PRUNE1', 'PRXL2B', 'PSAT1', 'PSD2', 'PSEN2', 'PSENEN', 'PSIP1', 'PSKH1', 'PSMA3', 'PSMA3-AS1', 'PSMA4', 'PSMA5', 'PSMB1', 'PSMB10', 'PSMB2', 'PSMB4', 'PSMB6', 'PSMB7', 'PSMB8.1', 'PSMB8.4', 'PSMC2', 'PSMC2P1', 'PSMD1', 'PSMD13', 'PSMD5', 'PSMD6', 'PSMD7', 'PSMD9', 'PSME3', 'PSME4', 'PSMF1', 'PSMG1', 'PSMG2', 'PSMG4', 'PSPC1', 'PSPN', 'PSRC1', 'PSTK', 'PSTPIP2', 'PTBP1', 'PTBP2', 'PTCD1', 'PTCH1', 'PTCHD1', 'PTDSS2', 'PTDSS2.2', 'PTENP1', 'PTGDR2', 'PTGER4', 'PTGES2', 'PTGES3', 'PTGES3L-AARSD1', 'PTGFRN', 'PTP4A3', 'PTP4A3.1', 'PTP4A3.2', 'PTP4A3.3', 'PTPMT1', 'PTPN1', 'PTPN14', 'PTPN18', 'PTPRC.1', 'PTPRC.3', 'PTPRR', 'PTPRU', 'PTPRVP', 'PTRH1', 'PTRH2', 'PTS', 'PTX3', 'PUF60', 'PUF60.1', 'PUF60.2', 'PUF60.3', 'PUM1', 'PUM3', 'PUS1', 'PUS10', 'PUS3', 'PUS7', 'PUS7L', 'PUSL1', 'PWP1', 'PXDC1', 'PXMP2', 'PXYLP1', 'PYCR2', 'PYCR3', 'PYM1', 'PYURF', 'QRSL1', 'QTRT1', 'R3HCC1', 'R3HCC1L', 'R3HDM4', 'RAB11A', 'RAB11FIP4', 'RAB12', 'RAB1B', 'RAB23', 'RAB26', 'RAB30', 'RAB33B', 'RAB34', 'RAB35', 'RAB38', 'RAB3A', 'RAB3D', 'RAB3GAP1', 'RAB3IP', 'RAB40A', 'RAB40B', 'RAB40C', 'RAB4B', 'RAB5A', 'RAB5C', 'RAB7B', 'RAB8B', 'RAB9B', 'RABEP1', 'RABEPK', 'RABGAP1L', 'RABGAP1L-DT', 'RABGEF1', 'RABIF', 'RABL2A', 'RABL6', 'RAC3', 'RAD1', 'RAD17.1', 'RAD17.3', 'RAD18', 'RAD23A', 'RAD23B', 'RAD50', 'RAD51B', 'RAD52', 'RAD54L2', 'RAD9A', 'RAET1K', 'RAF1', 'RAG1', 'RALA', 'RALB', 'RALGAPA2', 'RALGAPB', 'RALGDS', 'RAMAC', 'RAN', 'RANBP1', 'RANBP3', 'RANGRF', 'RAP1B', 'RAP2C-AS1', 'RAPGEF1', 'RAPGEF2', 'RAPGEF4', 'RAPGEF6', 'RAPSN', 'RARA', 'RARG', 'RARS1', 'RARS2', 'RASA2', 'RASAL2', 'RASSF4', 'RB1CC1', 'RBBP6', 'RBBP7', 'RBBP8', 'RBBP9', 'RBCK1', 'RBFA', 'RBFOX2', 'RBFOX2.1', 'RBFOX2.2', 'RBFOX2.3', 'RBIS', 'RBM12', 'RBM12B', 'RBM14', 'RBM15', 'RBM15B', 'RBM17', 'RBM24', 'RBM25', 'RBM26-AS1', 'RBM28', 'RBM3', 'RBM34', 'RBM4', 'RBM45', 'RBM5', 'RBM6', 'RBMS1', 'RBMS2', 'RBMX', 'RBMXL1', 'RBPJ', 'RBPMS2', 'RBX1', 'RC3H1', 'RC3H2', 'RCC1', 'RCC1L', 'RCC2', 'RCL1', 'RCN2', 'RCN3', 'RDH13.1', 'RDH13.3', 'RDH14', 'RDH5', 'RDX', 'REC8', 'RECQL5', 'REG4', 'RELB', 'RELL1', 'RELL2', 'RENBP', 'REP15', 'REPIN1', 'REPS1', 'REPS2', 'RERE', 'RETREG2', 'RETREG3', 'REX1BD', 'REXO1', 'REXO5', 'RFC2', 'RFC3', 'RFC5', 'RFK', 'RFLNB', 'RFNG', 'RFWD3', 'RFX1', 'RFX2', 'RFX3', 'RFX5', 'RFX7', 'RFXANK', 'RFXAP', 'RGL2', 'RGN', 'RGPD8', 'RGS12', 'RGS16', 'RGS17', 'RGS4', 'RGS5.1', 'RGS5.3', 'RGS7', 'RGS9', 'RHBDD1', 'RHBDD2', 'RHBDF1', 'RHEB', 'RHEBL1', 'RHNO1', 'RHOC', 'RHOD', 'RHOT2', 'RIMBP3C', 'RIMKLA', 'RIMKLB', 'RIMS3', 'RINT1', 'RIOK1', 'RIOK2', 'RIOX1', 'RIPK1', 'RIT1', 'RLF', 'RLN1', 'RLN1.2', 'RMDN1', 'RMDN2', 'RMI2', 'RMND5B', 'RN7SKP11', 'RN7SL1', 'RN7SL125P', 'RN7SL219P', 'RN7SL239P', 'RN7SL253P', 'RN7SL255P', 'RN7SL321P', 'RN7SL363P', 'RN7SL461P', 'RN7SL558P', 'RN7SL66P', 'RN7SL714P', 'RN7SL73P', 'RN7SL75P', 'RN7SL774P', 'RN7SL850P', 'RNASE10', 'RNASEH1', 'RNASEH1-AS1', 'RNASEL', 'RND1', 'RND2', 'RND3', 'RNF103', 'RNF115', 'RNF121', 'RNF122', 'RNF126', 'RNF138', 'RNF139', 'RNF141', 'RNF146', 'RNF148', 'RNF150', 'RNF152', 'RNF167', 'RNF170', 'RNF185', 'RNF19B', 'RNF20', 'RNF207', 'RNF213-AS1', 'RNF214', 'RNF220', 'RNF227', 'RNF24', 'RNF25', 'RNF38', 'RNF4', 'RNF41', 'RNF7', 'RNPC3', 'RNPS1', 'RO60', 'ROBO3', 'ROCK1P1', 'ROGDI', 'ROR1', 'RORA', 'RP9P', 'RPAP2', 'RPAP3', 'RPARP-AS1', 'RPE65', 'RPF1', 'RPF2', 'RPGR', 'RPGRIP1L', 'RPL13AP26', 'RPL15P11', 'RPL15P9', 'RPL22L1', 'RPL22P19', 'RPL23AP81', 'RPL26L1', 'RPL26P18', 'RPL32P18', 'RPL32P29', 'RPL32P3', 'RPL36A-HNRNPH2', 'RPL36AL', 'RPL39L', 'RPL5P9', 'RPL7AP16', 'RPL7AP66', 'RPL7L1', 'RPL8P3', 'RPLP0P10', 'RPP14', 'RPP25L', 'RPP38', 'RPP40', 'RPRD2', 'RPS25P3', 'RPS2P11', 'RPS3AP38', 'RPS3P5', 'RPS4XP16', 'RPS6KB1', 'RPS6KB2', 'RPS6KC1', 'RPS6KL1', 'RPS6P1', 'RPSAP12', 'RPSAP46', 'RPUSD1', 'RRAGA', 'RRAGB', 'RREB1', 'RRN3', 'RRP1', 'RRP12', 'RRP15', 'RRP1B', 'RRP36', 'RRP7A', 'RRP7BP', 'RRP9', 'RRS1', 'RRS1-AS1', 'RSBN1', 'RSF1', 'RSL1D1', 'RSL24D1', 'RSPH3', 'RSPRY1', 'RSRP1', 'RTCB', 'RTEL1P1', 'RTL10', 'RTL8B', 'RTN4IP1', 'RTRAF', 'RUFY2', 'RUNX1', 'RUSC1-AS1', 'RUSF1', 'RWDD1', 'RWDD2A', 'RWDD4', 'RXYLT1', 'RYBP.1', 'RYBP.3', 'S100A10', 'S100A11', 'S1PR1', 'SAC3D1', 'SACS', 'SAE1', 'SAFB2', 'SAMD1', 'SAMD11', 'SAMD3', 'SAMD4A', 'SAMM50', 'SAP30L', 'SAR1A', 'SARAF', 'SARM1', 'SARS1', 'SARS2', 'SASH1', 'SAT1', 'SATB1', 'SAV1', 'SAYSD1', 'SBDS', 'SBF1', 'SBF2-AS1', 'SC5D', 'SCAF8', 'SCAI', 'SCAMP1-AS1', 'SCAMP4', 'SCAMP5', 'SCAND1', 'SCARNA17', 'SCARNA9', 'SCART1', 'SCFD1', 'SCFD2', 'SCLT1', 'SCMH1', 'SCML1', 'SCN5A', 'SCN8A', 'SCNN1D', 'SCO1', 'SCRN2', 'SCT', 'SCUBE2', 'SCYL2', 'SDAD1', 'SDAD1P1', 'SDCBP', 'SDCBP2-AS1', 'SDE2', 'SDF2', 'SDF2L1', 'SDHAF1', 'SDHAF2', 'SDHAF3', 'SDHB', 'SDR39U1', 'SEC11C', 'SEC14L1P1', 'SEC14L2', 'SEC22B', 'SEC22C', 'SEC23A', 'SEC23IP', 'SEC61B', 'SECISBP2', 'SECISBP2L', 'SEH1L', 'SEL1L', 'SELENOF', 'SELENOK', 'SEM1', 'SEMA4A', 'SEMA4B', 'SEMA4D', 'SEMA4G', 'SEMA5A', 'SENP1', 'SENP3', 'SENP6', 'SEPHS1', 'SEPHS2', 'SEPSECS', 'SEPTIN14', 'SEPTIN9.1', 'SEPTIN9.3', 'SERAC1', 'SERF1A.13', 'SERF1A.14', 'SERF1A.18', 'SERF1A.19', 'SERF1A.23', 'SERF1A.24', 'SERF1A.3', 'SERF1A.4', 'SERF1A.8', 'SERF1A.9', 'SERINC3', 'SERPINB6', 'SERPINB8', 'SERPINE1', 'SERPINE2', 'SERPINH1', 'SET', 'SETBP1', 'SETD1A', 'SETD3', 'SETD6', 'SETD9', 'SETMAR', 'SF1', 'SF3A2', 'SF3B4', 'SF3B5', 'SFPQ', 'SFT2D3', 'SFXN2', 'SFXN3', 'SGCA', 'SGK2', 'SGK3', 'SGPL1', 'SGTA', 'SH2D7', 'SH3BGR', 'SH3BP5', 'SH3D21', 'SH3GLB2', 'SH3PXD2A', 'SHFL', 'SHISA5', 'SHLD2', 'SHMT1', 'SHTN1', 'SIGLEC8', 'SIGMAR1', 'SIK1B', 'SIK3', 'SIRLNT', 'SIRT1', 'SIRT4', 'SIRT5', 'SIVA1', 'SIX2', 'SKA2', 'SKOR1', 'SLA2', 'SLBP', 'SLC11A2', 'SLC12A2', 'SLC12A4', 'SLC12A6', 'SLC12A9', 'SLC12A9-AS1', 'SLC13A3', 'SLC15A4', 'SLC16A1', 'SLC16A7', 'SLC18B1', 'SLC19A1', 'SLC19A2', 'SLC20A1', 'SLC20A2', 'SLC22A2', 'SLC22A20P', 'SLC23A3', 'SLC25A10', 'SLC25A11', 'SLC25A12', 'SLC25A13', 'SLC25A15', 'SLC25A16', 'SLC25A17', 'SLC25A20', 'SLC25A24', 'SLC25A25', 'SLC25A26', 'SLC25A28', 'SLC25A3', 'SLC25A32', 'SLC25A33', 'SLC25A35', 'SLC25A36', 'SLC25A37', 'SLC25A39', 'SLC25A42', 'SLC25A44', 'SLC25A46', 'SLC25A5', 'SLC25A53', 'SLC26A6', 'SLC27A4', 'SLC28A1', 'SLC2A1', 'SLC2A13', 'SLC2A5', 'SLC2A8', 'SLC30A1', 'SLC30A7', 'SLC30A9', 'SLC31A1', 'SLC33A1', 'SLC35A4', 'SLC35B2', 'SLC35B3', 'SLC35B4', 'SLC35C2', 'SLC35D1', 'SLC35E1', 'SLC35E2A', 'SLC35E3', 'SLC35G1', 'SLC36A4', 'SLC37A4', 'SLC37A4.2', 'SLC38A3', 'SLC38A5', 'SLC39A14', 'SLC39A3', 'SLC39A4', 'SLC39A7', 'SLC41A2', 'SLC43A2.1', 'SLC43A2.3', 'SLC44A2', 'SLC44A5', 'SLC45A2', 'SLC45A2.2', 'SLC48A1', 'SLC4A11', 'SLC4A4', 'SLC5A3', 'SLC5A5', 'SLC66A1', 'SLC66A1L', 'SLC66A2', 'SLC7A11', 'SLC7A2', 'SLC9A1', 'SLC9A5', 'SLC9A8', 'SLC9A9', 'SLC9B1', 'SLC9B2', 'SLC9C1', 'SLCO4A1', 'SLCO4A1-AS1', 'SLCO4C1', 'SLCO5A1', 'SLCO6A1', 'SLF2', 'SLFN5', 'SLFNL1', 'SLIT1', 'SLTM', 'SLU7', 'SLX1B', 'SLX1B-SULT1A4', 'SLX4', 'SLX4IP', 'SMAD3', 'SMAD5', 'SMAP2', 'SMARCA1', 'SMARCA5', 'SMARCA5-AS1', 'SMARCAD1', 'SMARCAL1', 'SMARCB1', 'SMARCD1', 'SMARCD3', 'SMARCE1', 'SMARCE1P5', 'SMC5', 'SMC6', 'SMCO1', 'SMCR8', 'SMDT1', 'SMDT1.2', 'SMG1', 'SMG8', 'SMG9', 'SMIM12', 'SMIM15', 'SMIM19', 'SMIM2-AS1', 'SMIM26', 'SMIM27', 'SMIM29', 'SMIM31', 'SMIM4', 'SMIM6', 'SMIM7', 'SMKR1', 'SMN1.1', 'SMN1.11', 'SMN1.16', 'SMN1.21', 'SMN1.6', 'SMPD2', 'SMPD4', 'SMS', 'SMU1', 'SMYD3', 'SMYD5', 'SNAP23', 'SNAPC2', 'SNAPC3', 'SNAPC4', 'SNAPIN', 'SNCAIP', 'SND1', 'SNHG11', 'SNHG12', 'SNHG15', 'SNHG16', 'SNHG17', 'SNHG21', 'SNHG31', 'SNHG8', 'SNHG9', 'SNIP1', 'SNN', 'SNORA24', 'SNORA33', 'SNORA72', 'SNORD104', 'SNORD17', 'SNORD19', 'SNORD23', 'SNORD48.1', 'SNORD48.3', 'SNPH', 'SNRNP35', 'SNRNP40', 'SNRNP48', 'SNRNP70', 'SNRPA1', 'SNRPB', 'SNRPB2', 'SNRPD1', 'SNRPE', 'SNRPF', 'SNUPN', 'SNURF', 'SNX11', 'SNX12', 'SNX14', 'SNX15', 'SNX16', 'SNX17', 'SNX18', 'SNX19', 'SNX21', 'SNX25P1', 'SNX27', 'SNX3', 'SNX33', 'SNX4', 'SNX5', 'SOCS2-AS1', 'SOCS4', 'SOCS6', 'SOD1', 'SOHLH2', 'SORBS1', 'SORL1', 'SOS1', 'SOX13', 'SOX30', 'SOX9', 'SP1', 'SP110', 'SP2', 'SPA17', 'SPACA6P-AS', 'SPAG1', 'SPAG16', 'SPAG7', 'SPANXA2-OT1', 'SPART-AS1', 'SPAST', 'SPATA20', 'SPATA2L', 'SPATA33', 'SPATA7', 'SPATS2L', 'SPCS1', 'SPCS2', 'SPDEF', 'SPDYE9', 'SPEF2', 'SPG11', 'SPHK1', 'SPHK2', 'SPIN2B', 'SPIRE1', 'SPOCD1', 'SPPL2B', 'SPR', 'SPRING1', 'SPRTN', 'SPRYD4', 'SPSB2', 'SPTAN1', 'SPTBN1', 'SQLE', 'SRA1', 'SRBD1', 'SRC', 'SRD5A3', 'SREBF1', 'SRF', 'SRGAP3', 'SRM', 'SRP19', 'SRP72', 'SRP9', 'SRPRA', 'SRR', 'SRRD', 'SRRM1', 'SRRM2-AS1', 'SRRM5', 'SRSF10', 'SRSF12', 'SRSF2', 'SRSF3', 'SRSF5', 'SRSF7', 'SRSF8', 'SRXN1', 'SSB', 'SSBP1', 'SSBP1.1', 'SSBP1.2', 'SSBP1.3', 'SSBP4', 'SSH3', 'SSNA1', 'SSTR1', 'SSU72', 'ST13', 'ST14', 'ST3GAL3', 'ST6GALNAC2', 'ST6GALNAC4P1', 'ST7-AS1', 'ST7L', 'ST8SIA4', 'STAC', 'STAG3L4', 'STAM', 'STAMBP', 'STAMBPL1', 'STARD6', 'STARD7', 'STARD9', 'STAT1', 'STAT5B', 'STBD1', 'STEAP2-AS1', 'STEAP3-AS1', 'STK16', 'STK19.1', 'STK19.11', 'STK19.16', 'STK19.21', 'STK19.6', 'STK26', 'STK32C', 'STK33', 'STK35', 'STK38L', 'STMP1', 'STON1-GTF2A1L', 'STOX2', 'STRADA', 'STRAP', 'STRIP1', 'STRN4', 'STT3A', 'STT3B', 'STUB1', 'STX10', 'STX11', 'STX16-NPEPL1', 'STX17', 'STX18', 'STX18-AS1', 'STX7', 'STXBP1', 'STXBP3', 'STXBP4', 'STYXL1', 'SUB1', 'SUCLG2', 'SUFU', 'SUGCT', 'SUGP2', 'SUGT1', 'SUMO2', 'SUMO3', 'SUPT16H', 'SUPV3L1', 'SURF1', 'SURF2', 'SURF6', 'SUV39H2', 'SVIL-AS1', 'SVIP', 'SVOPL', 'SWSAP1', 'SWT1', 'SYAP1', 'SYCP2L', 'SYDE2', 'SYNCRIP', 'SYNE1', 'SYNGAP1', 'SYNGAP1.1', 'SYNGAP1.2', 'SYNGAP1.3', 'SYNGR2', 'SYNJ2BP', 'SYTL2', 'SYTL3', 'SYVN1', 'SZRD1', 'SZT2-AS1', 'TAB1', 'TAB2', 'TAB2.2', 'TAB3', 'TACC1', 'TACO1', 'TADA1', 'TAF11', 'TAF13', 'TAF1A', 'TAF1B', 'TAF1D', 'TAF4B', 'TAF5L', 'TAF6L', 'TAF9.1', 'TAF9.3', 'TAF9B', 'TALDO1', 'TAMM41.1', 'TAMM41.3', 'TANC2', 'TANGO6', 'TAOK2', 'TAOK3', 'TAP2.10', 'TAP2.17', 'TAP2.24', 'TAP2.3', 'TAP2.31', 'TAP2.38', 'TAPT1-AS1', 'TARS1', 'TAS2R10', 'TAS2R15P', 'TAS2R19', 'TAS2R19.2', 'TASOR2', 'TASP1', 'TATDN1', 'TATDN3', 'TAX1BP3', 'TBC1D12', 'TBC1D15', 'TBC1D16', 'TBC1D22A', 'TBC1D3', 'TBC1D32', 'TBC1D3P1-DHX40P1', 'TBC1D8-AS1', 'TBCB', 'TBCC', 'TBCE', 'TBK1', 'TBL1XR1', 'TBL3', 'TBP', 'TBX2', 'TBX6', 'TBXA2R', 'TCAF2', 'TCAP', 'TCEA1', 'TCEA2', 'TCEA3', 'TCEAL1', 'TCEAL3', 'TCEAL9', 'TCEANC2', 'TCERG1', 'TCF25', 'TCF3', 'TCF7L2', 'TCP10L', 'TCP11L2', 'TCTA', 'TCTN3', 'TDG', 'TDO2', 'TEAD2', 'TEAD3', 'TEC', 'TECPR1', 'TECPR2', 'TEDC2', 'TEF', 'TEKT4', 'TEKT4P2', 'TELO2', 'TEN1', 'TENT5C', 'TEP1', 'TERF2', 'TESK2', 'TET1', 'TET2', 'TEX10', 'TEX30', 'TEX35', 'TEX9', 'TFAM', 'TFAP2E', 'TFB2M', 'TFCP2', 'TFIP11', 'TFR2', 'TFRC', 'TGFA', 'TGFB1', 'TGFB2', 'TGFBR1', 'TGFBRAP1', 'TGIF1', 'TGM4', 'TGS1', 'THAP1', 'THAP12', 'THAP2', 'THAP4', 'THAP5', 'THAP6', 'THAP7-AS1', 'THBS3', 'THBS4', 'THEGL', 'THEM4', 'THEM6', 'THOC2', 'THOP1', 'THORLNC', 'THRAP3', 'THUMPD1', 'THUMPD3-AS1', 'TIAL1', 'TIGAR', 'TIGD2', 'TIMELESS', 'TIMM10', 'TIMM10B', 'TIMM13', 'TIMM17A', 'TIMM17B', 'TIMM22', 'TIMM23', 'TIMM23B', 'TIMM29', 'TIMM44', 'TIMM8A', 'TIMM9', 'TINF2', 'TIPIN', 'TIPRL', 'TLCD2', 'TLE4', 'TLN2', 'TLNRD1', 'TLR1', 'TM2D1', 'TM2D2', 'TM7SF2', 'TMA16', 'TMBIM4', 'TMC4.14', 'TMC4.19', 'TMC4.4', 'TMC4.9', 'TMCC1', 'TMCC2', 'TMCC3', 'TMED1', 'TMED5', 'TMED7-TICAM2', 'TMEM104', 'TMEM11', 'TMEM115', 'TMEM116', 'TMEM120B', 'TMEM126A', 'TMEM126B', 'TMEM128', 'TMEM129', 'TMEM131L', 'TMEM134', 'TMEM135', 'TMEM138', 'TMEM141', 'TMEM144', 'TMEM147-AS1', 'TMEM14B', 'TMEM14C', 'TMEM156', 'TMEM158', 'TMEM160', 'TMEM161B', 'TMEM165', 'TMEM168', 'TMEM170A', 'TMEM170B', 'TMEM175', 'TMEM177', 'TMEM18', 'TMEM185A', 'TMEM185B', 'TMEM192', 'TMEM201', 'TMEM202-AS1', 'TMEM203', 'TMEM205', 'TMEM208', 'TMEM209', 'TMEM217', 'TMEM220', 'TMEM222', 'TMEM232', 'TMEM233', 'TMEM256', 'TMEM259', 'TMEM265', 'TMEM267', 'TMEM31', 'TMEM38A', 'TMEM45A', 'TMEM50B.1', 'TMEM50B.3', 'TMEM53', 'TMEM60', 'TMEM62', 'TMEM63A', 'TMEM69', 'TMEM70', 'TMEM79', 'TMEM81', 'TMEM86A', 'TMEM87A', 'TMEM9', 'TMEM94', 'TMLHE', 'TMPO', 'TMPO-AS1', 'TMPRSS12', 'TMSB4X', 'TMSB4Y', 'TNFAIP1', 'TNFAIP8', 'TNFRSF10B', 'TNFRSF12A', 'TNFRSF25', 'TNIK', 'TNK1', 'TNK2', 'TNKS', 'TNNI3K', 'TNPO2', 'TNRC6A', 'TNRC6B', 'TNRC6C', 'TNS1', 'TOE1', 'TOMM20', 'TOMM22', 'TOMM34', 'TOMM40', 'TOMM40L', 'TOMM6', 'TOMM70', 'TOP3B', 'TOR1A', 'TOR1AIP1', 'TOR3A', 'TP53', 'TP53BP2', 'TP53INP2', 'TP53RK', 'TP73-AS1', 'TPCN2', 'TPD52', 'TPD52L1', 'TPD52L2', 'TPGS1', 'TPI1', 'TPI1P2', 'TPK1', 'TPM1', 'TPM3P9', 'TPMT', 'TPP1', 'TPRA1', 'TPRKB', 'TPST1', 'TPTE2', 'TRA2B', 'TRAF3', 'TRAF3IP1', 'TRAFD1', 'TRAM2', 'TRAP1', 'TRAPPC10', 'TRAPPC12', 'TRAPPC12.2', 'TRAPPC13', 'TRAPPC2L', 'TRAPPC4', 'TRAPPC5', 'TRAPPC6A', 'TRAPPC8', 'TRAPPC9', 'TREM1', 'TRERF1', 'TRIAP1', 'TRIM11', 'TRIM14', 'TRIM2', 'TRIM25', 'TRIM27', 'TRIM27.11', 'TRIM27.13', 'TRIM27.14', 'TRIM27.18', 'TRIM27.20', 'TRIM27.21', 'TRIM27.25', 'TRIM27.27', 'TRIM27.28', 'TRIM27.32', 'TRIM27.34', 'TRIM27.35', 'TRIM27.39', 'TRIM27.4', 'TRIM27.41', 'TRIM27.42', 'TRIM27.46', 'TRIM27.48', 'TRIM27.6', 'TRIM27.7', 'TRIM33', 'TRIM35', 'TRIM36', 'TRIM37', 'TRIM45', 'TRIM46', 'TRIM5', 'TRIM52', 'TRIM52-AS1', 'TRIM56', 'TRIM65', 'TRIM67', 'TRIM69', 'TRIM69.1', 'TRIM69.2', 'TRIM69.3', 'TRIM73', 'TRIM74.1', 'TRIM74.3', 'TRIO', 'TRIP4', 'TRIP6', 'TRMO', 'TRMT10A', 'TRMT10C', 'TRMT11', 'TRMT12', 'TRMT1L', 'TRMT2A', 'TRMT2B', 'TRMT5', 'TRMT6', 'TRMT61A', 'TRNT1', 'TRPC1', 'TRPC3', 'TRPC4', 'TRPC4AP', 'TRPV1', 'TRUB1', 'TRUB2', 'TSC1', 'TSC22D1', 'TSC22D1-AS1', 'TSC22D4', 'TSEN15', 'TSFM', 'TSGA13', 'TSHZ1', 'TSKU', 'TSN', 'TSNARE1', 'TSNAX', 'TSPAN15', 'TSPAN17', 'TSPAN31', 'TSPAN4', 'TSPO', 'TSPYL1', 'TSPYL2', 'TSR1', 'TSR2', 'TSSC2', 'TSSC4', 'TSSK6', 'TST', 'TSTD2', 'TTC12', 'TTC13', 'TTC14', 'TTC19', 'TTC27', 'TTC32', 'TTC34', 'TTC34.1', 'TTC34.2', 'TTC34.3', 'TTC39A', 'TTC39C', 'TTC41P', 'TTC8', 'TTC9C', 'TTF2', 'TTK', 'TTL', 'TTLL12', 'TTLL3', 'TTLL5', 'TTLL6', 'TTN', 'TTTY10', 'TUBA1C', 'TUBA3D', 'TUBB3', 'TUBB4A', 'TUBB6', 'TUBG1', 'TUBG2', 'TUBGCP4', 'TUFM', 'TULP3', 'TULP4', 'TUSC2', 'TWNK', 'TXK', 'TXLNA', 'TXLNG', 'TXNDC9', 'TXNL4A', 'TXNRD3', 'TYW1', 'U2AF1', 'U2SURP', 'UAP1', 'UBA2', 'UBA3', 'UBA6-AS1', 'UBA7', 'UBAC2', 'UBAC2-AS1', 'UBALD1', 'UBALD2', 'UBAP1L', 'UBAP2L', 'UBB', 'UBE2A', 'UBE2B', 'UBE2D1', 'UBE2D2', 'UBE2D3', 'UBE2G1', 'UBE2G2', 'UBE2I', 'UBE2J1', 'UBE2J2', 'UBE2K', 'UBE2M', 'UBE2N', 'UBE2Q2L', 'UBE2Q2L.2', 'UBE2Q2P2', 'UBE2Q2P2.1', 'UBE2Q2P2.2', 'UBE2Q2P2.3', 'UBE2V2', 'UBE3C', 'UBE4B', 'UBFD1', 'UBIAD1', 'UBLCP1', 'UBN2', 'UBOX5', 'UBP1', 'UBR2', 'UBTD1', 'UBXN2B', 'UBXN4', 'UBXN7', 'UCHL3', 'UCHL5', 'UCK1', 'UCK2', 'UCN2', 'UCP2', 'UFSP1', 'UFSP2', 'UGGT1', 'UGP2', 'UHRF1BP1', 'UHRF2', 'ULK2', 'ULK4', 'UMPS', 'UNC93B1', 'UNG', 'UNK', 'UNKL', 'UPF3A', 'UPP1', 'UPP2', 'UQCC2', 'UQCR10', 'UQCRC1', 'UQCRC2', 'UQCRFS1', 'URAHP', 'URB1-AS1', 'URB2', 'URM1', 'UROD', 'UROS', 'USE1', 'USF3', 'USP1', 'USP10', 'USP13', 'USP15', 'USP16', 'USP2', 'USP21', 'USP22', 'USP27X', 'USP27X-AS1', 'USP28', 'USP36', 'USP37', 'USP38', 'USP4', 'USP46-DT', 'USP47', 'USP49', 'USP5', 'USP6NL', 'USP7', 'USP8', 'UTP11', 'UTP14A', 'UTP15', 'UTP18', 'UTP3', 'UTP4', 'UTP4.2', 'UTS2', 'VAMP2', 'VAMP5', 'VAMP7', 'VAPB', 'VARS1', 'VARS1.10', 'VARS1.15', 'VARS1.20', 'VARS1.5', 'VASH1', 'VASP', 'VAV2', 'VBP1', 'VCPKMT', 'VDAC1', 'VEGFA', 'VEZF1', 'VHL', 'VIPAS39', 'VKORC1L1', 'VLDLR', 'VMA21', 'VN1R108P', 'VPS13B-DT', 'VPS13C', 'VPS13D', 'VPS25', 'VPS26A', 'VPS28', 'VPS29', 'VPS35', 'VPS36', 'VPS37A', 'VPS37B', 'VPS37D', 'VPS4A', 'VPS51', 'VPS9D1', 'VRK1', 'VRK2', 'VRK3', 'VTA1', 'VWA5A', 'WAKMAR2', 'WARS2', 'WASF2', 'WASHC4', 'WBP1', 'WBP11P1', 'WDFY3', 'WDR1', 'WDR12', 'WDR13', 'WDR17', 'WDR18', 'WDR20', 'WDR3', 'WDR35', 'WDR36', 'WDR37', 'WDR38', 'WDR4', 'WDR43', 'WDR45', 'WDR46.11', 'WDR46.15', 'WDR46.3', 'WDR46.7', 'WDR49', 'WDR5', 'WDR5B', 'WDR6', 'WDR61', 'WDR62', 'WDR64', 'WDR73', 'WDR74', 'WDR75', 'WDR77', 'WDR82', 'WDR86', 'WDR90', 'WDR92', 'WDR93', 'WDSUB1', 'WFDC3', 'WFIKKN1', 'WFS1', 'WHRN', 'WIPF2', 'WNK3', 'WNK4', 'WNT7A', 'WRN', 'WTAP', 'WWC2', 'WWOX', 'WWP1', 'XK', 'XKRX', 'XPA', 'XPO1', 'XPO4', 'XPO5', 'XPO6', 'XPR1', 'XRCC5', 'XRN2', 'XRRA1', 'XXYLT1', 'YAF2', 'YARS1', 'YBEY', 'YDJC', 'YEATS2', 'YIF1A', 'YJEFN3', 'YJU2', 'YPEL2', 'YPEL3', 'YPEL4', 'YRDC', 'YTHDC1', 'YTHDC2', 'YTHDF1', 'YTHDF2', 'YTHDF3', 'YWHAG', 'YY1AP1', 'YY2', 'ZBED1', 'ZBED5-AS1', 'ZBED6', 'ZBED6CL', 'ZBED8', 'ZBTB10', 'ZBTB11-AS1', 'ZBTB12', 'ZBTB12.3', 'ZBTB14', 'ZBTB24', 'ZBTB38', 'ZBTB4', 'ZBTB40', 'ZBTB42', 'ZBTB44', 'ZBTB6', 'ZBTB8A', 'ZBTB8OS', 'ZBTB9.1', 'ZBTB9.3', 'ZC2HC1C', 'ZC3H11B', 'ZC3H12A', 'ZC3H14', 'ZC3H7A', 'ZC3HAV1', 'ZCCHC12', 'ZCCHC2', 'ZCCHC7', 'ZCCHC9', 'ZCRB1', 'ZDHHC1', 'ZDHHC13', 'ZDHHC20', 'ZDHHC21', 'ZDHHC23', 'ZDHHC24', 'ZDHHC9', 'ZEB2', 'ZFAND3', 'ZFAND6', 'ZFAT', 'ZFHX2', 'ZFHX3', 'ZFP14', 'ZFP36L1', 'ZFP62', 'ZFP64', 'ZFP91', 'ZFPL1', 'ZFPM1', 'ZFYVE1', 'ZFYVE26', 'ZFYVE27', 'ZFYVE9', 'ZGLP1', 'ZGPAT', 'ZHX1', 'ZHX1-C8orf76', 'ZHX2', 'ZKSCAN2', 'ZKSCAN3', 'ZKSCAN7-AS1', 'ZMYM5', 'ZMYND19', 'ZMYND8', 'ZNF106', 'ZNF121', 'ZNF124', 'ZNF133', 'ZNF143', 'ZNF146', 'ZNF155', 'ZNF160', 'ZNF174', 'ZNF175', 'ZNF182', 'ZNF189', 'ZNF192P2', 'ZNF200', 'ZNF202', 'ZNF205', 'ZNF207', 'ZNF22-AS1', 'ZNF224', 'ZNF226', 'ZNF23', 'ZNF232-AS1', 'ZNF233', 'ZNF234', 'ZNF239', 'ZNF250', 'ZNF252P', 'ZNF26', 'ZNF263', 'ZNF267', 'ZNF271P', 'ZNF274', 'ZNF280C', 'ZNF281', 'ZNF287', 'ZNF292', 'ZNF326', 'ZNF333', 'ZNF335', 'ZNF341', 'ZNF343', 'ZNF346', 'ZNF35', 'ZNF354B', 'ZNF365', 'ZNF367', 'ZNF37A', 'ZNF384', 'ZNF394', 'ZNF395', 'ZNF404', 'ZNF414', 'ZNF428', 'ZNF431', 'ZNF432', 'ZNF436', 'ZNF44', 'ZNF451', 'ZNF462', 'ZNF484', 'ZNF485', 'ZNF488', 'ZNF490', 'ZNF500', 'ZNF512B', 'ZNF513', 'ZNF516', 'ZNF519', 'ZNF552', 'ZNF57', 'ZNF580', 'ZNF584', 'ZNF587B', 'ZNF589', 'ZNF592', 'ZNF593', 'ZNF598', 'ZNF607', 'ZNF616', 'ZNF628', 'ZNF629', 'ZNF630', 'ZNF654', 'ZNF655', 'ZNF66.1', 'ZNF66.3', 'ZNF668', 'ZNF672', 'ZNF689', 'ZNF705G', 'ZNF706', 'ZNF707', 'ZNF710-AS1', 'ZNF721', 'ZNF746', 'ZNF747', 'ZNF75D', 'ZNF76', 'ZNF763', 'ZNF765', 'ZNF77', 'ZNF774', 'ZNF777', 'ZNF778', 'ZNF780A', 'ZNF781', 'ZNF783', 'ZNF784', 'ZNF786', 'ZNF789', 'ZNF792', 'ZNF8-ERVK3-1', 'ZNF80', 'ZNF800', 'ZNF804A', 'ZNF823', 'ZNF836', 'ZNF837', 'ZNF846', 'ZNF85', 'ZNF85.2', 'ZNF852', 'ZNF860', 'ZNF862', 'ZNF876P', 'ZNF890P', 'ZNFX1', 'ZNHIT2', 'ZNHIT6', 'ZNNT1', 'ZNRD1ASP.1', 'ZNRD1ASP.15', 'ZNRD1ASP.22', 'ZNRD1ASP.29', 'ZNRD1ASP.36', 'ZNRD1ASP.43', 'ZNRD1ASP.8', 'ZNRD2', 'ZNRF3', 'ZP3', 'ZRANB1', 'ZSCAN20', 'ZSCAN26', 'ZSCAN32', 'ZSWIM6', 'ZW10', 'ZWILCH', 'ZYG11A', 'ZYX', 'ZZZ3']\n"
     ]
    }
   ],
   "source": [
    "# Intersection of selected features from all three methods\n",
    "lasso_features = list(set(lasso_feature_importance['Feature']))\n",
    "rf_features = list(set(rf_feature_importance['Feature']))\n",
    "svmrfe_features = list(set(svmrfe_feature_importance['Feature']))\n",
    "ttest_features = list(set(ttest_feature_importance['Feature']))\n",
    "features = list(set(lasso_features + rf_features + svmrfe_features + ttest_features))\n",
    "# Print the intersection of selected features\n",
    "print(\"Number of Selected features:\", len(list(features)))\n",
    "print(\"Selected features:\")\n",
    "print(list(sorted(features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of selected dtaset: (44, 5710)\n",
      "Preview of selected dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A2ML1</th>\n",
       "      <th>AAAS</th>\n",
       "      <th>AAR2</th>\n",
       "      <th>AARSD1</th>\n",
       "      <th>AASDHPPT</th>\n",
       "      <th>AASS</th>\n",
       "      <th>ABCB10</th>\n",
       "      <th>ABCB6</th>\n",
       "      <th>ABCC6.1</th>\n",
       "      <th>ABCC6.3</th>\n",
       "      <th>...</th>\n",
       "      <th>ZSCAN20</th>\n",
       "      <th>ZSCAN26</th>\n",
       "      <th>ZSCAN32</th>\n",
       "      <th>ZSWIM6</th>\n",
       "      <th>ZW10</th>\n",
       "      <th>ZWILCH</th>\n",
       "      <th>ZYG11A</th>\n",
       "      <th>ZYX</th>\n",
       "      <th>ZZZ3</th>\n",
       "      <th>Condition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.214624</td>\n",
       "      <td>0.261221</td>\n",
       "      <td>-1.465140</td>\n",
       "      <td>-1.538158</td>\n",
       "      <td>0.085676</td>\n",
       "      <td>-1.138701</td>\n",
       "      <td>-0.444011</td>\n",
       "      <td>0.696294</td>\n",
       "      <td>1.183622</td>\n",
       "      <td>1.183622</td>\n",
       "      <td>...</td>\n",
       "      <td>1.011338</td>\n",
       "      <td>1.119590</td>\n",
       "      <td>-0.624863</td>\n",
       "      <td>-0.630246</td>\n",
       "      <td>-0.537385</td>\n",
       "      <td>-0.759360</td>\n",
       "      <td>-1.049655</td>\n",
       "      <td>-0.482260</td>\n",
       "      <td>0.838684</td>\n",
       "      <td>case</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.300474</td>\n",
       "      <td>-0.141556</td>\n",
       "      <td>-1.240023</td>\n",
       "      <td>-0.243450</td>\n",
       "      <td>1.743770</td>\n",
       "      <td>-0.355563</td>\n",
       "      <td>-0.585528</td>\n",
       "      <td>0.147281</td>\n",
       "      <td>-0.956626</td>\n",
       "      <td>-0.956626</td>\n",
       "      <td>...</td>\n",
       "      <td>1.554744</td>\n",
       "      <td>2.584008</td>\n",
       "      <td>-0.324500</td>\n",
       "      <td>0.424689</td>\n",
       "      <td>1.508251</td>\n",
       "      <td>0.917483</td>\n",
       "      <td>-1.049655</td>\n",
       "      <td>-1.766094</td>\n",
       "      <td>-0.384590</td>\n",
       "      <td>case</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.815573</td>\n",
       "      <td>-1.017158</td>\n",
       "      <td>1.275666</td>\n",
       "      <td>-0.492432</td>\n",
       "      <td>-1.572418</td>\n",
       "      <td>-1.948844</td>\n",
       "      <td>-1.632756</td>\n",
       "      <td>2.192920</td>\n",
       "      <td>-0.956626</td>\n",
       "      <td>-0.956626</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166041</td>\n",
       "      <td>-0.730202</td>\n",
       "      <td>-0.496136</td>\n",
       "      <td>1.751114</td>\n",
       "      <td>-1.716061</td>\n",
       "      <td>-0.450468</td>\n",
       "      <td>-1.449524</td>\n",
       "      <td>-1.845865</td>\n",
       "      <td>-0.697359</td>\n",
       "      <td>case</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.330672</td>\n",
       "      <td>-1.454959</td>\n",
       "      <td>-1.358209</td>\n",
       "      <td>-0.691618</td>\n",
       "      <td>-1.211759</td>\n",
       "      <td>0.157528</td>\n",
       "      <td>-0.755349</td>\n",
       "      <td>0.718857</td>\n",
       "      <td>-0.567490</td>\n",
       "      <td>-0.567490</td>\n",
       "      <td>...</td>\n",
       "      <td>2.732123</td>\n",
       "      <td>1.264105</td>\n",
       "      <td>-0.839408</td>\n",
       "      <td>0.781505</td>\n",
       "      <td>-0.556868</td>\n",
       "      <td>1.535267</td>\n",
       "      <td>-0.783076</td>\n",
       "      <td>-0.492133</td>\n",
       "      <td>-0.085722</td>\n",
       "      <td>case</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.729723</td>\n",
       "      <td>0.383806</td>\n",
       "      <td>-0.243877</td>\n",
       "      <td>0.071928</td>\n",
       "      <td>0.699264</td>\n",
       "      <td>1.372742</td>\n",
       "      <td>2.810888</td>\n",
       "      <td>-1.883316</td>\n",
       "      <td>3.323870</td>\n",
       "      <td>3.323870</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.826447</td>\n",
       "      <td>-0.614590</td>\n",
       "      <td>0.340590</td>\n",
       "      <td>-1.281823</td>\n",
       "      <td>1.254981</td>\n",
       "      <td>0.888065</td>\n",
       "      <td>1.349557</td>\n",
       "      <td>1.429471</td>\n",
       "      <td>0.720527</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.729723</td>\n",
       "      <td>1.119312</td>\n",
       "      <td>0.583430</td>\n",
       "      <td>-0.226851</td>\n",
       "      <td>1.411214</td>\n",
       "      <td>-0.382568</td>\n",
       "      <td>-0.274190</td>\n",
       "      <td>-1.386948</td>\n",
       "      <td>-0.567490</td>\n",
       "      <td>-0.567490</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.313230</td>\n",
       "      <td>-1.173381</td>\n",
       "      <td>0.254772</td>\n",
       "      <td>-1.204255</td>\n",
       "      <td>0.037341</td>\n",
       "      <td>-0.538723</td>\n",
       "      <td>1.882715</td>\n",
       "      <td>1.009293</td>\n",
       "      <td>-0.308135</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.729723</td>\n",
       "      <td>-0.736965</td>\n",
       "      <td>1.894739</td>\n",
       "      <td>1.897800</td>\n",
       "      <td>-1.094662</td>\n",
       "      <td>-1.084692</td>\n",
       "      <td>-1.080839</td>\n",
       "      <td>0.297696</td>\n",
       "      <td>-0.891770</td>\n",
       "      <td>-0.891770</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.403798</td>\n",
       "      <td>-1.818882</td>\n",
       "      <td>-0.303045</td>\n",
       "      <td>0.347120</td>\n",
       "      <td>-0.732208</td>\n",
       "      <td>-0.612268</td>\n",
       "      <td>-0.649787</td>\n",
       "      <td>-0.863738</td>\n",
       "      <td>-0.259482</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.815573</td>\n",
       "      <td>1.872330</td>\n",
       "      <td>0.009380</td>\n",
       "      <td>0.470300</td>\n",
       "      <td>0.216825</td>\n",
       "      <td>2.506943</td>\n",
       "      <td>1.820267</td>\n",
       "      <td>-1.251575</td>\n",
       "      <td>0.145926</td>\n",
       "      <td>0.145926</td>\n",
       "      <td>...</td>\n",
       "      <td>0.800014</td>\n",
       "      <td>-0.325560</td>\n",
       "      <td>1.198771</td>\n",
       "      <td>-0.490622</td>\n",
       "      <td>2.160906</td>\n",
       "      <td>1.594104</td>\n",
       "      <td>2.815742</td>\n",
       "      <td>1.902172</td>\n",
       "      <td>2.068909</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.815573</td>\n",
       "      <td>1.662185</td>\n",
       "      <td>-1.104952</td>\n",
       "      <td>-0.359641</td>\n",
       "      <td>0.394812</td>\n",
       "      <td>0.103518</td>\n",
       "      <td>0.985315</td>\n",
       "      <td>1.320515</td>\n",
       "      <td>-0.372922</td>\n",
       "      <td>-0.372922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.769825</td>\n",
       "      <td>2.343150</td>\n",
       "      <td>-1.204135</td>\n",
       "      <td>-0.288944</td>\n",
       "      <td>-1.082888</td>\n",
       "      <td>-1.759582</td>\n",
       "      <td>-1.182945</td>\n",
       "      <td>-0.490158</td>\n",
       "      <td>0.199245</td>\n",
       "      <td>case</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.300474</td>\n",
       "      <td>0.173661</td>\n",
       "      <td>0.048775</td>\n",
       "      <td>-0.542228</td>\n",
       "      <td>0.652426</td>\n",
       "      <td>-0.922663</td>\n",
       "      <td>-0.217583</td>\n",
       "      <td>1.365639</td>\n",
       "      <td>-0.826914</td>\n",
       "      <td>-0.826914</td>\n",
       "      <td>...</td>\n",
       "      <td>1.433987</td>\n",
       "      <td>1.254470</td>\n",
       "      <td>-0.367409</td>\n",
       "      <td>0.874588</td>\n",
       "      <td>1.576438</td>\n",
       "      <td>0.093771</td>\n",
       "      <td>-1.982683</td>\n",
       "      <td>-0.261114</td>\n",
       "      <td>-0.933673</td>\n",
       "      <td>case</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 5710 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      A2ML1      AAAS      AAR2    AARSD1  AASDHPPT      AASS    ABCB10  \\\n",
       "0 -0.214624  0.261221 -1.465140 -1.538158  0.085676 -1.138701 -0.444011   \n",
       "1  0.300474 -0.141556 -1.240023 -0.243450  1.743770 -0.355563 -0.585528   \n",
       "2  0.815573 -1.017158  1.275666 -0.492432 -1.572418 -1.948844 -1.632756   \n",
       "3  1.330672 -1.454959 -1.358209 -0.691618 -1.211759  0.157528 -0.755349   \n",
       "4 -0.729723  0.383806 -0.243877  0.071928  0.699264  1.372742  2.810888   \n",
       "5 -0.729723  1.119312  0.583430 -0.226851  1.411214 -0.382568 -0.274190   \n",
       "6 -0.729723 -0.736965  1.894739  1.897800 -1.094662 -1.084692 -1.080839   \n",
       "7  0.815573  1.872330  0.009380  0.470300  0.216825  2.506943  1.820267   \n",
       "8  0.815573  1.662185 -1.104952 -0.359641  0.394812  0.103518  0.985315   \n",
       "9  0.300474  0.173661  0.048775 -0.542228  0.652426 -0.922663 -0.217583   \n",
       "\n",
       "      ABCB6   ABCC6.1   ABCC6.3  ...   ZSCAN20   ZSCAN26   ZSCAN32    ZSWIM6  \\\n",
       "0  0.696294  1.183622  1.183622  ...  1.011338  1.119590 -0.624863 -0.630246   \n",
       "1  0.147281 -0.956626 -0.956626  ...  1.554744  2.584008 -0.324500  0.424689   \n",
       "2  2.192920 -0.956626 -0.956626  ...  0.166041 -0.730202 -0.496136  1.751114   \n",
       "3  0.718857 -0.567490 -0.567490  ...  2.732123  1.264105 -0.839408  0.781505   \n",
       "4 -1.883316  3.323870  3.323870  ... -1.826447 -0.614590  0.340590 -1.281823   \n",
       "5 -1.386948 -0.567490 -0.567490  ... -1.313230 -1.173381  0.254772 -1.204255   \n",
       "6  0.297696 -0.891770 -0.891770  ... -1.403798 -1.818882 -0.303045  0.347120   \n",
       "7 -1.251575  0.145926  0.145926  ...  0.800014 -0.325560  1.198771 -0.490622   \n",
       "8  1.320515 -0.372922 -0.372922  ...  0.769825  2.343150 -1.204135 -0.288944   \n",
       "9  1.365639 -0.826914 -0.826914  ...  1.433987  1.254470 -0.367409  0.874588   \n",
       "\n",
       "       ZW10    ZWILCH    ZYG11A       ZYX      ZZZ3  Condition  \n",
       "0 -0.537385 -0.759360 -1.049655 -0.482260  0.838684       case  \n",
       "1  1.508251  0.917483 -1.049655 -1.766094 -0.384590       case  \n",
       "2 -1.716061 -0.450468 -1.449524 -1.845865 -0.697359       case  \n",
       "3 -0.556868  1.535267 -0.783076 -0.492133 -0.085722       case  \n",
       "4  1.254981  0.888065  1.349557  1.429471  0.720527    control  \n",
       "5  0.037341 -0.538723  1.882715  1.009293 -0.308135    control  \n",
       "6 -0.732208 -0.612268 -0.649787 -0.863738 -0.259482    control  \n",
       "7  2.160906  1.594104  2.815742  1.902172  2.068909    control  \n",
       "8 -1.082888 -1.759582 -1.182945 -0.490158  0.199245       case  \n",
       "9  1.576438  0.093771 -1.982683 -0.261114 -0.933673       case  \n",
       "\n",
       "[10 rows x 5710 columns]"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new DataFrame with the selected features and target for future uses\n",
    "selected_df = pd.concat([X[list(sorted(features))], pd.Series(label_encoder.inverse_transform(y), name='Condition')], axis=1)\n",
    "selected_df.rename({0:\"Condition\"})\n",
    "print(\"Shape of selected dtaset:\", selected_df.shape)\n",
    "print(\"Preview of selected dataset:\")\n",
    "selected_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_df.to_csv(\"Data/clean_t1d_selected_knnimputed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Machine Learning Model Training with K-Fold Cross Validation**\n",
    "\n",
    "A comprehensive evaluation of multiple machine learning models is conducted using 5-fold stratified cross-validation. Models include Logistic Regression, SVM, Random Forest, XGBoost, and others. To reduce dimensionality and multicollinearity, PCA is applied to retain 40 principal components. Each model is evaluated using accuracy, precision, recall, F1-score, and ROC AUC. An ensemble stacking classifier combines predictions from top-performing models using KNN as the final estimator, aiming to improve generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data: (44, 5710)\n",
      "Preview of data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A2ML1</th>\n",
       "      <th>AAAS</th>\n",
       "      <th>AAR2</th>\n",
       "      <th>AARSD1</th>\n",
       "      <th>AASDHPPT</th>\n",
       "      <th>AASS</th>\n",
       "      <th>ABCB10</th>\n",
       "      <th>ABCB6</th>\n",
       "      <th>ABCC6.1</th>\n",
       "      <th>ABCC6.3</th>\n",
       "      <th>...</th>\n",
       "      <th>ZSCAN20</th>\n",
       "      <th>ZSCAN26</th>\n",
       "      <th>ZSCAN32</th>\n",
       "      <th>ZSWIM6</th>\n",
       "      <th>ZW10</th>\n",
       "      <th>ZWILCH</th>\n",
       "      <th>ZYG11A</th>\n",
       "      <th>ZYX</th>\n",
       "      <th>ZZZ3</th>\n",
       "      <th>Condition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.214624</td>\n",
       "      <td>0.261221</td>\n",
       "      <td>-1.465140</td>\n",
       "      <td>-1.538158</td>\n",
       "      <td>0.085676</td>\n",
       "      <td>-1.138701</td>\n",
       "      <td>-0.444011</td>\n",
       "      <td>0.696294</td>\n",
       "      <td>1.183622</td>\n",
       "      <td>1.183622</td>\n",
       "      <td>...</td>\n",
       "      <td>1.011338</td>\n",
       "      <td>1.119590</td>\n",
       "      <td>-0.624863</td>\n",
       "      <td>-0.630246</td>\n",
       "      <td>-0.537385</td>\n",
       "      <td>-0.759360</td>\n",
       "      <td>-1.049655</td>\n",
       "      <td>-0.482260</td>\n",
       "      <td>0.838684</td>\n",
       "      <td>case</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.300474</td>\n",
       "      <td>-0.141556</td>\n",
       "      <td>-1.240023</td>\n",
       "      <td>-0.243450</td>\n",
       "      <td>1.743770</td>\n",
       "      <td>-0.355563</td>\n",
       "      <td>-0.585528</td>\n",
       "      <td>0.147281</td>\n",
       "      <td>-0.956626</td>\n",
       "      <td>-0.956626</td>\n",
       "      <td>...</td>\n",
       "      <td>1.554744</td>\n",
       "      <td>2.584008</td>\n",
       "      <td>-0.324500</td>\n",
       "      <td>0.424689</td>\n",
       "      <td>1.508251</td>\n",
       "      <td>0.917483</td>\n",
       "      <td>-1.049655</td>\n",
       "      <td>-1.766094</td>\n",
       "      <td>-0.384590</td>\n",
       "      <td>case</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.815573</td>\n",
       "      <td>-1.017158</td>\n",
       "      <td>1.275666</td>\n",
       "      <td>-0.492432</td>\n",
       "      <td>-1.572418</td>\n",
       "      <td>-1.948844</td>\n",
       "      <td>-1.632756</td>\n",
       "      <td>2.192920</td>\n",
       "      <td>-0.956626</td>\n",
       "      <td>-0.956626</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166041</td>\n",
       "      <td>-0.730202</td>\n",
       "      <td>-0.496136</td>\n",
       "      <td>1.751114</td>\n",
       "      <td>-1.716061</td>\n",
       "      <td>-0.450468</td>\n",
       "      <td>-1.449524</td>\n",
       "      <td>-1.845865</td>\n",
       "      <td>-0.697359</td>\n",
       "      <td>case</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.330672</td>\n",
       "      <td>-1.454959</td>\n",
       "      <td>-1.358209</td>\n",
       "      <td>-0.691618</td>\n",
       "      <td>-1.211759</td>\n",
       "      <td>0.157528</td>\n",
       "      <td>-0.755349</td>\n",
       "      <td>0.718857</td>\n",
       "      <td>-0.567490</td>\n",
       "      <td>-0.567490</td>\n",
       "      <td>...</td>\n",
       "      <td>2.732123</td>\n",
       "      <td>1.264105</td>\n",
       "      <td>-0.839408</td>\n",
       "      <td>0.781505</td>\n",
       "      <td>-0.556868</td>\n",
       "      <td>1.535267</td>\n",
       "      <td>-0.783076</td>\n",
       "      <td>-0.492133</td>\n",
       "      <td>-0.085722</td>\n",
       "      <td>case</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.729723</td>\n",
       "      <td>0.383806</td>\n",
       "      <td>-0.243877</td>\n",
       "      <td>0.071928</td>\n",
       "      <td>0.699264</td>\n",
       "      <td>1.372742</td>\n",
       "      <td>2.810888</td>\n",
       "      <td>-1.883316</td>\n",
       "      <td>3.323870</td>\n",
       "      <td>3.323870</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.826447</td>\n",
       "      <td>-0.614590</td>\n",
       "      <td>0.340590</td>\n",
       "      <td>-1.281823</td>\n",
       "      <td>1.254981</td>\n",
       "      <td>0.888065</td>\n",
       "      <td>1.349557</td>\n",
       "      <td>1.429471</td>\n",
       "      <td>0.720527</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.729723</td>\n",
       "      <td>1.119312</td>\n",
       "      <td>0.583430</td>\n",
       "      <td>-0.226851</td>\n",
       "      <td>1.411214</td>\n",
       "      <td>-0.382568</td>\n",
       "      <td>-0.274190</td>\n",
       "      <td>-1.386948</td>\n",
       "      <td>-0.567490</td>\n",
       "      <td>-0.567490</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.313230</td>\n",
       "      <td>-1.173381</td>\n",
       "      <td>0.254772</td>\n",
       "      <td>-1.204255</td>\n",
       "      <td>0.037341</td>\n",
       "      <td>-0.538723</td>\n",
       "      <td>1.882715</td>\n",
       "      <td>1.009293</td>\n",
       "      <td>-0.308135</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.729723</td>\n",
       "      <td>-0.736965</td>\n",
       "      <td>1.894739</td>\n",
       "      <td>1.897800</td>\n",
       "      <td>-1.094662</td>\n",
       "      <td>-1.084692</td>\n",
       "      <td>-1.080839</td>\n",
       "      <td>0.297696</td>\n",
       "      <td>-0.891770</td>\n",
       "      <td>-0.891770</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.403798</td>\n",
       "      <td>-1.818882</td>\n",
       "      <td>-0.303045</td>\n",
       "      <td>0.347120</td>\n",
       "      <td>-0.732208</td>\n",
       "      <td>-0.612268</td>\n",
       "      <td>-0.649787</td>\n",
       "      <td>-0.863738</td>\n",
       "      <td>-0.259482</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.815573</td>\n",
       "      <td>1.872330</td>\n",
       "      <td>0.009380</td>\n",
       "      <td>0.470300</td>\n",
       "      <td>0.216825</td>\n",
       "      <td>2.506943</td>\n",
       "      <td>1.820267</td>\n",
       "      <td>-1.251575</td>\n",
       "      <td>0.145926</td>\n",
       "      <td>0.145926</td>\n",
       "      <td>...</td>\n",
       "      <td>0.800014</td>\n",
       "      <td>-0.325560</td>\n",
       "      <td>1.198771</td>\n",
       "      <td>-0.490622</td>\n",
       "      <td>2.160906</td>\n",
       "      <td>1.594104</td>\n",
       "      <td>2.815742</td>\n",
       "      <td>1.902172</td>\n",
       "      <td>2.068909</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.815573</td>\n",
       "      <td>1.662185</td>\n",
       "      <td>-1.104952</td>\n",
       "      <td>-0.359641</td>\n",
       "      <td>0.394812</td>\n",
       "      <td>0.103518</td>\n",
       "      <td>0.985315</td>\n",
       "      <td>1.320515</td>\n",
       "      <td>-0.372922</td>\n",
       "      <td>-0.372922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.769825</td>\n",
       "      <td>2.343150</td>\n",
       "      <td>-1.204135</td>\n",
       "      <td>-0.288944</td>\n",
       "      <td>-1.082888</td>\n",
       "      <td>-1.759582</td>\n",
       "      <td>-1.182945</td>\n",
       "      <td>-0.490158</td>\n",
       "      <td>0.199245</td>\n",
       "      <td>case</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.300474</td>\n",
       "      <td>0.173661</td>\n",
       "      <td>0.048775</td>\n",
       "      <td>-0.542228</td>\n",
       "      <td>0.652426</td>\n",
       "      <td>-0.922663</td>\n",
       "      <td>-0.217583</td>\n",
       "      <td>1.365639</td>\n",
       "      <td>-0.826914</td>\n",
       "      <td>-0.826914</td>\n",
       "      <td>...</td>\n",
       "      <td>1.433987</td>\n",
       "      <td>1.254470</td>\n",
       "      <td>-0.367409</td>\n",
       "      <td>0.874588</td>\n",
       "      <td>1.576438</td>\n",
       "      <td>0.093771</td>\n",
       "      <td>-1.982683</td>\n",
       "      <td>-0.261114</td>\n",
       "      <td>-0.933673</td>\n",
       "      <td>case</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 5710 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      A2ML1      AAAS      AAR2    AARSD1  AASDHPPT      AASS    ABCB10  \\\n",
       "0 -0.214624  0.261221 -1.465140 -1.538158  0.085676 -1.138701 -0.444011   \n",
       "1  0.300474 -0.141556 -1.240023 -0.243450  1.743770 -0.355563 -0.585528   \n",
       "2  0.815573 -1.017158  1.275666 -0.492432 -1.572418 -1.948844 -1.632756   \n",
       "3  1.330672 -1.454959 -1.358209 -0.691618 -1.211759  0.157528 -0.755349   \n",
       "4 -0.729723  0.383806 -0.243877  0.071928  0.699264  1.372742  2.810888   \n",
       "5 -0.729723  1.119312  0.583430 -0.226851  1.411214 -0.382568 -0.274190   \n",
       "6 -0.729723 -0.736965  1.894739  1.897800 -1.094662 -1.084692 -1.080839   \n",
       "7  0.815573  1.872330  0.009380  0.470300  0.216825  2.506943  1.820267   \n",
       "8  0.815573  1.662185 -1.104952 -0.359641  0.394812  0.103518  0.985315   \n",
       "9  0.300474  0.173661  0.048775 -0.542228  0.652426 -0.922663 -0.217583   \n",
       "\n",
       "      ABCB6   ABCC6.1   ABCC6.3  ...   ZSCAN20   ZSCAN26   ZSCAN32    ZSWIM6  \\\n",
       "0  0.696294  1.183622  1.183622  ...  1.011338  1.119590 -0.624863 -0.630246   \n",
       "1  0.147281 -0.956626 -0.956626  ...  1.554744  2.584008 -0.324500  0.424689   \n",
       "2  2.192920 -0.956626 -0.956626  ...  0.166041 -0.730202 -0.496136  1.751114   \n",
       "3  0.718857 -0.567490 -0.567490  ...  2.732123  1.264105 -0.839408  0.781505   \n",
       "4 -1.883316  3.323870  3.323870  ... -1.826447 -0.614590  0.340590 -1.281823   \n",
       "5 -1.386948 -0.567490 -0.567490  ... -1.313230 -1.173381  0.254772 -1.204255   \n",
       "6  0.297696 -0.891770 -0.891770  ... -1.403798 -1.818882 -0.303045  0.347120   \n",
       "7 -1.251575  0.145926  0.145926  ...  0.800014 -0.325560  1.198771 -0.490622   \n",
       "8  1.320515 -0.372922 -0.372922  ...  0.769825  2.343150 -1.204135 -0.288944   \n",
       "9  1.365639 -0.826914 -0.826914  ...  1.433987  1.254470 -0.367409  0.874588   \n",
       "\n",
       "       ZW10    ZWILCH    ZYG11A       ZYX      ZZZ3  Condition  \n",
       "0 -0.537385 -0.759360 -1.049655 -0.482260  0.838684       case  \n",
       "1  1.508251  0.917483 -1.049655 -1.766094 -0.384590       case  \n",
       "2 -1.716061 -0.450468 -1.449524 -1.845865 -0.697359       case  \n",
       "3 -0.556868  1.535267 -0.783076 -0.492133 -0.085722       case  \n",
       "4  1.254981  0.888065  1.349557  1.429471  0.720527    control  \n",
       "5  0.037341 -0.538723  1.882715  1.009293 -0.308135    control  \n",
       "6 -0.732208 -0.612268 -0.649787 -0.863738 -0.259482    control  \n",
       "7  2.160906  1.594104  2.815742  1.902172  2.068909    control  \n",
       "8 -1.082888 -1.759582 -1.182945 -0.490158  0.199245       case  \n",
       "9  1.576438  0.093771 -1.982683 -0.261114 -0.933673       case  \n",
       "\n",
       "[10 rows x 5710 columns]"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "data = pd.read_csv(\"Data/clean_t1d_selected_knnimputed.csv\")\n",
    "print(\"Shape of data:\", data.shape)\n",
    "print(\"Preview of data:\")\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label map:\n",
      "  case:0\n",
      "  control:1\n"
     ]
    }
   ],
   "source": [
    "# Data preparation\n",
    "X = data.drop(columns=['Condition'], axis=1)\n",
    "y = data['Condition']\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Print label map (class name -> encoded label)\n",
    "label_map = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "print(\"Label map:\")\n",
    "for label_name, encoded_label in label_map.items():\n",
    "    print(f\"  {label_name}:{encoded_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensionality reductuin using PCA\n",
    "pca = PCA(n_components=40)\n",
    "X_scaled_pca = pca.fit_transform(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6560cd041d814c608af322583f0b5eed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Cross Validating Models ...:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross Validating Logistic Regression ...\n",
      "Model: Logistic Regression\n",
      "  Accuracy : 0.6806\n",
      "  Precision: 0.8000\n",
      "  Recall   : 0.6950\n",
      "  F1 Score : 0.6523\n",
      "  ROC AUC  : 0.9075\n",
      "Completed Cross Validating Logistic Regression\n",
      "----------------------------------------\n",
      "\n",
      "Cross Validating SVM ...\n",
      "Model: SVM\n",
      "  Accuracy : 0.6806\n",
      "  Precision: 0.8000\n",
      "  Recall   : 0.6950\n",
      "  F1 Score : 0.6523\n",
      "  ROC AUC  : 0.6000\n",
      "Completed Cross Validating SVM\n",
      "----------------------------------------\n",
      "\n",
      "Cross Validating KNN ...\n",
      "Model: KNN\n",
      "  Accuracy : 0.6139\n",
      "  Precision: 0.6367\n",
      "  Recall   : 0.6250\n",
      "  F1 Score : 0.6088\n",
      "  ROC AUC  : 0.6125\n",
      "Completed Cross Validating KNN\n",
      "----------------------------------------\n",
      "\n",
      "Cross Validating Random Forest ...\n",
      "Model: Random Forest\n",
      "  Accuracy : 0.8639\n",
      "  Precision: 0.8898\n",
      "  Recall   : 0.8550\n",
      "  F1 Score : 0.8562\n",
      "  ROC AUC  : 0.9500\n",
      "Completed Cross Validating Random Forest\n",
      "----------------------------------------\n",
      "\n",
      "Cross Validating XGBoost ...\n",
      "Model: XGBoost\n",
      "  Accuracy : 0.8139\n",
      "  Precision: 0.8364\n",
      "  Recall   : 0.8050\n",
      "  F1 Score : 0.8054\n",
      "  ROC AUC  : 0.8425\n",
      "Completed Cross Validating XGBoost\n",
      "----------------------------------------\n",
      "\n",
      "Cross Validating Gradient Boosting ...\n",
      "Model: Gradient Boosting\n",
      "  Accuracy : 0.8389\n",
      "  Precision: 0.8714\n",
      "  Recall   : 0.8300\n",
      "  F1 Score : 0.8265\n",
      "  ROC AUC  : 0.9150\n",
      "Completed Cross Validating Gradient Boosting\n",
      "----------------------------------------\n",
      "\n",
      "Cross Validating CatBoost ...\n",
      "Model: CatBoost\n",
      "  Accuracy : 0.8611\n",
      "  Precision: 0.8883\n",
      "  Recall   : 0.8550\n",
      "  F1 Score : 0.8549\n",
      "  ROC AUC  : 0.9350\n",
      "Completed Cross Validating CatBoost\n",
      "----------------------------------------\n",
      "\n",
      "Cross Validating AdaBoost ...\n",
      "Model: AdaBoost\n",
      "  Accuracy : 0.8861\n",
      "  Precision: 0.8967\n",
      "  Recall   : 0.8800\n",
      "  F1 Score : 0.8811\n",
      "  ROC AUC  : 0.9437\n",
      "Completed Cross Validating AdaBoost\n",
      "----------------------------------------\n",
      "\n",
      "Cross Validating Naive Bayes ...\n",
      "Model: Naive Bayes\n",
      "  Accuracy : 0.5694\n",
      "  Precision: 0.6833\n",
      "  Recall   : 0.5900\n",
      "  F1 Score : 0.5257\n",
      "  ROC AUC  : 0.8075\n",
      "Completed Cross Validating Naive Bayes\n",
      "----------------------------------------\n",
      "\n",
      "Cross Validating MLP ...\n",
      "Model: MLP\n",
      "  Accuracy : 0.6583\n",
      "  Precision: 0.7929\n",
      "  Recall   : 0.6750\n",
      "  F1 Score : 0.6225\n",
      "  ROC AUC  : 0.9250\n",
      "Completed Cross Validating MLP\n",
      "----------------------------------------\n",
      "\n",
      "Cross Validating Ensemble ...\n",
      "Model: Ensemble\n",
      "  Accuracy : 0.8611\n",
      "  Precision: 0.8833\n",
      "  Recall   : 0.8550\n",
      "  F1 Score : 0.8532\n",
      "  ROC AUC  : 0.9375\n",
      "Completed Cross Validating Ensemble\n",
      "----------------------------------------\n",
      "\n",
      "All Cross Validation Completed.\n",
      "\n",
      "Summary of Model Cross Validation Performance:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>ROC AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.886111</td>\n",
       "      <td>0.896667</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.881097</td>\n",
       "      <td>0.94375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.863889</td>\n",
       "      <td>0.889762</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.856227</td>\n",
       "      <td>0.95000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ensemble</td>\n",
       "      <td>0.861111</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.853160</td>\n",
       "      <td>0.93750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.861111</td>\n",
       "      <td>0.888333</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.854913</td>\n",
       "      <td>0.93500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.838889</td>\n",
       "      <td>0.871429</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.826537</td>\n",
       "      <td>0.91500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.813889</td>\n",
       "      <td>0.836429</td>\n",
       "      <td>0.805</td>\n",
       "      <td>0.805433</td>\n",
       "      <td>0.84250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.680556</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0.652338</td>\n",
       "      <td>0.90750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.680556</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0.652338</td>\n",
       "      <td>0.60000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.658333</td>\n",
       "      <td>0.792857</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.622468</td>\n",
       "      <td>0.92500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.613889</td>\n",
       "      <td>0.636667</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.608810</td>\n",
       "      <td>0.61250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.569444</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.525714</td>\n",
       "      <td>0.80750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model  Accuracy  Precision  Recall  F1 Score  ROC AUC\n",
       "0              AdaBoost  0.886111   0.896667   0.880  0.881097  0.94375\n",
       "1         Random Forest  0.863889   0.889762   0.855  0.856227  0.95000\n",
       "2              Ensemble  0.861111   0.883333   0.855  0.853160  0.93750\n",
       "3              CatBoost  0.861111   0.888333   0.855  0.854913  0.93500\n",
       "4     Gradient Boosting  0.838889   0.871429   0.830  0.826537  0.91500\n",
       "5               XGBoost  0.813889   0.836429   0.805  0.805433  0.84250\n",
       "6   Logistic Regression  0.680556   0.800000   0.695  0.652338  0.90750\n",
       "7                   SVM  0.680556   0.800000   0.695  0.652338  0.60000\n",
       "8                   MLP  0.658333   0.792857   0.675  0.622468  0.92500\n",
       "9                   KNN  0.613889   0.636667   0.625  0.608810  0.61250\n",
       "10          Naive Bayes  0.569444   0.683333   0.590  0.525714  0.80750"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the models dictionary\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "    'SVM': SVC(probability=True),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'XGBoost': XGBClassifier(eval_metric='logloss', random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
    "    'CatBoost': CatBoostClassifier(random_state=42, verbose=0),\n",
    "    'AdaBoost': AdaBoostClassifier(random_state=42),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'MLP': MLPClassifier(hidden_layer_sizes=(200, 50, 25), max_iter=1000, random_state=42)\n",
    "}\n",
    "\n",
    "# Define estimators for the stacking classifier (using strong models)\n",
    "estimators = [\n",
    "    ('Random Forest', models['Random Forest']),\n",
    "    ('XGBoost', models['XGBoost']),\n",
    "    ('CatBoost', models['CatBoost']),\n",
    "    ('AdaBoost', models['AdaBoost']),\n",
    "    ('Gradient Boosting', models['Gradient Boosting'])\n",
    "]\n",
    "\n",
    "# Stacking classifier with Logistic Regression as meta-learner\n",
    "stacking_model = StackingClassifier(\n",
    "    estimators=estimators,\n",
    "    final_estimator=models['KNN'],\n",
    "    cv=5,  # Cross-validation for meta-learner\n",
    "    n_jobs=-1,  # Use all available cores\n",
    "    passthrough=False  # Do not pass original features to meta-learner\n",
    ")\n",
    "models['Ensemble'] = stacking_model\n",
    "\n",
    "# Define the number of classes based on y_encoded\n",
    "n_classes = len(np.unique(y_encoded))\n",
    "\n",
    "# Define custom scoring metrics (with macro average and zero_division=0)\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'precision': make_scorer(precision_score, average='macro', zero_division=0),\n",
    "    'recall': make_scorer(recall_score, average='macro', zero_division=0),\n",
    "    'f1': make_scorer(f1_score, average='macro', zero_division=0),\n",
    "}\n",
    "\n",
    "# Add ROC AUC scorer based on number of classes\n",
    "if n_classes == 2:\n",
    "    scoring['roc_auc'] = 'roc_auc'\n",
    "else:\n",
    "    scoring['roc_auc'] = 'roc_auc_ovr'  # One-vs-Rest for multi-class\n",
    "\n",
    "# Define the cross-validation strategy (5-fold stratified)\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "results = []  # List to store performance metrics for each model\n",
    "\n",
    "# Train each model using k-fold CV and evaluate its performance\n",
    "for name, model in tqdm(models.items(), desc=\"Cross Validating Models ...\"):\n",
    "    print(f\"\\nCross Validating {name} ...\")\n",
    "    cv_results = cross_validate(model, X_scaled_pca, y_encoded, cv=cv, scoring=scoring, n_jobs=-1)\n",
    "    \n",
    "    # Calculate mean performance metrics across folds\n",
    "    accuracy = cv_results['test_accuracy'].mean()\n",
    "    precision = cv_results['test_precision'].mean()\n",
    "    recall = cv_results['test_recall'].mean()\n",
    "    f1 = cv_results['test_f1'].mean()\n",
    "    roc_auc = cv_results['test_roc_auc'].mean() if 'test_roc_auc' in cv_results else np.nan\n",
    "    \n",
    "    # Print performance metrics\n",
    "    print(f\"Model: {name}\")\n",
    "    print(f\"  Accuracy : {accuracy:.4f}\")\n",
    "    print(f\"  Precision: {precision:.4f}\")\n",
    "    print(f\"  Recall   : {recall:.4f}\")\n",
    "    print(f\"  F1 Score : {f1:.4f}\")\n",
    "    if not np.isnan(roc_auc):\n",
    "        print(f\"  ROC AUC  : {roc_auc:.4f}\")\n",
    "    else:\n",
    "        print(\"  ROC AUC  : Not available\")\n",
    "    print(f\"Completed Cross Validating {name}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Append results to list\n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'ROC AUC': roc_auc\n",
    "    })\n",
    "\n",
    "print(\"\\nAll Cross Validation Completed.\")\n",
    "\n",
    "# Store the results in a DataFrame and print\n",
    "results_df = pd.DataFrame(results).sort_values(by='Accuracy', ascending=False).reset_index(drop=True)\n",
    "print(\"\\nSummary of Model Cross Validation Performance:\")\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance for Base Model Saved\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Save the model results\n",
    "results_df.to_csv('results/t1d_base_predictive_model_performance.csv', index=False)\n",
    "print(\"Performance for Base Model Saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the performance metrics\n",
    "# Melt the results_df so that each row represents a metric score for a given model\n",
    "results_df_top = results_df.nlargest(n=5, columns=['Accuracy'])\n",
    "results_melted = results_df_top.melt(id_vars='Model', var_name='Metric', value_name='Score')\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(data=results_melted, x='Model', y='Score', hue='Metric')\n",
    "plt.title(\"Performance Metrics for Various Models\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.grid(True, axis='y', linestyle='--')\n",
    "plt.ylim([0, 1])\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig('results/t1d_predictive_model_performance.png')\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Hyperparameter Optimization**\n",
    "\n",
    "To further improve model performance, hyperparameter tuning is performed using Optuna, a Bayesian optimization framework. Five top-performing models—AdaBoost, Random Forest, CatBoost, Gradient Boosting, and XGBoost—are tuned over 100 trials each. The objective is to maximize cross-validation accuracy. Optimal hyperparameters are identified and used to retrain the models. A new stacking ensemble is built using these tuned models, and their performance is re-evaluated using the same cross-validation setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-10 20:05:39,834] A new study created in memory with name: no-name-d3c9727a-7002-4771-946d-a1054b4f4ea9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting tuning for AdaBoost ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e54e73169a06403f9b6b8f851832bf11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-10 20:05:40,890] Trial 0 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 277, 'learning_rate': 0.4211265710634895}. Best is trial 0 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:05:41,783] Trial 1 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 317, 'learning_rate': 0.32377416879967885}. Best is trial 0 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:05:42,878] Trial 2 finished with value: 0.8416666666666666 and parameters: {'n_estimators': 453, 'learning_rate': 0.31871557822332863}. Best is trial 0 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:05:43,540] Trial 3 finished with value: 0.836111111111111 and parameters: {'n_estimators': 125, 'learning_rate': 0.05238532577530695}. Best is trial 0 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:05:43,957] Trial 4 finished with value: 0.836111111111111 and parameters: {'n_estimators': 379, 'learning_rate': 0.0161138923453789}. Best is trial 0 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:05:44,324] Trial 5 finished with value: 0.8138888888888889 and parameters: {'n_estimators': 342, 'learning_rate': 0.01231239294184859}. Best is trial 0 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:05:44,690] Trial 6 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 330, 'learning_rate': 0.9672763675076852}. Best is trial 0 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:05:44,824] Trial 7 finished with value: 0.836111111111111 and parameters: {'n_estimators': 113, 'learning_rate': 0.05875364137232057}. Best is trial 0 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:05:45,069] Trial 8 finished with value: 0.836111111111111 and parameters: {'n_estimators': 222, 'learning_rate': 0.04189002062391549}. Best is trial 0 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:05:45,295] Trial 9 finished with value: 0.836111111111111 and parameters: {'n_estimators': 207, 'learning_rate': 0.03456972966473611}. Best is trial 0 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:05:45,817] Trial 10 finished with value: 0.8416666666666666 and parameters: {'n_estimators': 490, 'learning_rate': 0.24946472710036963}. Best is trial 0 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:05:46,116] Trial 11 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 266, 'learning_rate': 0.27003369688982254}. Best is trial 0 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:05:46,527] Trial 12 finished with value: 0.8416666666666666 and parameters: {'n_estimators': 390, 'learning_rate': 0.7506570562093923}. Best is trial 0 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:05:46,837] Trial 13 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 282, 'learning_rate': 0.15162024147187034}. Best is trial 0 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:05:47,048] Trial 14 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 186, 'learning_rate': 0.5452166152578888}. Best is trial 0 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:05:47,379] Trial 15 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 299, 'learning_rate': 0.10384520685988545}. Best is trial 0 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:05:47,458] Trial 16 finished with value: 0.8416666666666666 and parameters: {'n_estimators': 59, 'learning_rate': 0.4210304838498263}. Best is trial 0 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:05:47,889] Trial 17 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 406, 'learning_rate': 0.16140257920347179}. Best is trial 0 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:05:48,162] Trial 18 finished with value: 0.8416666666666666 and parameters: {'n_estimators': 247, 'learning_rate': 0.5927006041834751}. Best is trial 0 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:05:48,513] Trial 19 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 327, 'learning_rate': 0.18285012772270334}. Best is trial 0 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:05:48,711] Trial 20 finished with value: 0.7916666666666666 and parameters: {'n_estimators': 178, 'learning_rate': 0.09857093853848094}. Best is trial 0 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:05:49,092] Trial 21 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 324, 'learning_rate': 0.9376996245311906}. Best is trial 0 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:05:49,475] Trial 22 finished with value: 0.8416666666666666 and parameters: {'n_estimators': 357, 'learning_rate': 0.40434127252139856}. Best is trial 0 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:05:49,806] Trial 23 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 297, 'learning_rate': 0.9823999755262179}. Best is trial 0 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:05:50,289] Trial 24 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 448, 'learning_rate': 0.5759395340492663}. Best is trial 0 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:05:50,581] Trial 25 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 253, 'learning_rate': 0.4041037187095646}. Best is trial 0 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:05:51,043] Trial 26 finished with value: 0.8861111111111111 and parameters: {'n_estimators': 423, 'learning_rate': 0.7300608500092896}. Best is trial 26 with value: 0.8861111111111111.\n",
      "[I 2025-08-10 20:05:51,506] Trial 27 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 425, 'learning_rate': 0.22185323733309356}. Best is trial 26 with value: 0.8861111111111111.\n",
      "[I 2025-08-10 20:05:52,019] Trial 28 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 482, 'learning_rate': 0.107483486397002}. Best is trial 26 with value: 0.8861111111111111.\n",
      "[I 2025-08-10 20:05:52,412] Trial 29 finished with value: 0.8416666666666666 and parameters: {'n_estimators': 359, 'learning_rate': 0.3412414319373521}. Best is trial 26 with value: 0.8861111111111111.\n",
      "[I 2025-08-10 20:05:52,875] Trial 30 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 433, 'learning_rate': 0.6683853495454171}. Best is trial 26 with value: 0.8861111111111111.\n",
      "[I 2025-08-10 20:05:53,287] Trial 31 finished with value: 0.8861111111111111 and parameters: {'n_estimators': 380, 'learning_rate': 0.8088667388589235}. Best is trial 26 with value: 0.8861111111111111.\n",
      "[I 2025-08-10 20:05:53,720] Trial 32 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 401, 'learning_rate': 0.5200787204107012}. Best is trial 26 with value: 0.8861111111111111.\n",
      "[I 2025-08-10 20:05:54,133] Trial 33 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 374, 'learning_rate': 0.7659759761476153}. Best is trial 26 with value: 0.8861111111111111.\n",
      "[I 2025-08-10 20:05:54,646] Trial 34 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 470, 'learning_rate': 0.3167620133060081}. Best is trial 26 with value: 0.8861111111111111.\n",
      "[I 2025-08-10 20:05:54,987] Trial 35 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 305, 'learning_rate': 0.4278824965714725}. Best is trial 26 with value: 0.8861111111111111.\n",
      "[I 2025-08-10 20:05:55,450] Trial 36 finished with value: 0.8416666666666666 and parameters: {'n_estimators': 418, 'learning_rate': 0.7925241487777143}. Best is trial 26 with value: 0.8861111111111111.\n",
      "[I 2025-08-10 20:05:55,842] Trial 37 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 349, 'learning_rate': 0.3128325381107002}. Best is trial 26 with value: 0.8861111111111111.\n",
      "[I 2025-08-10 20:05:56,256] Trial 38 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 377, 'learning_rate': 0.48186456466331207}. Best is trial 26 with value: 0.8861111111111111.\n",
      "[I 2025-08-10 20:05:56,517] Trial 39 finished with value: 0.8138888888888889 and parameters: {'n_estimators': 231, 'learning_rate': 0.018225452193301232}. Best is trial 26 with value: 0.8861111111111111.\n",
      "[I 2025-08-10 20:05:57,019] Trial 40 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 455, 'learning_rate': 0.19804325710248513}. Best is trial 26 with value: 0.8861111111111111.\n",
      "[I 2025-08-10 20:05:57,381] Trial 41 finished with value: 0.8416666666666666 and parameters: {'n_estimators': 323, 'learning_rate': 0.987932249551133}. Best is trial 26 with value: 0.8861111111111111.\n",
      "[I 2025-08-10 20:05:57,753] Trial 42 finished with value: 0.8416666666666666 and parameters: {'n_estimators': 338, 'learning_rate': 0.8288408125767036}. Best is trial 26 with value: 0.8861111111111111.\n",
      "[I 2025-08-10 20:05:58,084] Trial 43 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 269, 'learning_rate': 0.6654342695277163}. Best is trial 26 with value: 0.8861111111111111.\n",
      "[I 2025-08-10 20:05:58,406] Trial 44 finished with value: 0.8416666666666666 and parameters: {'n_estimators': 286, 'learning_rate': 0.649941245380059}. Best is trial 26 with value: 0.8861111111111111.\n",
      "[I 2025-08-10 20:05:58,818] Trial 45 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 370, 'learning_rate': 0.2670234635671003}. Best is trial 26 with value: 0.8861111111111111.\n",
      "[I 2025-08-10 20:05:59,250] Trial 46 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 394, 'learning_rate': 0.5151840050551478}. Best is trial 26 with value: 0.8861111111111111.\n",
      "[I 2025-08-10 20:05:59,592] Trial 47 finished with value: 0.7916666666666666 and parameters: {'n_estimators': 311, 'learning_rate': 0.06040764392377849}. Best is trial 26 with value: 0.8861111111111111.\n",
      "[I 2025-08-10 20:05:59,833] Trial 48 finished with value: 0.8416666666666666 and parameters: {'n_estimators': 211, 'learning_rate': 0.7556864335948063}. Best is trial 26 with value: 0.8861111111111111.\n",
      "[I 2025-08-10 20:06:00,003] Trial 49 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 139, 'learning_rate': 0.35774957889335757}. Best is trial 26 with value: 0.8861111111111111.\n",
      "[I 2025-08-10 20:06:00,376] Trial 50 finished with value: 0.8416666666666666 and parameters: {'n_estimators': 342, 'learning_rate': 0.46116233272611296}. Best is trial 26 with value: 0.8861111111111111.\n",
      "[I 2025-08-10 20:06:00,678] Trial 51 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 270, 'learning_rate': 0.2619347518490126}. Best is trial 26 with value: 0.8861111111111111.\n",
      "[I 2025-08-10 20:06:00,969] Trial 52 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 257, 'learning_rate': 0.5895898635941684}. Best is trial 26 with value: 0.8861111111111111.\n",
      "[I 2025-08-10 20:06:01,293] Trial 53 finished with value: 0.8416666666666666 and parameters: {'n_estimators': 287, 'learning_rate': 0.1235774493417032}. Best is trial 26 with value: 0.8861111111111111.\n",
      "[I 2025-08-10 20:06:01,646] Trial 54 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 322, 'learning_rate': 0.9230615100830657}. Best is trial 26 with value: 0.8861111111111111.\n",
      "[I 2025-08-10 20:06:01,918] Trial 55 finished with value: 0.8138888888888889 and parameters: {'n_estimators': 241, 'learning_rate': 0.0750309839988813}. Best is trial 26 with value: 0.8861111111111111.\n",
      "[I 2025-08-10 20:06:02,361] Trial 56 finished with value: 0.8416666666666666 and parameters: {'n_estimators': 412, 'learning_rate': 0.2872874602256492}. Best is trial 26 with value: 0.8861111111111111.\n",
      "[I 2025-08-10 20:06:02,783] Trial 57 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 386, 'learning_rate': 0.6684448036412758}. Best is trial 26 with value: 0.8861111111111111.\n",
      "[I 2025-08-10 20:06:03,015] Trial 58 finished with value: 0.836111111111111 and parameters: {'n_estimators': 198, 'learning_rate': 0.029283745608140548}. Best is trial 26 with value: 0.8861111111111111.\n",
      "[I 2025-08-10 20:06:03,197] Trial 59 finished with value: 0.8416666666666666 and parameters: {'n_estimators': 160, 'learning_rate': 0.3766965399618014}. Best is trial 26 with value: 0.8861111111111111.\n",
      "[I 2025-08-10 20:06:03,307] Trial 60 finished with value: 0.8166666666666667 and parameters: {'n_estimators': 87, 'learning_rate': 0.23833086743573226}. Best is trial 26 with value: 0.8861111111111111.\n",
      "[I 2025-08-10 20:06:03,639] Trial 61 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 297, 'learning_rate': 0.16350826770196664}. Best is trial 26 with value: 0.8861111111111111.\n",
      "[I 2025-08-10 20:06:03,951] Trial 62 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 271, 'learning_rate': 0.14492687649207045}. Best is trial 26 with value: 0.8861111111111111.\n",
      "[I 2025-08-10 20:06:04,264] Trial 63 finished with value: 0.8416666666666666 and parameters: {'n_estimators': 285, 'learning_rate': 0.2212596502604932}. Best is trial 26 with value: 0.8861111111111111.\n",
      "[I 2025-08-10 20:06:04,616] Trial 64 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 312, 'learning_rate': 0.19962266614664131}. Best is trial 26 with value: 0.8861111111111111.\n",
      "[I 2025-08-10 20:06:05,009] Trial 65 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 356, 'learning_rate': 0.8890610737604862}. Best is trial 26 with value: 0.8861111111111111.\n",
      "[I 2025-08-10 20:06:05,382] Trial 66 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 337, 'learning_rate': 0.4488564105009222}. Best is trial 26 with value: 0.8861111111111111.\n",
      "[I 2025-08-10 20:06:05,865] Trial 67 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 437, 'learning_rate': 0.5611446466630393}. Best is trial 26 with value: 0.8861111111111111.\n",
      "[I 2025-08-10 20:06:06,153] Trial 68 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 237, 'learning_rate': 0.12869934904916136}. Best is trial 26 with value: 0.8861111111111111.\n",
      "[I 2025-08-10 20:06:06,565] Trial 69 finished with value: 0.8416666666666666 and parameters: {'n_estimators': 369, 'learning_rate': 0.34339029753742617}. Best is trial 26 with value: 0.8861111111111111.\n",
      "[I 2025-08-10 20:06:06,868] Trial 70 finished with value: 0.8416666666666666 and parameters: {'n_estimators': 264, 'learning_rate': 0.719299824053011}. Best is trial 26 with value: 0.8861111111111111.\n",
      "[I 2025-08-10 20:06:07,079] Trial 71 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 185, 'learning_rate': 0.5079130965329183}. Best is trial 26 with value: 0.8861111111111111.\n",
      "[I 2025-08-10 20:06:07,342] Trial 72 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 223, 'learning_rate': 0.39454664943692}. Best is trial 26 with value: 0.8861111111111111.\n",
      "[I 2025-08-10 20:06:07,483] Trial 73 finished with value: 0.8416666666666666 and parameters: {'n_estimators': 120, 'learning_rate': 0.8434396499421892}. Best is trial 26 with value: 0.8861111111111111.\n",
      "[I 2025-08-10 20:06:07,765] Trial 74 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 253, 'learning_rate': 0.6713298023939461}. Best is trial 26 with value: 0.8861111111111111.\n",
      "[I 2025-08-10 20:06:08,309] Trial 75 finished with value: 0.8416666666666666 and parameters: {'n_estimators': 497, 'learning_rate': 0.2944066549100985}. Best is trial 26 with value: 0.8861111111111111.\n",
      "[I 2025-08-10 20:06:08,665] Trial 76 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 316, 'learning_rate': 0.5229199157788762}. Best is trial 26 with value: 0.8861111111111111.\n",
      "[I 2025-08-10 20:06:08,987] Trial 77 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 285, 'learning_rate': 0.6080372273327114}. Best is trial 26 with value: 0.8861111111111111.\n",
      "[I 2025-08-10 20:06:09,321] Trial 78 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 297, 'learning_rate': 0.4445941338268955}. Best is trial 26 with value: 0.8861111111111111.\n",
      "[I 2025-08-10 20:06:09,695] Trial 79 finished with value: 0.8416666666666666 and parameters: {'n_estimators': 332, 'learning_rate': 0.9800373541443893}. Best is trial 26 with value: 0.8861111111111111.\n",
      "[I 2025-08-10 20:06:10,138] Trial 80 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 404, 'learning_rate': 0.7893210712151405}. Best is trial 26 with value: 0.8861111111111111.\n",
      "[I 2025-08-10 20:06:10,483] Trial 81 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 300, 'learning_rate': 0.07819522807172431}. Best is trial 26 with value: 0.8861111111111111.\n",
      "[I 2025-08-10 20:06:10,986] Trial 82 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 463, 'learning_rate': 0.07658006712246407}. Best is trial 26 with value: 0.8861111111111111.\n",
      "[I 2025-08-10 20:06:11,169] Trial 83 finished with value: 0.8138888888888889 and parameters: {'n_estimators': 155, 'learning_rate': 0.09084067112198202}. Best is trial 26 with value: 0.8861111111111111.\n",
      "[I 2025-08-10 20:06:11,482] Trial 84 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 278, 'learning_rate': 0.16873776530699452}. Best is trial 26 with value: 0.8861111111111111.\n",
      "[I 2025-08-10 20:06:11,875] Trial 85 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 351, 'learning_rate': 0.10731538752661554}. Best is trial 26 with value: 0.8861111111111111.\n",
      "[I 2025-08-10 20:06:11,988] Trial 86 finished with value: 0.8138888888888889 and parameters: {'n_estimators': 91, 'learning_rate': 0.13044684134308054}. Best is trial 26 with value: 0.8861111111111111.\n",
      "[I 2025-08-10 20:06:12,432] Trial 87 finished with value: 0.7916666666666666 and parameters: {'n_estimators': 387, 'learning_rate': 0.0462115525866766}. Best is trial 26 with value: 0.8861111111111111.\n",
      "[I 2025-08-10 20:06:12,806] Trial 88 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 327, 'learning_rate': 0.3223194353701599}. Best is trial 26 with value: 0.8861111111111111.\n",
      "[I 2025-08-10 20:06:13,221] Trial 89 finished with value: 0.8416666666666666 and parameters: {'n_estimators': 364, 'learning_rate': 0.552091724555341}. Best is trial 26 with value: 0.8861111111111111.\n",
      "[I 2025-08-10 20:06:13,576] Trial 90 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 307, 'learning_rate': 0.7109245628081351}. Best is trial 26 with value: 0.8861111111111111.\n",
      "[I 2025-08-10 20:06:14,040] Trial 91 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 417, 'learning_rate': 0.14783033372533125}. Best is trial 26 with value: 0.8861111111111111.\n",
      "[I 2025-08-10 20:06:14,487] Trial 92 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 398, 'learning_rate': 0.19494437655378588}. Best is trial 26 with value: 0.8861111111111111.\n",
      "[I 2025-08-10 20:06:15,014] Trial 93 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 450, 'learning_rate': 0.09391574020654683}. Best is trial 26 with value: 0.8861111111111111.\n",
      "[I 2025-08-10 20:06:15,498] Trial 94 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 432, 'learning_rate': 0.21914417225847085}. Best is trial 26 with value: 0.8861111111111111.\n",
      "[I 2025-08-10 20:06:15,972] Trial 95 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 407, 'learning_rate': 0.1194790163969967}. Best is trial 26 with value: 0.8861111111111111.\n",
      "[I 2025-08-10 20:06:16,288] Trial 96 finished with value: 0.8416666666666666 and parameters: {'n_estimators': 259, 'learning_rate': 0.6144586207257413}. Best is trial 26 with value: 0.8861111111111111.\n",
      "[I 2025-08-10 20:06:16,581] Trial 97 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 247, 'learning_rate': 0.14746343229064965}. Best is trial 26 with value: 0.8861111111111111.\n",
      "[I 2025-08-10 20:06:17,025] Trial 98 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 381, 'learning_rate': 0.2450195786191003}. Best is trial 26 with value: 0.8861111111111111.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-10 20:06:17,431] A new study created in memory with name: no-name-05eaa977-8976-438f-89f2-7ef15589e422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-10 20:06:17,430] Trial 99 finished with value: 0.836111111111111 and parameters: {'n_estimators': 348, 'learning_rate': 0.0133711893749404}. Best is trial 26 with value: 0.8861111111111111.\n",
      "Best params for AdaBoost: {'n_estimators': 423, 'learning_rate': 0.7300608500092896}\n",
      "Best accuracy: 0.8861\n",
      "\n",
      "Starting tuning for Random Forest ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7382f0d6ebbd46288a93210240ddfbe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-10 20:06:17,690] Trial 0 finished with value: 0.5888888888888888 and parameters: {'n_estimators': 283, 'max_depth': 12, 'min_samples_split': 18, 'min_samples_leaf': 10, 'max_features': 'sqrt'}. Best is trial 0 with value: 0.5888888888888888.\n",
      "[I 2025-08-10 20:06:17,897] Trial 1 finished with value: 0.45555555555555555 and parameters: {'n_estimators': 255, 'max_depth': 26, 'min_samples_split': 3, 'min_samples_leaf': 20, 'max_features': 'log2'}. Best is trial 0 with value: 0.5888888888888888.\n",
      "[I 2025-08-10 20:06:18,152] Trial 2 finished with value: 0.45555555555555555 and parameters: {'n_estimators': 332, 'max_depth': 7, 'min_samples_split': 17, 'min_samples_leaf': 14, 'max_features': 'sqrt'}. Best is trial 0 with value: 0.5888888888888888.\n",
      "[I 2025-08-10 20:06:18,438] Trial 3 finished with value: 0.5444444444444445 and parameters: {'n_estimators': 351, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': None}. Best is trial 0 with value: 0.5888888888888888.\n",
      "[I 2025-08-10 20:06:18,745] Trial 4 finished with value: 0.6333333333333333 and parameters: {'n_estimators': 364, 'max_depth': 29, 'min_samples_split': 2, 'min_samples_leaf': 8, 'max_features': None}. Best is trial 4 with value: 0.6333333333333333.\n",
      "[I 2025-08-10 20:06:19,132] Trial 5 finished with value: 0.5444444444444445 and parameters: {'n_estimators': 468, 'max_depth': 29, 'min_samples_split': 12, 'min_samples_leaf': 11, 'max_features': None}. Best is trial 4 with value: 0.6333333333333333.\n",
      "[I 2025-08-10 20:06:19,639] Trial 6 finished with value: 0.8388888888888889 and parameters: {'n_estimators': 637, 'max_depth': 11, 'min_samples_split': 13, 'min_samples_leaf': 3, 'max_features': 'sqrt'}. Best is trial 6 with value: 0.8388888888888889.\n",
      "[I 2025-08-10 20:06:20,008] Trial 7 finished with value: 0.5666666666666667 and parameters: {'n_estimators': 423, 'max_depth': 10, 'min_samples_split': 17, 'min_samples_leaf': 10, 'max_features': 'sqrt'}. Best is trial 6 with value: 0.8388888888888889.\n",
      "[I 2025-08-10 20:06:20,325] Trial 8 finished with value: 0.8166666666666667 and parameters: {'n_estimators': 371, 'max_depth': 29, 'min_samples_split': 16, 'min_samples_leaf': 5, 'max_features': None}. Best is trial 6 with value: 0.8388888888888889.\n",
      "[I 2025-08-10 20:06:20,419] Trial 9 finished with value: 0.7694444444444444 and parameters: {'n_estimators': 111, 'max_depth': 11, 'min_samples_split': 13, 'min_samples_leaf': 4, 'max_features': 'log2'}. Best is trial 6 with value: 0.8388888888888889.\n",
      "[I 2025-08-10 20:06:21,024] Trial 10 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 753, 'max_depth': 19, 'min_samples_split': 8, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 10 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:06:21,644] Trial 11 finished with value: 0.9083333333333332 and parameters: {'n_estimators': 767, 'max_depth': 19, 'min_samples_split': 7, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:06:22,433] Trial 12 finished with value: 0.8388888888888889 and parameters: {'n_estimators': 979, 'max_depth': 21, 'min_samples_split': 8, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:06:23,042] Trial 13 finished with value: 0.8861111111111111 and parameters: {'n_estimators': 738, 'max_depth': 18, 'min_samples_split': 8, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:06:23,690] Trial 14 finished with value: 0.7472222222222221 and parameters: {'n_estimators': 829, 'max_depth': 16, 'min_samples_split': 8, 'min_samples_leaf': 6, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:06:24,187] Trial 15 finished with value: 0.9083333333333332 and parameters: {'n_estimators': 607, 'max_depth': 23, 'min_samples_split': 6, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:06:24,643] Trial 16 finished with value: 0.45555555555555555 and parameters: {'n_estimators': 596, 'max_depth': 24, 'min_samples_split': 5, 'min_samples_leaf': 15, 'max_features': 'log2'}. Best is trial 11 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:06:25,383] Trial 17 finished with value: 0.6555555555555556 and parameters: {'n_estimators': 945, 'max_depth': 23, 'min_samples_split': 5, 'min_samples_leaf': 7, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:06:25,820] Trial 18 finished with value: 0.8416666666666666 and parameters: {'n_estimators': 537, 'max_depth': 14, 'min_samples_split': 10, 'min_samples_leaf': 3, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:06:26,360] Trial 19 finished with value: 0.45555555555555555 and parameters: {'n_estimators': 679, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 18, 'max_features': 'log2'}. Best is trial 11 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:06:27,038] Trial 20 finished with value: 0.7027777777777777 and parameters: {'n_estimators': 860, 'max_depth': 21, 'min_samples_split': 20, 'min_samples_leaf': 5, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:06:27,659] Trial 21 finished with value: 0.9083333333333332 and parameters: {'n_estimators': 751, 'max_depth': 18, 'min_samples_split': 7, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:06:28,329] Trial 22 finished with value: 0.8833333333333332 and parameters: {'n_estimators': 822, 'max_depth': 16, 'min_samples_split': 6, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:06:28,765] Trial 23 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 542, 'max_depth': 25, 'min_samples_split': 6, 'min_samples_leaf': 3, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:06:29,324] Trial 24 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 693, 'max_depth': 21, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:06:29,953] Trial 25 finished with value: 0.8388888888888889 and parameters: {'n_estimators': 785, 'max_depth': 18, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:06:30,644] Trial 26 finished with value: 0.611111111111111 and parameters: {'n_estimators': 898, 'max_depth': 14, 'min_samples_split': 7, 'min_samples_leaf': 8, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:06:31,142] Trial 27 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 621, 'max_depth': 27, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:06:31,711] Trial 28 finished with value: 0.7694444444444444 and parameters: {'n_estimators': 713, 'max_depth': 22, 'min_samples_split': 7, 'min_samples_leaf': 5, 'max_features': 'log2'}. Best is trial 11 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:06:32,108] Trial 29 finished with value: 0.5 and parameters: {'n_estimators': 484, 'max_depth': 14, 'min_samples_split': 11, 'min_samples_leaf': 12, 'max_features': None}. Best is trial 11 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:06:32,839] Trial 30 finished with value: 0.611111111111111 and parameters: {'n_estimators': 900, 'max_depth': 20, 'min_samples_split': 9, 'min_samples_leaf': 8, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:06:33,479] Trial 31 finished with value: 0.9083333333333332 and parameters: {'n_estimators': 766, 'max_depth': 18, 'min_samples_split': 7, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:06:34,110] Trial 32 finished with value: 0.8861111111111111 and parameters: {'n_estimators': 777, 'max_depth': 17, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:06:34,639] Trial 33 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 656, 'max_depth': 19, 'min_samples_split': 6, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:06:35,300] Trial 34 finished with value: 0.8388888888888889 and parameters: {'n_estimators': 802, 'max_depth': 27, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:06:35,889] Trial 35 finished with value: 0.9083333333333332 and parameters: {'n_estimators': 718, 'max_depth': 23, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:06:36,339] Trial 36 finished with value: 0.45555555555555555 and parameters: {'n_estimators': 566, 'max_depth': 15, 'min_samples_split': 7, 'min_samples_leaf': 20, 'max_features': None}. Best is trial 11 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:06:37,020] Trial 37 finished with value: 0.7472222222222221 and parameters: {'n_estimators': 887, 'max_depth': 19, 'min_samples_split': 9, 'min_samples_leaf': 6, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:06:37,509] Trial 38 finished with value: 0.8416666666666666 and parameters: {'n_estimators': 606, 'max_depth': 25, 'min_samples_split': 12, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 11 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:06:37,889] Trial 39 finished with value: 0.45555555555555555 and parameters: {'n_estimators': 478, 'max_depth': 9, 'min_samples_split': 15, 'min_samples_leaf': 16, 'max_features': None}. Best is trial 11 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:06:38,126] Trial 40 finished with value: 0.4333333333333333 and parameters: {'n_estimators': 281, 'max_depth': 13, 'min_samples_split': 3, 'min_samples_leaf': 12, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:06:38,717] Trial 41 finished with value: 0.9083333333333332 and parameters: {'n_estimators': 728, 'max_depth': 22, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:06:39,238] Trial 42 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 658, 'max_depth': 23, 'min_samples_split': 6, 'min_samples_leaf': 3, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:06:39,849] Trial 43 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 760, 'max_depth': 18, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:06:40,419] Trial 44 finished with value: 0.9083333333333332 and parameters: {'n_estimators': 708, 'max_depth': 20, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:06:41,081] Trial 45 finished with value: 0.8166666666666667 and parameters: {'n_estimators': 829, 'max_depth': 17, 'min_samples_split': 7, 'min_samples_leaf': 4, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:06:41,249] Trial 46 finished with value: 0.775 and parameters: {'n_estimators': 180, 'max_depth': 23, 'min_samples_split': 9, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:06:41,919] Trial 47 finished with value: 0.861111111111111 and parameters: {'n_estimators': 750, 'max_depth': 25, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': None}. Best is trial 11 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:06:42,390] Trial 48 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 580, 'max_depth': 27, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:06:43,130] Trial 49 finished with value: 0.5888888888888888 and parameters: {'n_estimators': 957, 'max_depth': 22, 'min_samples_split': 8, 'min_samples_leaf': 9, 'max_features': 'log2'}. Best is trial 11 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:06:43,814] Trial 50 finished with value: 0.7472222222222221 and parameters: {'n_estimators': 858, 'max_depth': 20, 'min_samples_split': 6, 'min_samples_leaf': 6, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:06:44,405] Trial 51 finished with value: 0.9083333333333332 and parameters: {'n_estimators': 720, 'max_depth': 22, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:06:44,923] Trial 52 finished with value: 0.9083333333333332 and parameters: {'n_estimators': 642, 'max_depth': 24, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:06:45,505] Trial 53 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 680, 'max_depth': 19, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:06:46,106] Trial 54 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 736, 'max_depth': 16, 'min_samples_split': 7, 'min_samples_leaf': 4, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:06:46,545] Trial 55 finished with value: 0.9083333333333332 and parameters: {'n_estimators': 528, 'max_depth': 21, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:06:47,187] Trial 56 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 815, 'max_depth': 24, 'min_samples_split': 8, 'min_samples_leaf': 3, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:06:47,799] Trial 57 finished with value: 0.7916666666666666 and parameters: {'n_estimators': 771, 'max_depth': 18, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:06:48,349] Trial 58 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 685, 'max_depth': 26, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:06:49,022] Trial 59 finished with value: 0.9083333333333332 and parameters: {'n_estimators': 849, 'max_depth': 23, 'min_samples_split': 6, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 11 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:06:49,361] Trial 60 finished with value: 0.8166666666666667 and parameters: {'n_estimators': 415, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 4, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:06:49,941] Trial 61 finished with value: 0.9083333333333332 and parameters: {'n_estimators': 718, 'max_depth': 20, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:06:50,441] Trial 62 finished with value: 0.8861111111111111 and parameters: {'n_estimators': 624, 'max_depth': 20, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:06:51,002] Trial 63 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 709, 'max_depth': 17, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:06:51,654] Trial 64 finished with value: 0.8833333333333332 and parameters: {'n_estimators': 796, 'max_depth': 22, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:06:52,175] Trial 65 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 662, 'max_depth': 21, 'min_samples_split': 2, 'min_samples_leaf': 3, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:06:52,775] Trial 66 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 761, 'max_depth': 18, 'min_samples_split': 6, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:06:53,306] Trial 67 finished with value: 0.45555555555555555 and parameters: {'n_estimators': 701, 'max_depth': 15, 'min_samples_split': 7, 'min_samples_leaf': 18, 'max_features': None}. Best is trial 11 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:06:53,878] Trial 68 finished with value: 0.8138888888888889 and parameters: {'n_estimators': 732, 'max_depth': 20, 'min_samples_split': 19, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:06:54,368] Trial 69 finished with value: 0.8861111111111111 and parameters: {'n_estimators': 606, 'max_depth': 19, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:06:55,101] Trial 70 finished with value: 0.8833333333333332 and parameters: {'n_estimators': 925, 'max_depth': 22, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:06:55,734] Trial 71 finished with value: 0.9083333333333332 and parameters: {'n_estimators': 780, 'max_depth': 22, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:06:56,326] Trial 72 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 727, 'max_depth': 24, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:06:56,746] Trial 73 finished with value: 0.861111111111111 and parameters: {'n_estimators': 511, 'max_depth': 21, 'min_samples_split': 8, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:06:57,298] Trial 74 finished with value: 0.8388888888888889 and parameters: {'n_estimators': 685, 'max_depth': 23, 'min_samples_split': 14, 'min_samples_leaf': 3, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:06:57,940] Trial 75 finished with value: 0.8833333333333332 and parameters: {'n_estimators': 799, 'max_depth': 26, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:06:58,453] Trial 76 finished with value: 0.7944444444444444 and parameters: {'n_estimators': 641, 'max_depth': 19, 'min_samples_split': 6, 'min_samples_leaf': 4, 'max_features': 'log2'}. Best is trial 11 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:06:59,077] Trial 77 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 745, 'max_depth': 20, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:06:59,518] Trial 78 finished with value: 0.45555555555555555 and parameters: {'n_estimators': 567, 'max_depth': 15, 'min_samples_split': 4, 'min_samples_leaf': 14, 'max_features': None}. Best is trial 11 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:07:00,191] Trial 79 finished with value: 0.8166666666666667 and parameters: {'n_estimators': 842, 'max_depth': 17, 'min_samples_split': 11, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:07:00,722] Trial 80 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 660, 'max_depth': 18, 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:07:01,233] Trial 81 finished with value: 0.9083333333333332 and parameters: {'n_estimators': 632, 'max_depth': 25, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:07:01,795] Trial 82 finished with value: 0.9083333333333332 and parameters: {'n_estimators': 700, 'max_depth': 24, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:07:02,287] Trial 83 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 592, 'max_depth': 23, 'min_samples_split': 7, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:07:02,809] Trial 84 finished with value: 0.9083333333333332 and parameters: {'n_estimators': 646, 'max_depth': 28, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:07:03,503] Trial 85 finished with value: 0.8388888888888889 and parameters: {'n_estimators': 877, 'max_depth': 24, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:07:04,026] Trial 86 finished with value: 0.5 and parameters: {'n_estimators': 670, 'max_depth': 22, 'min_samples_split': 3, 'min_samples_leaf': 11, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:07:04,637] Trial 87 finished with value: 0.8861111111111111 and parameters: {'n_estimators': 757, 'max_depth': 21, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:07:05,291] Trial 88 finished with value: 0.8833333333333332 and parameters: {'n_estimators': 817, 'max_depth': 19, 'min_samples_split': 6, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:07:05,914] Trial 89 finished with value: 0.8416666666666666 and parameters: {'n_estimators': 783, 'max_depth': 21, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 11 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:07:06,487] Trial 90 finished with value: 0.9083333333333332 and parameters: {'n_estimators': 713, 'max_depth': 25, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:07:06,938] Trial 91 finished with value: 0.9083333333333332 and parameters: {'n_estimators': 543, 'max_depth': 21, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:07:07,369] Trial 92 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 527, 'max_depth': 22, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:07:07,951] Trial 93 finished with value: 0.9083333333333332 and parameters: {'n_estimators': 728, 'max_depth': 20, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:07:08,322] Trial 94 finished with value: 0.8861111111111111 and parameters: {'n_estimators': 454, 'max_depth': 23, 'min_samples_split': 7, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:07:08,783] Trial 95 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 562, 'max_depth': 24, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:07:09,205] Trial 96 finished with value: 0.8861111111111111 and parameters: {'n_estimators': 519, 'max_depth': 18, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:07:09,799] Trial 97 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 691, 'max_depth': 16, 'min_samples_split': 7, 'min_samples_leaf': 4, 'max_features': None}. Best is trial 11 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:07:10,404] Trial 98 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 747, 'max_depth': 20, 'min_samples_split': 9, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.9083333333333332.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-10 20:07:10,808] A new study created in memory with name: no-name-396e0f9e-d6ff-4895-b876-d1d2d79b2e3d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-10 20:07:10,807] Trial 99 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 496, 'max_depth': 22, 'min_samples_split': 6, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.9083333333333332.\n",
      "Best params for Random Forest: {'n_estimators': 767, 'max_depth': 19, 'min_samples_split': 7, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Best accuracy: 0.9083\n",
      "\n",
      "Starting tuning for CatBoost ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5774e53a990a4b56947e9db29a023dd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-10 20:07:14,109] Trial 0 finished with value: 0.75 and parameters: {'depth': 10, 'learning_rate': 0.14272912299728455, 'iterations': 317, 'l2_leaf_reg': 0.003985593431496364, 'border_count': 186}. Best is trial 0 with value: 0.75.\n",
      "[I 2025-08-10 20:07:17,764] Trial 1 finished with value: 0.9083333333333332 and parameters: {'depth': 8, 'learning_rate': 0.23147795084586875, 'iterations': 815, 'l2_leaf_reg': 1.824129884197628, 'border_count': 239}. Best is trial 1 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:07:19,706] Trial 2 finished with value: 0.8833333333333332 and parameters: {'depth': 7, 'learning_rate': 0.10573080300369403, 'iterations': 667, 'l2_leaf_reg': 0.21191335182103824, 'border_count': 164}. Best is trial 1 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:07:20,745] Trial 3 finished with value: 0.8833333333333332 and parameters: {'depth': 6, 'learning_rate': 0.023859411574475624, 'iterations': 506, 'l2_leaf_reg': 3.294966920025535, 'border_count': 44}. Best is trial 1 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:07:30,088] Trial 4 finished with value: 0.8833333333333332 and parameters: {'depth': 10, 'learning_rate': 0.08599612412549429, 'iterations': 933, 'l2_leaf_reg': 0.42048191706035365, 'border_count': 86}. Best is trial 1 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:07:30,845] Trial 5 finished with value: 0.8833333333333332 and parameters: {'depth': 6, 'learning_rate': 0.107018808509398, 'iterations': 408, 'l2_leaf_reg': 0.12500892157656165, 'border_count': 40}. Best is trial 1 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:07:31,652] Trial 6 finished with value: 0.8861111111111111 and parameters: {'depth': 5, 'learning_rate': 0.20422363229219825, 'iterations': 551, 'l2_leaf_reg': 2.3653278376104225, 'border_count': 174}. Best is trial 1 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:07:32,692] Trial 7 finished with value: 0.7472222222222221 and parameters: {'depth': 7, 'learning_rate': 0.22381271118736099, 'iterations': 410, 'l2_leaf_reg': 0.00153163183059562, 'border_count': 152}. Best is trial 1 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:07:33,306] Trial 8 finished with value: 0.8388888888888889 and parameters: {'depth': 4, 'learning_rate': 0.0822863529639897, 'iterations': 390, 'l2_leaf_reg': 0.19792178171435348, 'border_count': 167}. Best is trial 1 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:07:33,780] Trial 9 finished with value: 0.7888888888888889 and parameters: {'depth': 7, 'learning_rate': 0.012963507596908173, 'iterations': 196, 'l2_leaf_reg': 0.6707965421155498, 'border_count': 50}. Best is trial 1 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:07:40,666] Trial 10 finished with value: 0.8861111111111111 and parameters: {'depth': 9, 'learning_rate': 0.03867810585780725, 'iterations': 979, 'l2_leaf_reg': 0.02056857319333004, 'border_count': 244}. Best is trial 1 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:07:41,536] Trial 11 finished with value: 0.8388888888888889 and parameters: {'depth': 4, 'learning_rate': 0.24977900811085435, 'iterations': 745, 'l2_leaf_reg': 9.291935761718308, 'border_count': 250}. Best is trial 1 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:07:44,502] Trial 12 finished with value: 0.8833333333333332 and parameters: {'depth': 8, 'learning_rate': 0.2048495294340713, 'iterations': 753, 'l2_leaf_reg': 2.0471195615738176, 'border_count': 210}. Best is trial 1 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:07:45,637] Trial 13 finished with value: 0.861111111111111 and parameters: {'depth': 5, 'learning_rate': 0.2872456323588622, 'iterations': 845, 'l2_leaf_reg': 1.5964833402829597, 'border_count': 124}. Best is trial 1 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:07:48,211] Trial 14 finished with value: 0.8833333333333332 and parameters: {'depth': 8, 'learning_rate': 0.049999568266123555, 'iterations': 612, 'l2_leaf_reg': 0.02687334782152331, 'border_count': 221}. Best is trial 1 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:07:48,411] Trial 15 finished with value: 0.8583333333333332 and parameters: {'depth': 5, 'learning_rate': 0.15131918974461359, 'iterations': 109, 'l2_leaf_reg': 7.966805116104963, 'border_count': 121}. Best is trial 1 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:07:50,480] Trial 16 finished with value: 0.861111111111111 and parameters: {'depth': 8, 'learning_rate': 0.17075876778547977, 'iterations': 514, 'l2_leaf_reg': 0.8562582129489843, 'border_count': 207}. Best is trial 1 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:07:52,021] Trial 17 finished with value: 0.8833333333333332 and parameters: {'depth': 6, 'learning_rate': 0.060931394048832715, 'iterations': 850, 'l2_leaf_reg': 0.0481649837778178, 'border_count': 197}. Best is trial 1 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:07:55,524] Trial 18 finished with value: 0.8833333333333332 and parameters: {'depth': 9, 'learning_rate': 0.02504502952654363, 'iterations': 626, 'l2_leaf_reg': 4.589434411311878, 'border_count': 226}. Best is trial 1 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:07:56,481] Trial 19 finished with value: 0.9083333333333332 and parameters: {'depth': 5, 'learning_rate': 0.12720376796142946, 'iterations': 712, 'l2_leaf_reg': 1.292543810453402, 'border_count': 128}. Best is trial 1 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:08:01,481] Trial 20 finished with value: 0.8833333333333332 and parameters: {'depth': 9, 'learning_rate': 0.12382999446481409, 'iterations': 753, 'l2_leaf_reg': 1.012809294738081, 'border_count': 82}. Best is trial 1 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:08:02,622] Trial 21 finished with value: 0.8638888888888889 and parameters: {'depth': 5, 'learning_rate': 0.2987102764452743, 'iterations': 691, 'l2_leaf_reg': 0.40675894008318, 'border_count': 122}. Best is trial 1 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:08:03,666] Trial 22 finished with value: 0.8861111111111111 and parameters: {'depth': 4, 'learning_rate': 0.17904768097133478, 'iterations': 865, 'l2_leaf_reg': 2.5476364632327266, 'border_count': 93}. Best is trial 1 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:08:04,547] Trial 23 finished with value: 0.861111111111111 and parameters: {'depth': 5, 'learning_rate': 0.19790033629187617, 'iterations': 567, 'l2_leaf_reg': 4.8506841355303845, 'border_count': 179}. Best is trial 1 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:08:06,078] Trial 24 finished with value: 0.8833333333333332 and parameters: {'depth': 6, 'learning_rate': 0.0760509383199335, 'iterations': 785, 'l2_leaf_reg': 1.3155387557584366, 'border_count': 139}. Best is trial 1 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:08:06,957] Trial 25 finished with value: 0.836111111111111 and parameters: {'depth': 5, 'learning_rate': 0.1351004062874161, 'iterations': 571, 'l2_leaf_reg': 0.44611294751800673, 'border_count': 104}. Best is trial 1 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:08:08,852] Trial 26 finished with value: 0.8833333333333332 and parameters: {'depth': 7, 'learning_rate': 0.24026637361896633, 'iterations': 682, 'l2_leaf_reg': 3.514669138677056, 'border_count': 235}. Best is trial 1 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:08:10,289] Trial 27 finished with value: 0.861111111111111 and parameters: {'depth': 8, 'learning_rate': 0.10184832994792421, 'iterations': 470, 'l2_leaf_reg': 9.995942025301423, 'border_count': 137}. Best is trial 1 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:08:11,891] Trial 28 finished with value: 0.8833333333333332 and parameters: {'depth': 6, 'learning_rate': 0.16382440402816423, 'iterations': 919, 'l2_leaf_reg': 0.26559342265190444, 'border_count': 156}. Best is trial 1 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:08:12,868] Trial 29 finished with value: 0.861111111111111 and parameters: {'depth': 4, 'learning_rate': 0.13883033860319996, 'iterations': 815, 'l2_leaf_reg': 0.009905945604917877, 'border_count': 189}. Best is trial 1 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:08:19,579] Trial 30 finished with value: 0.9055555555555556 and parameters: {'depth': 10, 'learning_rate': 0.061912002265532014, 'iterations': 627, 'l2_leaf_reg': 0.08262562276260241, 'border_count': 66}. Best is trial 1 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:08:25,946] Trial 31 finished with value: 0.8833333333333332 and parameters: {'depth': 10, 'learning_rate': 0.03516930479232096, 'iterations': 630, 'l2_leaf_reg': 0.09526939589361598, 'border_count': 62}. Best is trial 1 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:08:33,721] Trial 32 finished with value: 0.8138888888888889 and parameters: {'depth': 10, 'learning_rate': 0.11393989650090142, 'iterations': 722, 'l2_leaf_reg': 0.0803991030026413, 'border_count': 65}. Best is trial 1 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:08:37,027] Trial 33 finished with value: 0.8388888888888889 and parameters: {'depth': 9, 'learning_rate': 0.060222858357716326, 'iterations': 470, 'l2_leaf_reg': 0.007006664902808102, 'border_count': 171}. Best is trial 1 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:08:38,686] Trial 34 finished with value: 0.8833333333333332 and parameters: {'depth': 7, 'learning_rate': 0.09116737998687982, 'iterations': 645, 'l2_leaf_reg': 0.6273551080301383, 'border_count': 103}. Best is trial 1 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:08:41,993] Trial 35 finished with value: 0.8833333333333332 and parameters: {'depth': 10, 'learning_rate': 0.0725162366667024, 'iterations': 319, 'l2_leaf_reg': 0.1832049090112951, 'border_count': 67}. Best is trial 1 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:08:43,056] Trial 36 finished with value: 0.8833333333333332 and parameters: {'depth': 6, 'learning_rate': 0.04772080727317072, 'iterations': 551, 'l2_leaf_reg': 0.04350151396326639, 'border_count': 32}. Best is trial 1 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:08:44,444] Trial 37 finished with value: 0.861111111111111 and parameters: {'depth': 5, 'learning_rate': 0.015099274675300844, 'iterations': 912, 'l2_leaf_reg': 2.023811741876395, 'border_count': 152}. Best is trial 1 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:08:49,571] Trial 38 finished with value: 0.8333333333333333 and parameters: {'depth': 9, 'learning_rate': 0.2344798188969019, 'iterations': 678, 'l2_leaf_reg': 0.3814620462142696, 'border_count': 255}. Best is trial 1 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:08:50,731] Trial 39 finished with value: 0.8833333333333332 and parameters: {'depth': 6, 'learning_rate': 0.022751424584246466, 'iterations': 595, 'l2_leaf_reg': 5.463063959622254, 'border_count': 80}. Best is trial 1 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:08:52,042] Trial 40 finished with value: 0.8833333333333332 and parameters: {'depth': 7, 'learning_rate': 0.09810297272889587, 'iterations': 499, 'l2_leaf_reg': 0.15449654200043492, 'border_count': 106}. Best is trial 1 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:08:59,070] Trial 41 finished with value: 0.861111111111111 and parameters: {'depth': 9, 'learning_rate': 0.035181878930938604, 'iterations': 998, 'l2_leaf_reg': 0.013827395414889053, 'border_count': 239}. Best is trial 1 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:09:08,724] Trial 42 finished with value: 0.8166666666666667 and parameters: {'depth': 10, 'learning_rate': 0.03408596313136161, 'iterations': 941, 'l2_leaf_reg': 0.022626533645060763, 'border_count': 243}. Best is trial 1 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:09:12,652] Trial 43 finished with value: 0.8861111111111111 and parameters: {'depth': 8, 'learning_rate': 0.04254406610999202, 'iterations': 968, 'l2_leaf_reg': 0.0032399842639029702, 'border_count': 214}. Best is trial 1 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:09:18,199] Trial 44 finished with value: 0.861111111111111 and parameters: {'depth': 9, 'learning_rate': 0.027704963289613985, 'iterations': 794, 'l2_leaf_reg': 0.0556747405302279, 'border_count': 197}. Best is trial 1 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:09:27,905] Trial 45 finished with value: 0.5666666666666667 and parameters: {'depth': 10, 'learning_rate': 0.21497355864526427, 'iterations': 875, 'l2_leaf_reg': 0.0010191699709229357, 'border_count': 228}. Best is trial 1 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:09:30,998] Trial 46 finished with value: 0.8194444444444444 and parameters: {'depth': 8, 'learning_rate': 0.06568724328371028, 'iterations': 735, 'l2_leaf_reg': 0.004493379135883676, 'border_count': 179}. Best is trial 1 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:09:33,568] Trial 47 finished with value: 0.7944444444444445 and parameters: {'depth': 9, 'learning_rate': 0.26577075861734306, 'iterations': 427, 'l2_leaf_reg': 0.023235549038104528, 'border_count': 248}. Best is trial 1 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:09:38,292] Trial 48 finished with value: 0.8583333333333332 and parameters: {'depth': 9, 'learning_rate': 0.15965331507881966, 'iterations': 711, 'l2_leaf_reg': 1.0654926099856867, 'border_count': 220}. Best is trial 1 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:09:39,285] Trial 49 finished with value: 0.861111111111111 and parameters: {'depth': 4, 'learning_rate': 0.020671658073137193, 'iterations': 817, 'l2_leaf_reg': 2.924032269485942, 'border_count': 205}. Best is trial 1 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:09:40,682] Trial 50 finished with value: 0.9083333333333332 and parameters: {'depth': 8, 'learning_rate': 0.11931135596389598, 'iterations': 347, 'l2_leaf_reg': 1.8046274585371633, 'border_count': 129}. Best is trial 1 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:09:42,041] Trial 51 finished with value: 0.8833333333333332 and parameters: {'depth': 8, 'learning_rate': 0.18759091872897465, 'iterations': 275, 'l2_leaf_reg': 1.5975898834078064, 'border_count': 130}. Best is trial 1 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:09:44,113] Trial 52 finished with value: 0.8833333333333332 and parameters: {'depth': 8, 'learning_rate': 0.12704147124296047, 'iterations': 519, 'l2_leaf_reg': 0.6754095242346375, 'border_count': 116}. Best is trial 1 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:09:45,531] Trial 53 finished with value: 0.8861111111111111 and parameters: {'depth': 8, 'learning_rate': 0.042569267074699234, 'iterations': 350, 'l2_leaf_reg': 0.28245546304571656, 'border_count': 149}. Best is trial 1 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:09:46,108] Trial 54 finished with value: 0.8833333333333332 and parameters: {'depth': 7, 'learning_rate': 0.08342766151731407, 'iterations': 226, 'l2_leaf_reg': 2.1454791042714656, 'border_count': 113}. Best is trial 1 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:09:47,034] Trial 55 finished with value: 0.8833333333333332 and parameters: {'depth': 9, 'learning_rate': 0.05363268632267408, 'iterations': 140, 'l2_leaf_reg': 6.145873986205059, 'border_count': 92}. Best is trial 1 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:09:47,977] Trial 56 finished with value: 0.7916666666666666 and parameters: {'depth': 5, 'learning_rate': 0.11857895641896783, 'iterations': 589, 'l2_leaf_reg': 3.299913986571313, 'border_count': 167}. Best is trial 1 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:09:49,679] Trial 57 finished with value: 0.8833333333333332 and parameters: {'depth': 7, 'learning_rate': 0.14604706460815794, 'iterations': 648, 'l2_leaf_reg': 1.4299678940836575, 'border_count': 232}. Best is trial 1 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:09:52,832] Trial 58 finished with value: 0.7722222222222223 and parameters: {'depth': 8, 'learning_rate': 0.20793102080276518, 'iterations': 763, 'l2_leaf_reg': 0.035766851459956166, 'border_count': 52}. Best is trial 1 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:09:53,817] Trial 59 finished with value: 0.861111111111111 and parameters: {'depth': 4, 'learning_rate': 0.18245896789151478, 'iterations': 889, 'l2_leaf_reg': 0.11726770816783019, 'border_count': 159}. Best is trial 1 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:09:57,462] Trial 60 finished with value: 0.861111111111111 and parameters: {'depth': 10, 'learning_rate': 0.28190216599945084, 'iterations': 446, 'l2_leaf_reg': 0.7704299317005467, 'border_count': 132}. Best is trial 1 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:09:58,495] Trial 61 finished with value: 0.8388888888888889 and parameters: {'depth': 4, 'learning_rate': 0.1746114991063232, 'iterations': 869, 'l2_leaf_reg': 2.23067114750775, 'border_count': 94}. Best is trial 1 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:09:59,499] Trial 62 finished with value: 0.8638888888888889 and parameters: {'depth': 4, 'learning_rate': 0.24020520407711649, 'iterations': 825, 'l2_leaf_reg': 3.816898613484839, 'border_count': 79}. Best is trial 1 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:10:00,617] Trial 63 finished with value: 0.9305555555555556 and parameters: {'depth': 5, 'learning_rate': 0.15262688468040386, 'iterations': 779, 'l2_leaf_reg': 1.1361450198586107, 'border_count': 74}. Best is trial 63 with value: 0.9305555555555556.\n",
      "[I 2025-08-10 20:10:01,833] Trial 64 finished with value: 0.8583333333333332 and parameters: {'depth': 5, 'learning_rate': 0.10568289838465983, 'iterations': 776, 'l2_leaf_reg': 1.0622992931158701, 'border_count': 71}. Best is trial 63 with value: 0.9305555555555556.\n",
      "[I 2025-08-10 20:10:02,454] Trial 65 finished with value: 0.8583333333333332 and parameters: {'depth': 5, 'learning_rate': 0.1481861046824429, 'iterations': 378, 'l2_leaf_reg': 0.5402425770179969, 'border_count': 54}. Best is trial 63 with value: 0.9305555555555556.\n",
      "[I 2025-08-10 20:10:03,812] Trial 66 finished with value: 0.861111111111111 and parameters: {'depth': 6, 'learning_rate': 0.1266235563891715, 'iterations': 695, 'l2_leaf_reg': 0.06112050482606746, 'border_count': 47}. Best is trial 63 with value: 0.9305555555555556.\n",
      "[I 2025-08-10 20:10:04,583] Trial 67 finished with value: 0.8833333333333332 and parameters: {'depth': 5, 'learning_rate': 0.030207320773877555, 'iterations': 532, 'l2_leaf_reg': 0.015723268549146886, 'border_count': 146}. Best is trial 63 with value: 0.9305555555555556.\n",
      "[I 2025-08-10 20:10:05,383] Trial 68 finished with value: 0.8166666666666667 and parameters: {'depth': 5, 'learning_rate': 0.09262383815855235, 'iterations': 610, 'l2_leaf_reg': 7.750718193871969, 'border_count': 41}. Best is trial 63 with value: 0.9305555555555556.\n",
      "[I 2025-08-10 20:10:06,522] Trial 69 finished with value: 0.861111111111111 and parameters: {'depth': 6, 'learning_rate': 0.20151045388558456, 'iterations': 646, 'l2_leaf_reg': 1.6863203869981636, 'border_count': 58}. Best is trial 63 with value: 0.9305555555555556.\n",
      "[I 2025-08-10 20:10:11,357] Trial 70 finished with value: 0.8833333333333332 and parameters: {'depth': 9, 'learning_rate': 0.0745856932318227, 'iterations': 741, 'l2_leaf_reg': 0.2982759614198194, 'border_count': 73}. Best is trial 63 with value: 0.9305555555555556.\n",
      "[I 2025-08-10 20:10:12,422] Trial 71 finished with value: 0.861111111111111 and parameters: {'depth': 4, 'learning_rate': 0.16238545291986708, 'iterations': 901, 'l2_leaf_reg': 2.4379415154713158, 'border_count': 90}. Best is trial 63 with value: 0.9305555555555556.\n",
      "[I 2025-08-10 20:10:13,530] Trial 72 finished with value: 0.8388888888888889 and parameters: {'depth': 4, 'learning_rate': 0.2602426291760113, 'iterations': 939, 'l2_leaf_reg': 1.2804874160414883, 'border_count': 127}. Best is trial 63 with value: 0.9305555555555556.\n",
      "[I 2025-08-10 20:10:15,128] Trial 73 finished with value: 0.8833333333333332 and parameters: {'depth': 6, 'learning_rate': 0.17800703965749679, 'iterations': 839, 'l2_leaf_reg': 4.276701517123533, 'border_count': 102}. Best is trial 63 with value: 0.9305555555555556.\n",
      "[I 2025-08-10 20:10:16,543] Trial 74 finished with value: 0.8833333333333332 and parameters: {'depth': 5, 'learning_rate': 0.13776073895204918, 'iterations': 986, 'l2_leaf_reg': 0.8649341102092245, 'border_count': 113}. Best is trial 63 with value: 0.9305555555555556.\n",
      "[I 2025-08-10 20:10:20,349] Trial 75 finished with value: 0.861111111111111 and parameters: {'depth': 10, 'learning_rate': 0.21783981595995353, 'iterations': 795, 'l2_leaf_reg': 2.512426229020479, 'border_count': 143}. Best is trial 63 with value: 0.9305555555555556.\n",
      "[I 2025-08-10 20:10:21,391] Trial 76 finished with value: 0.8583333333333332 and parameters: {'depth': 5, 'learning_rate': 0.11426236621773474, 'iterations': 666, 'l2_leaf_reg': 1.839277622517308, 'border_count': 95}. Best is trial 63 with value: 0.9305555555555556.\n",
      "[I 2025-08-10 20:10:22,647] Trial 77 finished with value: 0.861111111111111 and parameters: {'depth': 4, 'learning_rate': 0.041315686035983575, 'iterations': 855, 'l2_leaf_reg': 0.5138471493509628, 'border_count': 137}. Best is trial 63 with value: 0.9305555555555556.\n",
      "[I 2025-08-10 20:10:25,134] Trial 78 finished with value: 0.8833333333333332 and parameters: {'depth': 7, 'learning_rate': 0.15556433436079176, 'iterations': 951, 'l2_leaf_reg': 2.95558206216652, 'border_count': 86}. Best is trial 63 with value: 0.9305555555555556.\n",
      "[I 2025-08-10 20:10:26,902] Trial 79 finished with value: 0.861111111111111 and parameters: {'depth': 8, 'learning_rate': 0.1965047962620917, 'iterations': 574, 'l2_leaf_reg': 6.064437897019039, 'border_count': 74}. Best is trial 63 with value: 0.9305555555555556.\n",
      "[I 2025-08-10 20:10:32,312] Trial 80 finished with value: 0.861111111111111 and parameters: {'depth': 10, 'learning_rate': 0.061838037122007805, 'iterations': 717, 'l2_leaf_reg': 1.148924001530925, 'border_count': 120}. Best is trial 63 with value: 0.9305555555555556.\n",
      "[I 2025-08-10 20:10:36,087] Trial 81 finished with value: 0.8388888888888889 and parameters: {'depth': 8, 'learning_rate': 0.040024376250077584, 'iterations': 912, 'l2_leaf_reg': 0.0025148746378566263, 'border_count': 223}. Best is trial 63 with value: 0.9305555555555556.\n",
      "[I 2025-08-10 20:10:39,938] Trial 82 finished with value: 0.8861111111111111 and parameters: {'depth': 8, 'learning_rate': 0.036937170987413774, 'iterations': 979, 'l2_leaf_reg': 0.002557033391145613, 'border_count': 218}. Best is trial 63 with value: 0.9305555555555556.\n",
      "[I 2025-08-10 20:10:46,603] Trial 83 finished with value: 0.836111111111111 and parameters: {'depth': 9, 'learning_rate': 0.05428959408269075, 'iterations': 958, 'l2_leaf_reg': 0.0076136935677563675, 'border_count': 249}. Best is trial 63 with value: 0.9305555555555556.\n",
      "[I 2025-08-10 20:10:50,679] Trial 84 finished with value: 0.861111111111111 and parameters: {'depth': 8, 'learning_rate': 0.03078835948415446, 'iterations': 976, 'l2_leaf_reg': 0.08451974966069473, 'border_count': 242}. Best is trial 63 with value: 0.9305555555555556.\n",
      "[I 2025-08-10 20:10:56,395] Trial 85 finished with value: 0.8833333333333332 and parameters: {'depth': 9, 'learning_rate': 0.04719313558660062, 'iterations': 798, 'l2_leaf_reg': 0.029258156229740345, 'border_count': 212}. Best is trial 63 with value: 0.9305555555555556.\n",
      "[I 2025-08-10 20:10:58,024] Trial 86 finished with value: 0.8583333333333332 and parameters: {'depth': 6, 'learning_rate': 0.23056941496909536, 'iterations': 877, 'l2_leaf_reg': 0.8422751942506074, 'border_count': 255}. Best is trial 63 with value: 0.9305555555555556.\n",
      "[I 2025-08-10 20:10:59,286] Trial 87 finished with value: 0.8833333333333332 and parameters: {'depth': 7, 'learning_rate': 0.04645680255251437, 'iterations': 495, 'l2_leaf_reg': 0.004782482625912739, 'border_count': 188}. Best is trial 63 with value: 0.9305555555555556.\n",
      "[I 2025-08-10 20:11:03,108] Trial 88 finished with value: 0.836111111111111 and parameters: {'depth': 8, 'learning_rate': 0.018365662528151028, 'iterations': 925, 'l2_leaf_reg': 0.001536873917432757, 'border_count': 196}. Best is trial 63 with value: 0.9305555555555556.\n",
      "[I 2025-08-10 20:11:06,052] Trial 89 finished with value: 0.861111111111111 and parameters: {'depth': 9, 'learning_rate': 0.1723606890486335, 'iterations': 549, 'l2_leaf_reg': 2.8001682928549503, 'border_count': 179}. Best is trial 63 with value: 0.9305555555555556.\n",
      "[I 2025-08-10 20:11:08,131] Trial 90 finished with value: 0.8583333333333332 and parameters: {'depth': 7, 'learning_rate': 0.06878092419259176, 'iterations': 839, 'l2_leaf_reg': 0.016816273738682865, 'border_count': 229}. Best is trial 63 with value: 0.9305555555555556.\n",
      "[I 2025-08-10 20:11:09,449] Trial 91 finished with value: 0.8833333333333332 and parameters: {'depth': 8, 'learning_rate': 0.04001131414466466, 'iterations': 334, 'l2_leaf_reg': 0.241987800677137, 'border_count': 150}. Best is trial 63 with value: 0.9305555555555556.\n",
      "[I 2025-08-10 20:11:10,912] Trial 92 finished with value: 0.861111111111111 and parameters: {'depth': 8, 'learning_rate': 0.05201769569298747, 'iterations': 358, 'l2_leaf_reg': 0.31734674900550564, 'border_count': 236}. Best is trial 63 with value: 0.9305555555555556.\n",
      "[I 2025-08-10 20:11:12,162] Trial 93 finished with value: 0.861111111111111 and parameters: {'depth': 8, 'learning_rate': 0.043298344158964545, 'iterations': 297, 'l2_leaf_reg': 0.1772908564728413, 'border_count': 160}. Best is trial 63 with value: 0.9305555555555556.\n",
      "[I 2025-08-10 20:11:15,434] Trial 94 finished with value: 0.8833333333333332 and parameters: {'depth': 8, 'learning_rate': 0.03719480912203543, 'iterations': 764, 'l2_leaf_reg': 0.1470292101767834, 'border_count': 172}. Best is trial 63 with value: 0.9305555555555556.\n",
      "[I 2025-08-10 20:11:16,522] Trial 95 finished with value: 0.861111111111111 and parameters: {'depth': 8, 'learning_rate': 0.030648798029514448, 'iterations': 265, 'l2_leaf_reg': 1.5200820676059035, 'border_count': 62}. Best is trial 63 with value: 0.9305555555555556.\n",
      "[I 2025-08-10 20:11:16,868] Trial 96 finished with value: 0.861111111111111 and parameters: {'depth': 5, 'learning_rate': 0.02583641747818012, 'iterations': 215, 'l2_leaf_reg': 1.9045541148102434, 'border_count': 134}. Best is trial 63 with value: 0.9305555555555556.\n",
      "[I 2025-08-10 20:11:20,040] Trial 97 finished with value: 0.8833333333333332 and parameters: {'depth': 9, 'learning_rate': 0.19050342349534888, 'iterations': 464, 'l2_leaf_reg': 0.06618900756084271, 'border_count': 202}. Best is trial 63 with value: 0.9305555555555556.\n",
      "[I 2025-08-10 20:11:21,197] Trial 98 finished with value: 0.8388888888888889 and parameters: {'depth': 4, 'learning_rate': 0.13317170323514482, 'iterations': 961, 'l2_leaf_reg': 1.2604807894103578, 'border_count': 212}. Best is trial 63 with value: 0.9305555555555556.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-10 20:11:22,041] A new study created in memory with name: no-name-aaf686af-65b2-47c0-b964-5a299814ca53\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-10 20:11:22,040] Trial 99 finished with value: 0.861111111111111 and parameters: {'depth': 5, 'learning_rate': 0.010010036355611002, 'iterations': 423, 'l2_leaf_reg': 4.240977660001461, 'border_count': 125}. Best is trial 63 with value: 0.9305555555555556.\n",
      "Best params for CatBoost: {'depth': 5, 'learning_rate': 0.15262688468040386, 'iterations': 779, 'l2_leaf_reg': 1.1361450198586107, 'border_count': 74}\n",
      "Best accuracy: 0.9306\n",
      "\n",
      "Starting tuning for Gradient Boosting ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59c769d4d1c5471988834298b2daaa4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-10 20:11:22,262] Trial 0 finished with value: 0.7055555555555555 and parameters: {'n_estimators': 384, 'learning_rate': 0.12327901152965724, 'max_depth': 13, 'min_samples_split': 4, 'min_samples_leaf': 14, 'subsample': 0.9689852455700073}. Best is trial 0 with value: 0.7055555555555555.\n",
      "[I 2025-08-10 20:11:22,649] Trial 1 finished with value: 0.7277777777777776 and parameters: {'n_estimators': 770, 'learning_rate': 0.06271766222226922, 'max_depth': 12, 'min_samples_split': 12, 'min_samples_leaf': 9, 'subsample': 0.6450527744564899}. Best is trial 1 with value: 0.7277777777777776.\n",
      "[I 2025-08-10 20:11:22,795] Trial 2 finished with value: 0.47777777777777775 and parameters: {'n_estimators': 308, 'learning_rate': 0.07040120926468936, 'max_depth': 15, 'min_samples_split': 20, 'min_samples_leaf': 14, 'subsample': 0.5192594163694855}. Best is trial 1 with value: 0.7277777777777776.\n",
      "[I 2025-08-10 20:11:23,102] Trial 3 finished with value: 0.836111111111111 and parameters: {'n_estimators': 486, 'learning_rate': 0.10244377547574142, 'max_depth': 7, 'min_samples_split': 14, 'min_samples_leaf': 7, 'subsample': 0.9975599018242771}. Best is trial 3 with value: 0.836111111111111.\n",
      "[I 2025-08-10 20:11:23,207] Trial 4 finished with value: 0.8166666666666667 and parameters: {'n_estimators': 159, 'learning_rate': 0.03240700449342826, 'max_depth': 10, 'min_samples_split': 13, 'min_samples_leaf': 7, 'subsample': 0.9314792321918293}. Best is trial 3 with value: 0.836111111111111.\n",
      "[I 2025-08-10 20:11:23,291] Trial 5 finished with value: 0.8166666666666667 and parameters: {'n_estimators': 118, 'learning_rate': 0.022382308985919207, 'max_depth': 14, 'min_samples_split': 4, 'min_samples_leaf': 4, 'subsample': 0.607321990291243}. Best is trial 3 with value: 0.836111111111111.\n",
      "[I 2025-08-10 20:11:23,446] Trial 6 finished with value: 0.5 and parameters: {'n_estimators': 353, 'learning_rate': 0.1393285643124445, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 17, 'subsample': 0.5433202837695557}. Best is trial 3 with value: 0.836111111111111.\n",
      "[I 2025-08-10 20:11:24,045] Trial 7 finished with value: 0.836111111111111 and parameters: {'n_estimators': 900, 'learning_rate': 0.0501132813947696, 'max_depth': 9, 'min_samples_split': 11, 'min_samples_leaf': 6, 'subsample': 0.9472621183440677}. Best is trial 3 with value: 0.836111111111111.\n",
      "[I 2025-08-10 20:11:24,110] Trial 8 finished with value: 0.45555555555555555 and parameters: {'n_estimators': 113, 'learning_rate': 0.0208643302500112, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 14, 'subsample': 0.7418124954986821}. Best is trial 3 with value: 0.836111111111111.\n",
      "[I 2025-08-10 20:11:24,184] Trial 9 finished with value: 0.45555555555555555 and parameters: {'n_estimators': 146, 'learning_rate': 0.1465429612412223, 'max_depth': 14, 'min_samples_split': 8, 'min_samples_leaf': 13, 'subsample': 0.6771031926223705}. Best is trial 3 with value: 0.836111111111111.\n",
      "[I 2025-08-10 20:11:24,492] Trial 10 finished with value: 0.7222222222222222 and parameters: {'n_estimators': 580, 'learning_rate': 0.288241237789689, 'max_depth': 5, 'min_samples_split': 18, 'min_samples_leaf': 1, 'subsample': 0.850032007149397}. Best is trial 3 with value: 0.836111111111111.\n",
      "[I 2025-08-10 20:11:25,123] Trial 11 finished with value: 0.861111111111111 and parameters: {'n_estimators': 966, 'learning_rate': 0.012673267280837138, 'max_depth': 8, 'min_samples_split': 15, 'min_samples_leaf': 6, 'subsample': 0.8676589045124962}. Best is trial 11 with value: 0.861111111111111.\n",
      "[I 2025-08-10 20:11:25,542] Trial 12 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 620, 'learning_rate': 0.011550084164782889, 'max_depth': 7, 'min_samples_split': 16, 'min_samples_leaf': 4, 'subsample': 0.8460322312014209}. Best is trial 12 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:11:26,073] Trial 13 finished with value: 0.861111111111111 and parameters: {'n_estimators': 712, 'learning_rate': 0.01320232765726708, 'max_depth': 8, 'min_samples_split': 17, 'min_samples_leaf': 1, 'subsample': 0.8296017975355326}. Best is trial 12 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:11:26,715] Trial 14 finished with value: 0.9083333333333332 and parameters: {'n_estimators': 934, 'learning_rate': 0.010525369198300974, 'max_depth': 11, 'min_samples_split': 16, 'min_samples_leaf': 4, 'subsample': 0.8481396189959345}. Best is trial 14 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:11:27,236] Trial 15 finished with value: 0.9083333333333332 and parameters: {'n_estimators': 812, 'learning_rate': 0.0108190296553507, 'max_depth': 11, 'min_samples_split': 17, 'min_samples_leaf': 3, 'subsample': 0.7734487379363824}. Best is trial 14 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:11:27,738] Trial 16 finished with value: 0.8861111111111111 and parameters: {'n_estimators': 828, 'learning_rate': 0.01940518808288243, 'max_depth': 11, 'min_samples_split': 20, 'min_samples_leaf': 3, 'subsample': 0.7475781889797756}. Best is trial 14 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:11:28,239] Trial 17 finished with value: 0.6805555555555556 and parameters: {'n_estimators': 970, 'learning_rate': 0.030517534538566142, 'max_depth': 11, 'min_samples_split': 9, 'min_samples_leaf': 11, 'subsample': 0.7939552019825102}. Best is trial 14 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:11:28,559] Trial 18 finished with value: 0.45555555555555555 and parameters: {'n_estimators': 693, 'learning_rate': 0.010777545531484804, 'max_depth': 12, 'min_samples_split': 18, 'min_samples_leaf': 20, 'subsample': 0.9037280324213456}. Best is trial 14 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:11:28,999] Trial 19 finished with value: 0.7305555555555555 and parameters: {'n_estimators': 865, 'learning_rate': 0.01647847813334776, 'max_depth': 10, 'min_samples_split': 15, 'min_samples_leaf': 10, 'subsample': 0.7022728108458515}. Best is trial 14 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:11:29,569] Trial 20 finished with value: 0.8861111111111111 and parameters: {'n_estimators': 753, 'learning_rate': 0.0370524293632313, 'max_depth': 12, 'min_samples_split': 11, 'min_samples_leaf': 2, 'subsample': 0.7927574804309492}. Best is trial 14 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:11:30,060] Trial 21 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 851, 'learning_rate': 0.01837362718599811, 'max_depth': 10, 'min_samples_split': 20, 'min_samples_leaf': 4, 'subsample': 0.7466428364886495}. Best is trial 14 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:11:30,570] Trial 22 finished with value: 0.9083333333333332 and parameters: {'n_estimators': 813, 'learning_rate': 0.010123881312232042, 'max_depth': 12, 'min_samples_split': 19, 'min_samples_leaf': 3, 'subsample': 0.7862083362538342}. Best is trial 14 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:11:31,152] Trial 23 finished with value: 0.8388888888888889 and parameters: {'n_estimators': 986, 'learning_rate': 0.010056549661887454, 'max_depth': 13, 'min_samples_split': 18, 'min_samples_leaf': 5, 'subsample': 0.797721236363161}. Best is trial 14 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:11:31,653] Trial 24 finished with value: 0.861111111111111 and parameters: {'n_estimators': 630, 'learning_rate': 0.014049610701527064, 'max_depth': 11, 'min_samples_split': 16, 'min_samples_leaf': 2, 'subsample': 0.8960718357452515}. Best is trial 14 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:11:32,134] Trial 25 finished with value: 0.75 and parameters: {'n_estimators': 910, 'learning_rate': 0.025679260605427686, 'max_depth': 13, 'min_samples_split': 19, 'min_samples_leaf': 8, 'subsample': 0.7022314748374957}. Best is trial 14 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:11:32,685] Trial 26 finished with value: 0.9083333333333332 and parameters: {'n_estimators': 799, 'learning_rate': 0.01551576558668675, 'max_depth': 15, 'min_samples_split': 17, 'min_samples_leaf': 3, 'subsample': 0.8097066784011058}. Best is trial 14 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:11:33,144] Trial 27 finished with value: 0.861111111111111 and parameters: {'n_estimators': 691, 'learning_rate': 0.010151921885356453, 'max_depth': 9, 'min_samples_split': 14, 'min_samples_leaf': 5, 'subsample': 0.7718448337272006}. Best is trial 14 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:11:33,929] Trial 28 finished with value: 0.861111111111111 and parameters: {'n_estimators': 521, 'learning_rate': 0.015712357718622786, 'max_depth': 11, 'min_samples_split': 2, 'min_samples_leaf': 1, 'subsample': 0.8840171600127789}. Best is trial 14 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:11:34,274] Trial 29 finished with value: 0.9083333333333332 and parameters: {'n_estimators': 449, 'learning_rate': 0.04657384241192545, 'max_depth': 14, 'min_samples_split': 16, 'min_samples_leaf': 3, 'subsample': 0.7200399180333518}. Best is trial 14 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:11:34,696] Trial 30 finished with value: 0.45555555555555555 and parameters: {'n_estimators': 929, 'learning_rate': 0.02456634784232457, 'max_depth': 12, 'min_samples_split': 19, 'min_samples_leaf': 12, 'subsample': 0.6563725750401274}. Best is trial 14 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:11:35,291] Trial 31 finished with value: 0.9083333333333332 and parameters: {'n_estimators': 813, 'learning_rate': 0.014509514593440466, 'max_depth': 15, 'min_samples_split': 17, 'min_samples_leaf': 3, 'subsample': 0.8240529372263032}. Best is trial 14 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:11:35,826] Trial 32 finished with value: 0.8833333333333332 and parameters: {'n_estimators': 780, 'learning_rate': 0.012639116496398302, 'max_depth': 13, 'min_samples_split': 17, 'min_samples_leaf': 5, 'subsample': 0.8074238839396605}. Best is trial 14 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:11:36,362] Trial 33 finished with value: 0.8166666666666667 and parameters: {'n_estimators': 749, 'learning_rate': 0.016859429138254164, 'max_depth': 15, 'min_samples_split': 19, 'min_samples_leaf': 9, 'subsample': 0.858738593939169}. Best is trial 14 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:11:36,906] Trial 34 finished with value: 0.9083333333333332 and parameters: {'n_estimators': 880, 'learning_rate': 0.07815909592997526, 'max_depth': 13, 'min_samples_split': 14, 'min_samples_leaf': 2, 'subsample': 0.7717441038278964}. Best is trial 14 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:11:37,449] Trial 35 finished with value: 0.861111111111111 and parameters: {'n_estimators': 803, 'learning_rate': 0.012446001807559212, 'max_depth': 9, 'min_samples_split': 12, 'min_samples_leaf': 6, 'subsample': 0.9134552786018415}. Best is trial 14 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:11:37,781] Trial 36 finished with value: 0.7499999999999999 and parameters: {'n_estimators': 638, 'learning_rate': 0.015049693735913713, 'max_depth': 12, 'min_samples_split': 15, 'min_samples_leaf': 8, 'subsample': 0.6251744026815063}. Best is trial 14 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:11:38,597] Trial 37 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 944, 'learning_rate': 0.019275989671894974, 'max_depth': 14, 'min_samples_split': 13, 'min_samples_leaf': 3, 'subsample': 0.9819021101459959}. Best is trial 14 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:11:39,223] Trial 38 finished with value: 0.8166666666666667 and parameters: {'n_estimators': 1000, 'learning_rate': 0.010122578207410707, 'max_depth': 10, 'min_samples_split': 18, 'min_samples_leaf': 7, 'subsample': 0.7666961191756059}. Best is trial 14 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:11:39,759] Trial 39 finished with value: 0.8861111111111111 and parameters: {'n_estimators': 738, 'learning_rate': 0.03776484559657656, 'max_depth': 15, 'min_samples_split': 20, 'min_samples_leaf': 4, 'subsample': 0.9375974514348937}. Best is trial 14 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:11:39,950] Trial 40 finished with value: 0.8388888888888889 and parameters: {'n_estimators': 220, 'learning_rate': 0.02484864229609498, 'max_depth': 11, 'min_samples_split': 9, 'min_samples_leaf': 2, 'subsample': 0.8233651983081872}. Best is trial 14 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:11:40,213] Trial 41 finished with value: 0.9083333333333332 and parameters: {'n_estimators': 443, 'learning_rate': 0.17552757561580945, 'max_depth': 14, 'min_samples_split': 16, 'min_samples_leaf': 3, 'subsample': 0.7094135182259187}. Best is trial 14 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:11:40,454] Trial 42 finished with value: 0.8166666666666667 and parameters: {'n_estimators': 397, 'learning_rate': 0.04598569403508633, 'max_depth': 14, 'min_samples_split': 17, 'min_samples_leaf': 5, 'subsample': 0.724441710729698}. Best is trial 14 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:11:40,676] Trial 43 finished with value: 0.836111111111111 and parameters: {'n_estimators': 278, 'learning_rate': 0.06499206075218661, 'max_depth': 13, 'min_samples_split': 16, 'min_samples_leaf': 1, 'subsample': 0.673421412395192}. Best is trial 14 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:11:40,957] Trial 44 finished with value: 0.8388888888888889 and parameters: {'n_estimators': 449, 'learning_rate': 0.08495706114101811, 'max_depth': 15, 'min_samples_split': 13, 'min_samples_leaf': 4, 'subsample': 0.5882459093502078}. Best is trial 14 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:11:41,230] Trial 45 finished with value: 0.45555555555555555 and parameters: {'n_estimators': 587, 'learning_rate': 0.01185721358109374, 'max_depth': 13, 'min_samples_split': 19, 'min_samples_leaf': 15, 'subsample': 0.725705695200933}. Best is trial 14 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:11:41,571] Trial 46 finished with value: 0.8388888888888889 and parameters: {'n_estimators': 514, 'learning_rate': 0.02911800547150276, 'max_depth': 14, 'min_samples_split': 14, 'min_samples_leaf': 7, 'subsample': 0.8702551138388176}. Best is trial 14 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:11:41,814] Trial 47 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 350, 'learning_rate': 0.11436495432756591, 'max_depth': 3, 'min_samples_split': 15, 'min_samples_leaf': 3, 'subsample': 0.7652562167182093}. Best is trial 14 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:11:42,255] Trial 48 finished with value: 0.8166666666666667 and parameters: {'n_estimators': 842, 'learning_rate': 0.22301035056880733, 'max_depth': 12, 'min_samples_split': 17, 'min_samples_leaf': 6, 'subsample': 0.81185731470751}. Best is trial 14 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:11:42,781] Trial 49 finished with value: 0.861111111111111 and parameters: {'n_estimators': 894, 'learning_rate': 0.057606999703127514, 'max_depth': 10, 'min_samples_split': 18, 'min_samples_leaf': 2, 'subsample': 0.8375999066000362}. Best is trial 14 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:11:43,275] Trial 50 finished with value: 0.861111111111111 and parameters: {'n_estimators': 677, 'learning_rate': 0.011636785421261779, 'max_depth': 14, 'min_samples_split': 16, 'min_samples_leaf': 1, 'subsample': 0.7867553697702272}. Best is trial 14 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:11:43,832] Trial 51 finished with value: 0.9083333333333332 and parameters: {'n_estimators': 802, 'learning_rate': 0.015091311092207484, 'max_depth': 15, 'min_samples_split': 17, 'min_samples_leaf': 3, 'subsample': 0.8319638344095228}. Best is trial 14 with value: 0.9083333333333332.\n",
      "[I 2025-08-10 20:11:44,335] Trial 52 finished with value: 0.9305555555555556 and parameters: {'n_estimators': 810, 'learning_rate': 0.021629091319927143, 'max_depth': 15, 'min_samples_split': 19, 'min_samples_leaf': 4, 'subsample': 0.816685022589326}. Best is trial 52 with value: 0.9305555555555556.\n",
      "[I 2025-08-10 20:11:44,891] Trial 53 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 937, 'learning_rate': 0.021609670195152465, 'max_depth': 14, 'min_samples_split': 20, 'min_samples_leaf': 4, 'subsample': 0.7374000970905212}. Best is trial 52 with value: 0.9305555555555556.\n",
      "[I 2025-08-10 20:11:45,356] Trial 54 finished with value: 0.8388888888888889 and parameters: {'n_estimators': 773, 'learning_rate': 0.017581693096783094, 'max_depth': 15, 'min_samples_split': 19, 'min_samples_leaf': 5, 'subsample': 0.7818493316000301}. Best is trial 52 with value: 0.9305555555555556.\n",
      "[I 2025-08-10 20:11:45,891] Trial 55 finished with value: 0.8166666666666667 and parameters: {'n_estimators': 873, 'learning_rate': 0.013806490001105681, 'max_depth': 6, 'min_samples_split': 18, 'min_samples_leaf': 6, 'subsample': 0.852482230199471}. Best is trial 52 with value: 0.9305555555555556.\n",
      "[I 2025-08-10 20:11:46,346] Trial 56 finished with value: 0.8861111111111111 and parameters: {'n_estimators': 716, 'learning_rate': 0.04739097691210828, 'max_depth': 12, 'min_samples_split': 19, 'min_samples_leaf': 2, 'subsample': 0.7583292437315756}. Best is trial 52 with value: 0.9305555555555556.\n",
      "[I 2025-08-10 20:11:46,719] Trial 57 finished with value: 0.45555555555555555 and parameters: {'n_estimators': 838, 'learning_rate': 0.011251094806534983, 'max_depth': 11, 'min_samples_split': 7, 'min_samples_leaf': 20, 'subsample': 0.8104633177648748}. Best is trial 52 with value: 0.9305555555555556.\n",
      "[I 2025-08-10 20:11:47,031] Trial 58 finished with value: 0.45555555555555555 and parameters: {'n_estimators': 672, 'learning_rate': 0.0349317588674925, 'max_depth': 8, 'min_samples_split': 15, 'min_samples_leaf': 18, 'subsample': 0.8771874009922321}. Best is trial 52 with value: 0.9305555555555556.\n",
      "[I 2025-08-10 20:11:47,564] Trial 59 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 908, 'learning_rate': 0.021391526569155404, 'max_depth': 9, 'min_samples_split': 18, 'min_samples_leaf': 4, 'subsample': 0.7206525010059245}. Best is trial 52 with value: 0.9305555555555556.\n",
      "[I 2025-08-10 20:11:47,856] Trial 60 finished with value: 0.8166666666666667 and parameters: {'n_estimators': 567, 'learning_rate': 0.01125016029066302, 'max_depth': 13, 'min_samples_split': 16, 'min_samples_leaf': 3, 'subsample': 0.5071701981975125}. Best is trial 52 with value: 0.9305555555555556.\n",
      "[I 2025-08-10 20:11:48,390] Trial 61 finished with value: 0.9083333333333332 and parameters: {'n_estimators': 817, 'learning_rate': 0.01391015936276925, 'max_depth': 15, 'min_samples_split': 17, 'min_samples_leaf': 3, 'subsample': 0.8149624665982348}. Best is trial 52 with value: 0.9305555555555556.\n",
      "[I 2025-08-10 20:11:48,894] Trial 62 finished with value: 0.8833333333333332 and parameters: {'n_estimators': 771, 'learning_rate': 0.013311057549031604, 'max_depth': 14, 'min_samples_split': 17, 'min_samples_leaf': 5, 'subsample': 0.8373630661475003}. Best is trial 52 with value: 0.9305555555555556.\n",
      "[I 2025-08-10 20:11:49,418] Trial 63 finished with value: 0.8388888888888889 and parameters: {'n_estimators': 802, 'learning_rate': 0.016164842299594803, 'max_depth': 15, 'min_samples_split': 20, 'min_samples_leaf': 2, 'subsample': 0.7932245905704878}. Best is trial 52 with value: 0.9305555555555556.\n",
      "[I 2025-08-10 20:11:49,943] Trial 64 finished with value: 0.861111111111111 and parameters: {'n_estimators': 723, 'learning_rate': 0.018737297757746494, 'max_depth': 15, 'min_samples_split': 18, 'min_samples_leaf': 1, 'subsample': 0.7484157639322814}. Best is trial 52 with value: 0.9305555555555556.\n",
      "[I 2025-08-10 20:11:50,548] Trial 65 finished with value: 0.9083333333333332 and parameters: {'n_estimators': 865, 'learning_rate': 0.027950014395784747, 'max_depth': 14, 'min_samples_split': 16, 'min_samples_leaf': 4, 'subsample': 0.8503337240919379}. Best is trial 52 with value: 0.9305555555555556.\n",
      "[I 2025-08-10 20:11:51,136] Trial 66 finished with value: 0.9083333333333332 and parameters: {'n_estimators': 955, 'learning_rate': 0.015221364427576763, 'max_depth': 12, 'min_samples_split': 19, 'min_samples_leaf': 3, 'subsample': 0.7799067353671932}. Best is trial 52 with value: 0.9305555555555556.\n",
      "[I 2025-08-10 20:11:51,713] Trial 67 finished with value: 0.8388888888888889 and parameters: {'n_estimators': 922, 'learning_rate': 0.012808369113097552, 'max_depth': 15, 'min_samples_split': 17, 'min_samples_leaf': 7, 'subsample': 0.892478425207855}. Best is trial 52 with value: 0.9305555555555556.\n",
      "[I 2025-08-10 20:11:52,188] Trial 68 finished with value: 0.8861111111111111 and parameters: {'n_estimators': 648, 'learning_rate': 0.041961304590819544, 'max_depth': 11, 'min_samples_split': 15, 'min_samples_leaf': 4, 'subsample': 0.9102315902432015}. Best is trial 52 with value: 0.9305555555555556.\n",
      "[I 2025-08-10 20:11:52,693] Trial 69 finished with value: 0.861111111111111 and parameters: {'n_estimators': 784, 'learning_rate': 0.010338463689226552, 'max_depth': 13, 'min_samples_split': 13, 'min_samples_leaf': 5, 'subsample': 0.8031507402193392}. Best is trial 52 with value: 0.9305555555555556.\n",
      "[I 2025-08-10 20:11:53,420] Trial 70 finished with value: 0.7722222222222223 and parameters: {'n_estimators': 844, 'learning_rate': 0.019929190349340827, 'max_depth': 12, 'min_samples_split': 14, 'min_samples_leaf': 1, 'subsample': 0.8194173347301167}. Best is trial 52 with value: 0.9305555555555556.\n",
      "[I 2025-08-10 20:11:53,906] Trial 71 finished with value: 0.8861111111111111 and parameters: {'n_estimators': 893, 'learning_rate': 0.07931628028811112, 'max_depth': 13, 'min_samples_split': 16, 'min_samples_leaf': 2, 'subsample': 0.6957154652384266}. Best is trial 52 with value: 0.9305555555555556.\n",
      "[I 2025-08-10 20:11:54,369] Trial 72 finished with value: 0.9083333333333332 and parameters: {'n_estimators': 867, 'learning_rate': 0.08798583127686514, 'max_depth': 13, 'min_samples_split': 14, 'min_samples_leaf': 2, 'subsample': 0.760002754323628}. Best is trial 52 with value: 0.9305555555555556.\n",
      "[I 2025-08-10 20:11:54,965] Trial 73 finished with value: 0.8861111111111111 and parameters: {'n_estimators': 973, 'learning_rate': 0.06890051430265073, 'max_depth': 14, 'min_samples_split': 10, 'min_samples_leaf': 3, 'subsample': 0.772419897378502}. Best is trial 52 with value: 0.9305555555555556.\n",
      "[I 2025-08-10 20:11:55,513] Trial 74 finished with value: 0.9083333333333332 and parameters: {'n_estimators': 823, 'learning_rate': 0.05620648513131221, 'max_depth': 15, 'min_samples_split': 12, 'min_samples_leaf': 2, 'subsample': 0.7353982076713735}. Best is trial 52 with value: 0.9305555555555556.\n",
      "[I 2025-08-10 20:11:55,939] Trial 75 finished with value: 0.8861111111111111 and parameters: {'n_estimators': 756, 'learning_rate': 0.10457497483658221, 'max_depth': 14, 'min_samples_split': 17, 'min_samples_leaf': 3, 'subsample': 0.861581282922232}. Best is trial 52 with value: 0.9305555555555556.\n",
      "[I 2025-08-10 20:11:56,455] Trial 76 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 878, 'learning_rate': 0.0117715556724987, 'max_depth': 12, 'min_samples_split': 18, 'min_samples_leaf': 4, 'subsample': 0.6864768542320469}. Best is trial 52 with value: 0.9305555555555556.\n",
      "[I 2025-08-10 20:11:56,814] Trial 77 finished with value: 0.861111111111111 and parameters: {'n_estimators': 466, 'learning_rate': 0.01419681120884355, 'max_depth': 10, 'min_samples_split': 15, 'min_samples_leaf': 1, 'subsample': 0.7980910400866554}. Best is trial 52 with value: 0.9305555555555556.\n",
      "[I 2025-08-10 20:11:57,077] Trial 78 finished with value: 0.8166666666666667 and parameters: {'n_estimators': 401, 'learning_rate': 0.1298058699009762, 'max_depth': 13, 'min_samples_split': 19, 'min_samples_leaf': 6, 'subsample': 0.8306525404569183}. Best is trial 52 with value: 0.9305555555555556.\n",
      "[I 2025-08-10 20:11:57,513] Trial 79 finished with value: 0.6583333333333334 and parameters: {'n_estimators': 808, 'learning_rate': 0.07556521834040544, 'max_depth': 11, 'min_samples_split': 18, 'min_samples_leaf': 11, 'subsample': 0.7820124196012874}. Best is trial 52 with value: 0.9305555555555556.\n",
      "[I 2025-08-10 20:11:57,958] Trial 80 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 734, 'learning_rate': 0.02328227699425648, 'max_depth': 14, 'min_samples_split': 20, 'min_samples_leaf': 4, 'subsample': 0.7520899420164546}. Best is trial 52 with value: 0.9305555555555556.\n",
      "[I 2025-08-10 20:11:58,223] Trial 81 finished with value: 0.8861111111111111 and parameters: {'n_estimators': 417, 'learning_rate': 0.1907143390195568, 'max_depth': 15, 'min_samples_split': 16, 'min_samples_leaf': 3, 'subsample': 0.7128981864909161}. Best is trial 52 with value: 0.9305555555555556.\n",
      "[I 2025-08-10 20:11:58,449] Trial 82 finished with value: 0.8833333333333332 and parameters: {'n_estimators': 339, 'learning_rate': 0.19771634915384045, 'max_depth': 14, 'min_samples_split': 15, 'min_samples_leaf': 2, 'subsample': 0.655536903387467}. Best is trial 52 with value: 0.9305555555555556.\n",
      "[I 2025-08-10 20:11:58,761] Trial 83 finished with value: 0.9083333333333332 and parameters: {'n_estimators': 488, 'learning_rate': 0.254027976189941, 'max_depth': 13, 'min_samples_split': 16, 'min_samples_leaf': 3, 'subsample': 0.6747059401602715}. Best is trial 52 with value: 0.9305555555555556.\n",
      "[I 2025-08-10 20:11:59,249] Trial 84 finished with value: 0.8166666666666667 and parameters: {'n_estimators': 898, 'learning_rate': 0.1460393832956726, 'max_depth': 15, 'min_samples_split': 17, 'min_samples_leaf': 5, 'subsample': 0.7725945873970145}. Best is trial 52 with value: 0.9305555555555556.\n",
      "[I 2025-08-10 20:11:59,483] Trial 85 finished with value: 0.9305555555555556 and parameters: {'n_estimators': 423, 'learning_rate': 0.295174787890004, 'max_depth': 14, 'min_samples_split': 16, 'min_samples_leaf': 3, 'subsample': 0.7119922020729322}. Best is trial 52 with value: 0.9305555555555556.\n",
      "[I 2025-08-10 20:11:59,879] Trial 86 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 543, 'learning_rate': 0.010777997638309535, 'max_depth': 14, 'min_samples_split': 14, 'min_samples_leaf': 4, 'subsample': 0.8425730039546084}. Best is trial 52 with value: 0.9305555555555556.\n",
      "[I 2025-08-10 20:12:00,074] Trial 87 finished with value: 0.9083333333333332 and parameters: {'n_estimators': 328, 'learning_rate': 0.2892997289683415, 'max_depth': 13, 'min_samples_split': 17, 'min_samples_leaf': 2, 'subsample': 0.7411814872768111}. Best is trial 52 with value: 0.9305555555555556.\n",
      "[I 2025-08-10 20:12:00,302] Trial 88 finished with value: 0.8388888888888889 and parameters: {'n_estimators': 306, 'learning_rate': 0.012490783108484615, 'max_depth': 11, 'min_samples_split': 18, 'min_samples_leaf': 1, 'subsample': 0.8030931557310359}. Best is trial 52 with value: 0.9305555555555556.\n",
      "[I 2025-08-10 20:12:00,578] Trial 89 finished with value: 0.8388888888888889 and parameters: {'n_estimators': 384, 'learning_rate': 0.016794749626049366, 'max_depth': 15, 'min_samples_split': 12, 'min_samples_leaf': 5, 'subsample': 0.8241357817055844}. Best is trial 52 with value: 0.9305555555555556.\n",
      "[I 2025-08-10 20:12:00,874] Trial 90 finished with value: 0.47777777777777775 and parameters: {'n_estimators': 603, 'learning_rate': 0.16778112161873063, 'max_depth': 12, 'min_samples_split': 19, 'min_samples_leaf': 15, 'subsample': 0.7240238950565678}. Best is trial 52 with value: 0.9305555555555556.\n",
      "[I 2025-08-10 20:12:01,149] Trial 91 finished with value: 0.9305555555555556 and parameters: {'n_estimators': 454, 'learning_rate': 0.1615345274692295, 'max_depth': 14, 'min_samples_split': 16, 'min_samples_leaf': 3, 'subsample': 0.7055023867257646}. Best is trial 52 with value: 0.9305555555555556.\n",
      "[I 2025-08-10 20:12:01,417] Trial 92 finished with value: 0.9305555555555556 and parameters: {'n_estimators': 471, 'learning_rate': 0.2548393352103936, 'max_depth': 14, 'min_samples_split': 16, 'min_samples_leaf': 3, 'subsample': 0.6877909636651385}. Best is trial 52 with value: 0.9305555555555556.\n",
      "[I 2025-08-10 20:12:01,695] Trial 93 finished with value: 0.8861111111111111 and parameters: {'n_estimators': 501, 'learning_rate': 0.2613823330016657, 'max_depth': 14, 'min_samples_split': 15, 'min_samples_leaf': 3, 'subsample': 0.6973220832602038}. Best is trial 52 with value: 0.9305555555555556.\n",
      "[I 2025-08-10 20:12:01,953] Trial 94 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 438, 'learning_rate': 0.2346153098764764, 'max_depth': 15, 'min_samples_split': 16, 'min_samples_leaf': 4, 'subsample': 0.6572800621544448}. Best is trial 52 with value: 0.9305555555555556.\n",
      "[I 2025-08-10 20:12:02,217] Trial 95 finished with value: 0.9083333333333332 and parameters: {'n_estimators': 469, 'learning_rate': 0.21323398689669162, 'max_depth': 14, 'min_samples_split': 17, 'min_samples_leaf': 3, 'subsample': 0.6813953168854459}. Best is trial 52 with value: 0.9305555555555556.\n",
      "[I 2025-08-10 20:12:02,503] Trial 96 finished with value: 0.8861111111111111 and parameters: {'n_estimators': 531, 'learning_rate': 0.25584569580018063, 'max_depth': 10, 'min_samples_split': 16, 'min_samples_leaf': 4, 'subsample': 0.6336658735532035}. Best is trial 52 with value: 0.9305555555555556.\n",
      "[I 2025-08-10 20:12:02,758] Trial 97 finished with value: 0.8388888888888889 and parameters: {'n_estimators': 417, 'learning_rate': 0.010770874925565105, 'max_depth': 15, 'min_samples_split': 18, 'min_samples_leaf': 2, 'subsample': 0.7102199598801138}. Best is trial 52 with value: 0.9305555555555556.\n",
      "[I 2025-08-10 20:12:02,972] Trial 98 finished with value: 0.8166666666666667 and parameters: {'n_estimators': 362, 'learning_rate': 0.29443395897529756, 'max_depth': 14, 'min_samples_split': 6, 'min_samples_leaf': 5, 'subsample': 0.7544378431650046}. Best is trial 52 with value: 0.9305555555555556.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-10 20:12:03,240] A new study created in memory with name: no-name-64d31aa7-9db7-4aa8-8df4-31ccb5e8b32f\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-10 20:12:03,238] Trial 99 finished with value: 0.8861111111111111 and parameters: {'n_estimators': 424, 'learning_rate': 0.16162914511379325, 'max_depth': 15, 'min_samples_split': 2, 'min_samples_leaf': 3, 'subsample': 0.7913562690580325}. Best is trial 52 with value: 0.9305555555555556.\n",
      "Best params for Gradient Boosting: {'n_estimators': 810, 'learning_rate': 0.021629091319927143, 'max_depth': 15, 'min_samples_split': 19, 'min_samples_leaf': 4, 'subsample': 0.816685022589326}\n",
      "Best accuracy: 0.9306\n",
      "\n",
      "Starting tuning for XGBoost ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d15cc59910c241e986089b44c2520022",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-10 20:12:03,903] Trial 0 finished with value: 0.45555555555555555 and parameters: {'n_estimators': 576, 'max_depth': 13, 'learning_rate': 0.01764991470876496, 'subsample': 0.5719618067812335, 'colsample_bytree': 0.54232950091087, 'gamma': 2.2787481386450064, 'reg_alpha': 4.024695711014185, 'reg_lambda': 0.2563028362262376}. Best is trial 0 with value: 0.45555555555555555.\n",
      "[I 2025-08-10 20:12:05,150] Trial 1 finished with value: 0.45555555555555555 and parameters: {'n_estimators': 320, 'max_depth': 5, 'learning_rate': 0.019655481214392822, 'subsample': 0.938697491722259, 'colsample_bytree': 0.9683136569672488, 'gamma': 1.5038715236699929, 'reg_alpha': 3.954431904695157, 'reg_lambda': 4.205632127041385}. Best is trial 0 with value: 0.45555555555555555.\n",
      "[I 2025-08-10 20:12:06,262] Trial 2 finished with value: 0.45555555555555555 and parameters: {'n_estimators': 390, 'max_depth': 8, 'learning_rate': 0.05024853005525821, 'subsample': 0.7563004295403907, 'colsample_bytree': 0.509238148125079, 'gamma': 4.89475548261798, 'reg_alpha': 4.623145037847464, 'reg_lambda': 2.9427546218349185}. Best is trial 0 with value: 0.45555555555555555.\n",
      "[I 2025-08-10 20:12:07,452] Trial 3 finished with value: 0.45555555555555555 and parameters: {'n_estimators': 943, 'max_depth': 13, 'learning_rate': 0.11711590092511884, 'subsample': 0.6105148117255864, 'colsample_bytree': 0.62315345502898, 'gamma': 3.2998482883413365, 'reg_alpha': 4.392120710491422, 'reg_lambda': 2.044033234000234}. Best is trial 0 with value: 0.45555555555555555.\n",
      "[I 2025-08-10 20:12:08,409] Trial 4 finished with value: 0.45555555555555555 and parameters: {'n_estimators': 529, 'max_depth': 12, 'learning_rate': 0.029322714953785068, 'subsample': 0.8288707622831959, 'colsample_bytree': 0.7944782157707193, 'gamma': 0.580922563029812, 'reg_alpha': 4.44509975924019, 'reg_lambda': 3.1787386366305665}. Best is trial 0 with value: 0.45555555555555555.\n",
      "[I 2025-08-10 20:12:09,575] Trial 5 finished with value: 0.725 and parameters: {'n_estimators': 130, 'max_depth': 13, 'learning_rate': 0.2989415979892707, 'subsample': 0.8704414993346001, 'colsample_bytree': 0.7172222769647523, 'gamma': 1.8782345591888494, 'reg_alpha': 0.7539494673834429, 'reg_lambda': 4.80440891649152}. Best is trial 5 with value: 0.725.\n",
      "[I 2025-08-10 20:12:09,634] Trial 6 finished with value: 0.8138888888888889 and parameters: {'n_estimators': 747, 'max_depth': 4, 'learning_rate': 0.012649664116555317, 'subsample': 0.8801729290134737, 'colsample_bytree': 0.5083523247302033, 'gamma': 0.2520571136366684, 'reg_alpha': 0.7380371540458763, 'reg_lambda': 1.9504466542169951}. Best is trial 6 with value: 0.8138888888888889.\n",
      "[I 2025-08-10 20:12:10,476] Trial 7 finished with value: 0.45555555555555555 and parameters: {'n_estimators': 180, 'max_depth': 4, 'learning_rate': 0.017481227291810758, 'subsample': 0.9862420995001612, 'colsample_bytree': 0.786176237114321, 'gamma': 1.3824379150603554, 'reg_alpha': 4.6084427813312825, 'reg_lambda': 3.5680601037560704}. Best is trial 6 with value: 0.8138888888888889.\n",
      "[I 2025-08-10 20:12:10,522] Trial 8 finished with value: 0.45555555555555555 and parameters: {'n_estimators': 764, 'max_depth': 15, 'learning_rate': 0.013731761318295368, 'subsample': 0.7233166270432805, 'colsample_bytree': 0.8221509677864445, 'gamma': 0.16344379822537558, 'reg_alpha': 4.863988487436024, 'reg_lambda': 4.740912350802576}. Best is trial 6 with value: 0.8138888888888889.\n",
      "[I 2025-08-10 20:12:10,556] Trial 9 finished with value: 0.861111111111111 and parameters: {'n_estimators': 380, 'max_depth': 5, 'learning_rate': 0.016399755600554223, 'subsample': 0.6318525933020062, 'colsample_bytree': 0.7758825205498896, 'gamma': 2.2519735413759188, 'reg_alpha': 0.21952593095142914, 'reg_lambda': 1.0476084403026409}. Best is trial 9 with value: 0.861111111111111.\n",
      "[I 2025-08-10 20:12:10,606] Trial 10 finished with value: 0.6583333333333333 and parameters: {'n_estimators': 400, 'max_depth': 7, 'learning_rate': 0.047604879743965954, 'subsample': 0.6449383343287942, 'colsample_bytree': 0.9352312093021861, 'gamma': 3.3666819082576245, 'reg_alpha': 1.956498280958177, 'reg_lambda': 0.5863418007008407}. Best is trial 9 with value: 0.861111111111111.\n",
      "[I 2025-08-10 20:12:10,677] Trial 11 finished with value: 0.7722222222222223 and parameters: {'n_estimators': 698, 'max_depth': 3, 'learning_rate': 0.010151440921363013, 'subsample': 0.508705023509461, 'colsample_bytree': 0.6692002345730469, 'gamma': 3.255579270697602, 'reg_alpha': 0.07263379044278404, 'reg_lambda': 1.6499731185648088}. Best is trial 9 with value: 0.861111111111111.\n",
      "[I 2025-08-10 20:12:10,757] Trial 12 finished with value: 0.8416666666666666 and parameters: {'n_estimators': 906, 'max_depth': 6, 'learning_rate': 0.029016991994975563, 'subsample': 0.7198377439159085, 'colsample_bytree': 0.8799275099887216, 'gamma': 0.9302367758304164, 'reg_alpha': 1.4975729806469409, 'reg_lambda': 1.2064692449850944}. Best is trial 9 with value: 0.861111111111111.\n",
      "[I 2025-08-10 20:12:10,841] Trial 13 finished with value: 0.8166666666666667 and parameters: {'n_estimators': 982, 'max_depth': 6, 'learning_rate': 0.031797240433458, 'subsample': 0.7062647739043462, 'colsample_bytree': 0.8674887998383968, 'gamma': 0.91428465126935, 'reg_alpha': 2.121969340770611, 'reg_lambda': 1.0132785067913437}. Best is trial 9 with value: 0.861111111111111.\n",
      "[I 2025-08-10 20:12:10,900] Trial 14 finished with value: 0.7472222222222221 and parameters: {'n_estimators': 557, 'max_depth': 10, 'learning_rate': 0.09555479563591658, 'subsample': 0.7924421899750372, 'colsample_bytree': 0.8912687362494338, 'gamma': 2.669934654292499, 'reg_alpha': 1.2080009990736142, 'reg_lambda': 1.1341303363755622}. Best is trial 9 with value: 0.861111111111111.\n",
      "[I 2025-08-10 20:12:10,941] Trial 15 finished with value: 0.45555555555555555 and parameters: {'n_estimators': 282, 'max_depth': 9, 'learning_rate': 0.02962746445946303, 'subsample': 0.6672885121392906, 'colsample_bytree': 0.7185058678332807, 'gamma': 4.91224889421936, 'reg_alpha': 2.999596728998739, 'reg_lambda': 0.07596607728654226}. Best is trial 9 with value: 0.861111111111111.\n",
      "[I 2025-08-10 20:12:11,020] Trial 16 finished with value: 0.7472222222222222 and parameters: {'n_estimators': 854, 'max_depth': 6, 'learning_rate': 0.02478686483610122, 'subsample': 0.554191124256687, 'colsample_bytree': 0.8700918046810769, 'gamma': 4.0368861573368005, 'reg_alpha': 0.17652073719190575, 'reg_lambda': 1.2225210994663112}. Best is trial 9 with value: 0.861111111111111.\n",
      "[I 2025-08-10 20:12:11,070] Trial 17 finished with value: 0.7944444444444444 and parameters: {'n_estimators': 466, 'max_depth': 7, 'learning_rate': 0.07759590339952957, 'subsample': 0.6766192253672544, 'colsample_bytree': 0.9946636680853438, 'gamma': 1.1724721418738537, 'reg_alpha': 1.4732267570653614, 'reg_lambda': 2.4204416576765224}. Best is trial 9 with value: 0.861111111111111.\n",
      "[I 2025-08-10 20:12:11,128] Trial 18 finished with value: 0.6805555555555556 and parameters: {'n_estimators': 643, 'max_depth': 3, 'learning_rate': 0.14830187101150605, 'subsample': 0.7590819597594375, 'colsample_bytree': 0.8345418627507593, 'gamma': 2.061164814816581, 'reg_alpha': 2.6811443412397544, 'reg_lambda': 1.502147954420808}. Best is trial 9 with value: 0.861111111111111.\n",
      "[I 2025-08-10 20:12:11,169] Trial 19 finished with value: 0.7666666666666666 and parameters: {'n_estimators': 212, 'max_depth': 10, 'learning_rate': 0.060927025015404125, 'subsample': 0.6116615591883848, 'colsample_bytree': 0.9159658966165918, 'gamma': 2.664995414172165, 'reg_alpha': 0.6952985289630097, 'reg_lambda': 0.653195229925892}. Best is trial 9 with value: 0.861111111111111.\n",
      "[I 2025-08-10 20:12:11,218] Trial 20 finished with value: 0.8166666666666667 and parameters: {'n_estimators': 469, 'max_depth': 5, 'learning_rate': 0.043026193695402615, 'subsample': 0.5132303501963972, 'colsample_bytree': 0.7506455491786753, 'gamma': 0.8028191497539621, 'reg_alpha': 1.3793478411462152, 'reg_lambda': 2.429671223802172}. Best is trial 9 with value: 0.861111111111111.\n",
      "[I 2025-08-10 20:12:11,299] Trial 21 finished with value: 0.8166666666666667 and parameters: {'n_estimators': 1000, 'max_depth': 6, 'learning_rate': 0.035133761574463, 'subsample': 0.7085752230419746, 'colsample_bytree': 0.8623803541299078, 'gamma': 0.9474665071018086, 'reg_alpha': 2.059776284850929, 'reg_lambda': 0.8130980874702587}. Best is trial 9 with value: 0.861111111111111.\n",
      "[I 2025-08-10 20:12:11,370] Trial 22 finished with value: 0.611111111111111 and parameters: {'n_estimators': 871, 'max_depth': 7, 'learning_rate': 0.02309610410769587, 'subsample': 0.6990002614619852, 'colsample_bytree': 0.9381281466454603, 'gamma': 1.5153213909817331, 'reg_alpha': 3.2619901633347035, 'reg_lambda': 1.1870538288207761}. Best is trial 9 with value: 0.861111111111111.\n",
      "[I 2025-08-10 20:12:11,439] Trial 23 finished with value: 0.8388888888888889 and parameters: {'n_estimators': 846, 'max_depth': 5, 'learning_rate': 0.034551500105052646, 'subsample': 0.6272290095844972, 'colsample_bytree': 0.7736673941148118, 'gamma': 0.552987780572701, 'reg_alpha': 2.0292847168304062, 'reg_lambda': 1.8324846640114345}. Best is trial 9 with value: 0.861111111111111.\n",
      "[I 2025-08-10 20:12:11,511] Trial 24 finished with value: 0.8388888888888889 and parameters: {'n_estimators': 878, 'max_depth': 5, 'learning_rate': 0.03905691495832687, 'subsample': 0.6250725299359523, 'colsample_bytree': 0.7600434190231987, 'gamma': 0.48312967666260764, 'reg_alpha': 1.6284512793731394, 'reg_lambda': 1.9002423354436904}. Best is trial 9 with value: 0.861111111111111.\n",
      "[I 2025-08-10 20:12:11,581] Trial 25 finished with value: 0.6361111111111111 and parameters: {'n_estimators': 784, 'max_depth': 4, 'learning_rate': 0.01423971380918864, 'subsample': 0.5691780172797946, 'colsample_bytree': 0.6458471638860758, 'gamma': 1.6962890100565198, 'reg_alpha': 2.487467085016299, 'reg_lambda': 1.573935746729408}. Best is trial 9 with value: 0.861111111111111.\n",
      "[I 2025-08-10 20:12:11,642] Trial 26 finished with value: 0.8166666666666667 and parameters: {'n_estimators': 632, 'max_depth': 8, 'learning_rate': 0.0668673396977642, 'subsample': 0.6455989861809612, 'colsample_bytree': 0.7017426219221606, 'gamma': 0.026862158039913986, 'reg_alpha': 1.0155977562954304, 'reg_lambda': 0.4304543552540647}. Best is trial 9 with value: 0.861111111111111.\n",
      "[I 2025-08-10 20:12:11,711] Trial 27 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 821, 'max_depth': 3, 'learning_rate': 0.022626999681824245, 'subsample': 0.7970088826168483, 'colsample_bytree': 0.8115427798277244, 'gamma': 1.1231868437826464, 'reg_alpha': 0.4589995116997439, 'reg_lambda': 2.718280580801548}. Best is trial 27 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:12:11,793] Trial 28 finished with value: 0.7944444444444444 and parameters: {'n_estimators': 909, 'max_depth': 3, 'learning_rate': 0.022594053174400927, 'subsample': 0.7939307486774585, 'colsample_bytree': 0.8108130577632678, 'gamma': 2.285562326740629, 'reg_alpha': 0.33310609989538387, 'reg_lambda': 2.7819384049129896}. Best is trial 27 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:12:11,853] Trial 29 finished with value: 0.7055555555555555 and parameters: {'n_estimators': 640, 'max_depth': 4, 'learning_rate': 0.017071460498573426, 'subsample': 0.8309811018974442, 'colsample_bytree': 0.8409576265451694, 'gamma': 2.385458867961699, 'reg_alpha': 0.39078788161213796, 'reg_lambda': 3.5446304304184615}. Best is trial 27 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:12:11,926] Trial 30 finished with value: 0.8416666666666666 and parameters: {'n_estimators': 786, 'max_depth': 3, 'learning_rate': 0.01680944576232293, 'subsample': 0.7952009652323035, 'colsample_bytree': 0.5934309098762668, 'gamma': 1.1905511626729701, 'reg_alpha': 1.0070316573396667, 'reg_lambda': 2.22577706631625}. Best is trial 27 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:12:11,995] Trial 31 finished with value: 0.7944444444444444 and parameters: {'n_estimators': 702, 'max_depth': 3, 'learning_rate': 0.01010022797101907, 'subsample': 0.7946539733427253, 'colsample_bytree': 0.5649603058284514, 'gamma': 1.1777592815860227, 'reg_alpha': 0.9611548277152726, 'reg_lambda': 2.2670881128101947}. Best is trial 27 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:12:12,069] Trial 32 finished with value: 0.8166666666666667 and parameters: {'n_estimators': 809, 'max_depth': 4, 'learning_rate': 0.017276411488624435, 'subsample': 0.7367694659508128, 'colsample_bytree': 0.57809281203532, 'gamma': 1.7644829560670048, 'reg_alpha': 0.5343781324540147, 'reg_lambda': 2.730431327270871}. Best is trial 27 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:12:12,150] Trial 33 finished with value: 0.7972222222222222 and parameters: {'n_estimators': 928, 'max_depth': 5, 'learning_rate': 0.020996111647320962, 'subsample': 0.8845685728505962, 'colsample_bytree': 0.6830452064101754, 'gamma': 1.2299560976881165, 'reg_alpha': 1.0590734188712387, 'reg_lambda': 3.1559381388606766}. Best is trial 27 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:12:12,224] Trial 34 finished with value: 0.6583333333333333 and parameters: {'n_estimators': 712, 'max_depth': 3, 'learning_rate': 0.025786750629010095, 'subsample': 0.7639917913739385, 'colsample_bytree': 0.7357242114766729, 'gamma': 3.0670426327290845, 'reg_alpha': 1.695167935930747, 'reg_lambda': 3.958796934877916}. Best is trial 27 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:12:12,274] Trial 35 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 330, 'max_depth': 6, 'learning_rate': 0.016049627809449962, 'subsample': 0.8393207574828702, 'colsample_bytree': 0.6081951189229564, 'gamma': 2.0621872497030767, 'reg_alpha': 0.3350293623159688, 'reg_lambda': 1.4372158797524377}. Best is trial 27 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:12:12,327] Trial 36 finished with value: 0.8166666666666667 and parameters: {'n_estimators': 305, 'max_depth': 8, 'learning_rate': 0.013260618176734495, 'subsample': 0.9203329863660589, 'colsample_bytree': 0.787831799891242, 'gamma': 2.1193399954217114, 'reg_alpha': 0.042066160506314176, 'reg_lambda': 1.4307063584592632}. Best is trial 27 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:12:12,377] Trial 37 finished with value: 0.8194444444444443 and parameters: {'n_estimators': 370, 'max_depth': 6, 'learning_rate': 0.02021076151078474, 'subsample': 0.842994999508786, 'colsample_bytree': 0.5418885565054907, 'gamma': 3.8200850939461053, 'reg_alpha': 0.5098948757699396, 'reg_lambda': 0.2217417608937392}. Best is trial 27 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:12:12,430] Trial 38 finished with value: 0.45555555555555555 and parameters: {'n_estimators': 504, 'max_depth': 7, 'learning_rate': 0.011844880946062621, 'subsample': 0.9259774719581808, 'colsample_bytree': 0.8995106156992643, 'gamma': 2.732415118094144, 'reg_alpha': 3.79745431486745, 'reg_lambda': 0.8614547536810613}. Best is trial 27 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:12:12,473] Trial 39 finished with value: 0.7972222222222222 and parameters: {'n_estimators': 234, 'max_depth': 9, 'learning_rate': 0.028146088337773673, 'subsample': 0.853603106459371, 'colsample_bytree': 0.8473793551878299, 'gamma': 1.970567560881572, 'reg_alpha': 0.7250036353220615, 'reg_lambda': 2.1672430384700805}. Best is trial 27 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:12:12,527] Trial 40 finished with value: 0.8166666666666667 and parameters: {'n_estimators': 375, 'max_depth': 6, 'learning_rate': 0.014809970791646311, 'subsample': 0.9673788264263586, 'colsample_bytree': 0.6168021122805224, 'gamma': 1.6539867275339748, 'reg_alpha': 0.4059234623774115, 'reg_lambda': 1.319507434801686}. Best is trial 27 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:12:12,623] Trial 41 finished with value: 0.7722222222222221 and parameters: {'n_estimators': 812, 'max_depth': 4, 'learning_rate': 0.018442796238140567, 'subsample': 0.8115319775404786, 'colsample_bytree': 0.6010466837122516, 'gamma': 1.3783957659474126, 'reg_alpha': 0.8975639099840154, 'reg_lambda': 2.675304411924033}. Best is trial 27 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:12:12,685] Trial 42 finished with value: 0.7722222222222221 and parameters: {'n_estimators': 429, 'max_depth': 5, 'learning_rate': 0.01550317601183619, 'subsample': 0.7738151363393204, 'colsample_bytree': 0.534671065403066, 'gamma': 0.8564341987427305, 'reg_alpha': 1.305866177555361, 'reg_lambda': 3.0908763306808162}. Best is trial 27 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:12:12,738] Trial 43 finished with value: 0.8166666666666667 and parameters: {'n_estimators': 327, 'max_depth': 4, 'learning_rate': 0.011194815880035767, 'subsample': 0.9031432665359698, 'colsample_bytree': 0.6503978897884237, 'gamma': 0.37542230977623625, 'reg_alpha': 0.27150441401867215, 'reg_lambda': 1.7133738609451026}. Best is trial 27 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:12:12,830] Trial 44 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 962, 'max_depth': 3, 'learning_rate': 0.02043854687575446, 'subsample': 0.8253418069377289, 'colsample_bytree': 0.8084356138270394, 'gamma': 0.736466382723191, 'reg_alpha': 0.6287929824360915, 'reg_lambda': 3.4523811454689524}. Best is trial 27 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:12:12,925] Trial 45 finished with value: 0.8166666666666667 and parameters: {'n_estimators': 959, 'max_depth': 5, 'learning_rate': 0.020186748489982, 'subsample': 0.855718366212112, 'colsample_bytree': 0.8088860205240774, 'gamma': 0.633470877552464, 'reg_alpha': 0.03131646719696962, 'reg_lambda': 3.5170067605168525}. Best is trial 27 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:12:12,967] Trial 46 finished with value: 0.7944444444444444 and parameters: {'n_estimators': 121, 'max_depth': 4, 'learning_rate': 0.026547295172269506, 'subsample': 0.7315713051055709, 'colsample_bytree': 0.7989128153631168, 'gamma': 1.5302691912391386, 'reg_alpha': 0.6952199858376359, 'reg_lambda': 3.4022749722421106}. Best is trial 27 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:12:13,052] Trial 47 finished with value: 0.8416666666666666 and parameters: {'n_estimators': 915, 'max_depth': 15, 'learning_rate': 0.05246717712212359, 'subsample': 0.8139354475515912, 'colsample_bytree': 0.7312843021852311, 'gamma': 0.22003770478287532, 'reg_alpha': 0.5759228544778968, 'reg_lambda': 3.859718062658144}. Best is trial 27 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:12:13,135] Trial 48 finished with value: 0.8583333333333332 and parameters: {'n_estimators': 966, 'max_depth': 13, 'learning_rate': 0.29479768036736803, 'subsample': 0.8841775786987267, 'colsample_bytree': 0.7642256799372125, 'gamma': 0.7181756538223625, 'reg_alpha': 0.23840937315255228, 'reg_lambda': 4.254550395578452}. Best is trial 27 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:12:13,219] Trial 49 finished with value: 0.8388888888888889 and parameters: {'n_estimators': 968, 'max_depth': 14, 'learning_rate': 0.205450033017571, 'subsample': 0.8837887141679792, 'colsample_bytree': 0.7702296335241743, 'gamma': 0.7549620376307996, 'reg_alpha': 0.21226678461225454, 'reg_lambda': 4.521582408079153}. Best is trial 27 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:12:13,311] Trial 50 finished with value: 0.7722222222222221 and parameters: {'n_estimators': 948, 'max_depth': 12, 'learning_rate': 0.23167570336053422, 'subsample': 0.9544962260709142, 'colsample_bytree': 0.7043347892436437, 'gamma': 2.523913711174584, 'reg_alpha': 0.2312309373970536, 'reg_lambda': 4.3346460587657845}. Best is trial 27 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:12:13,395] Trial 51 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 896, 'max_depth': 14, 'learning_rate': 0.03146942156386509, 'subsample': 0.8648240154047843, 'colsample_bytree': 0.8248328167543343, 'gamma': 1.0313551292210332, 'reg_alpha': 0.002652005884110409, 'reg_lambda': 3.894276373226867}. Best is trial 27 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:12:13,477] Trial 52 finished with value: 0.7277777777777777 and parameters: {'n_estimators': 999, 'max_depth': 14, 'learning_rate': 0.09886650430719597, 'subsample': 0.8976494215499214, 'colsample_bytree': 0.8253806252269591, 'gamma': 2.9127759966433695, 'reg_alpha': 0.4531227073159769, 'reg_lambda': 4.9406050766289304}. Best is trial 27 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:12:13,543] Trial 53 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 583, 'max_depth': 14, 'learning_rate': 0.02250090312588606, 'subsample': 0.8651408279747109, 'colsample_bytree': 0.7840129400777578, 'gamma': 1.0252147175641704, 'reg_alpha': 0.012092714414706107, 'reg_lambda': 3.8677286199733056}. Best is trial 27 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:12:13,585] Trial 54 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 251, 'max_depth': 14, 'learning_rate': 0.023175720435914118, 'subsample': 0.858452339613247, 'colsample_bytree': 0.8507580936349065, 'gamma': 1.0661748090136762, 'reg_alpha': 0.008661390141368758, 'reg_lambda': 3.8786260894959703}. Best is trial 27 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:12:13,629] Trial 55 finished with value: 0.8416666666666666 and parameters: {'n_estimators': 191, 'max_depth': 14, 'learning_rate': 0.023323804059059528, 'subsample': 0.8598096617682547, 'colsample_bytree': 0.848227539545508, 'gamma': 1.0324513908771933, 'reg_alpha': 0.031073406367038703, 'reg_lambda': 3.9024289850016656}. Best is trial 27 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:12:13,702] Trial 56 finished with value: 0.7722222222222221 and parameters: {'n_estimators': 586, 'max_depth': 12, 'learning_rate': 0.03513456480968371, 'subsample': 0.8225830426068259, 'colsample_bytree': 0.815710365009424, 'gamma': 1.3960090938586365, 'reg_alpha': 0.8184408855635132, 'reg_lambda': 3.7561780578442923}. Best is trial 27 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:12:13,746] Trial 57 finished with value: 0.7916666666666666 and parameters: {'n_estimators': 261, 'max_depth': 13, 'learning_rate': 0.044122527464842555, 'subsample': 0.8375245327888291, 'colsample_bytree': 0.7873696984418739, 'gamma': 0.32252523266654887, 'reg_alpha': 0.01497091099666351, 'reg_lambda': 3.2842096851609166}. Best is trial 27 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:12:13,789] Trial 58 finished with value: 0.8416666666666666 and parameters: {'n_estimators': 170, 'max_depth': 15, 'learning_rate': 0.03272767052213774, 'subsample': 0.9184216984559113, 'colsample_bytree': 0.89051350600479, 'gamma': 0.9970624646324583, 'reg_alpha': 0.5053208320642583, 'reg_lambda': 4.06110681421566}. Best is trial 27 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:12:13,864] Trial 59 finished with value: 0.7055555555555555 and parameters: {'n_estimators': 730, 'max_depth': 11, 'learning_rate': 0.030570532815691907, 'subsample': 0.7754149252733002, 'colsample_bytree': 0.9254223409201885, 'gamma': 1.8173119063870642, 'reg_alpha': 0.6259431901798616, 'reg_lambda': 4.641327937150417}. Best is trial 27 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:12:13,949] Trial 60 finished with value: 0.8166666666666667 and parameters: {'n_estimators': 832, 'max_depth': 13, 'learning_rate': 0.01881499395681747, 'subsample': 0.8689926900584766, 'colsample_bytree': 0.8687131278523876, 'gamma': 0.45589977741377297, 'reg_alpha': 0.17005347431010318, 'reg_lambda': 3.6709015899002564}. Best is trial 27 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:12:14,001] Trial 61 finished with value: 0.7722222222222221 and parameters: {'n_estimators': 342, 'max_depth': 14, 'learning_rate': 0.02173706539140211, 'subsample': 0.8142347487606019, 'colsample_bytree': 0.7464596002256464, 'gamma': 2.1225654585342886, 'reg_alpha': 0.3576440558119229, 'reg_lambda': 2.933459524361232}. Best is trial 27 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:12:14,055] Trial 62 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 416, 'max_depth': 11, 'learning_rate': 0.02467122994513627, 'subsample': 0.8415981122322124, 'colsample_bytree': 0.8012266168054788, 'gamma': 1.329342597495621, 'reg_alpha': 0.1827325218773329, 'reg_lambda': 4.053554874583024}. Best is trial 27 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:12:14,108] Trial 63 finished with value: 0.7972222222222222 and parameters: {'n_estimators': 267, 'max_depth': 11, 'learning_rate': 0.024999336234410575, 'subsample': 0.8406214762047733, 'colsample_bytree': 0.8275397842721157, 'gamma': 1.3735566573194962, 'reg_alpha': 0.8321466676436167, 'reg_lambda': 4.451627436535886}. Best is trial 27 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:12:14,193] Trial 64 finished with value: 0.7972222222222222 and parameters: {'n_estimators': 890, 'max_depth': 14, 'learning_rate': 0.028310285195547114, 'subsample': 0.8735681416528951, 'colsample_bytree': 0.8043665517378386, 'gamma': 1.1061879611363916, 'reg_alpha': 1.150470723865281, 'reg_lambda': 4.103023381112822}. Best is trial 27 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:12:14,247] Trial 65 finished with value: 0.8194444444444443 and parameters: {'n_estimators': 438, 'max_depth': 11, 'learning_rate': 0.015348777955580449, 'subsample': 0.8529868310350696, 'colsample_bytree': 0.8537315019937891, 'gamma': 1.5760321596800724, 'reg_alpha': 0.1523199477610454, 'reg_lambda': 4.078387642245581}. Best is trial 27 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:12:14,305] Trial 66 finished with value: 0.8194444444444443 and parameters: {'n_estimators': 414, 'max_depth': 12, 'learning_rate': 0.03873422270568992, 'subsample': 0.9052485382610956, 'colsample_bytree': 0.777430347994346, 'gamma': 1.3173786694905034, 'reg_alpha': 0.3451691880521215, 'reg_lambda': 3.7230086647465552}. Best is trial 27 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:12:14,372] Trial 67 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 513, 'max_depth': 15, 'learning_rate': 0.023414689307974062, 'subsample': 0.8073269783971301, 'colsample_bytree': 0.834228175472173, 'gamma': 0.6606511160073589, 'reg_alpha': 0.5246321629941774, 'reg_lambda': 3.4023100133569075}. Best is trial 27 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:12:14,449] Trial 68 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 596, 'max_depth': 9, 'learning_rate': 0.018095797817776836, 'subsample': 0.8343052849803371, 'colsample_bytree': 0.8791387658020683, 'gamma': 0.8911727913049694, 'reg_alpha': 0.011512880930896807, 'reg_lambda': 2.9567267230763483}. Best is trial 27 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:12:14,502] Trial 69 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 348, 'max_depth': 10, 'learning_rate': 0.020104322751525416, 'subsample': 0.7802224267934839, 'colsample_bytree': 0.7880262971823471, 'gamma': 1.0506774837316495, 'reg_alpha': 0.355987417184816, 'reg_lambda': 3.582658817395421}. Best is trial 27 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:12:14,557] Trial 70 finished with value: 0.45555555555555555 and parameters: {'n_estimators': 484, 'max_depth': 13, 'learning_rate': 0.037970057055651575, 'subsample': 0.7554169435647929, 'colsample_bytree': 0.9061499702933806, 'gamma': 1.8664321358558, 'reg_alpha': 4.196660735318589, 'reg_lambda': 2.5605458022964314}. Best is trial 27 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:12:14,621] Trial 71 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 548, 'max_depth': 15, 'learning_rate': 0.02354289757463522, 'subsample': 0.8042367785132111, 'colsample_bytree': 0.8211429326718409, 'gamma': 0.645642108269433, 'reg_alpha': 0.5531726478000092, 'reg_lambda': 3.420392041233974}. Best is trial 27 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:12:14,686] Trial 72 finished with value: 0.8416666666666666 and parameters: {'n_estimators': 506, 'max_depth': 15, 'learning_rate': 0.025391898684741863, 'subsample': 0.8253367278873487, 'colsample_bytree': 0.8361356284824973, 'gamma': 0.5277867129981111, 'reg_alpha': 0.15538852995050434, 'reg_lambda': 3.217653473496309}. Best is trial 27 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:12:14,739] Trial 73 finished with value: 0.8166666666666667 and parameters: {'n_estimators': 308, 'max_depth': 14, 'learning_rate': 0.022035393448616773, 'subsample': 0.8670074435709711, 'colsample_bytree': 0.8596901568676552, 'gamma': 0.11263522573244567, 'reg_alpha': 0.6841278579323464, 'reg_lambda': 3.8354278733879354}. Best is trial 27 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:12:14,815] Trial 74 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 670, 'max_depth': 15, 'learning_rate': 0.02754546224281331, 'subsample': 0.8021884051607999, 'colsample_bytree': 0.7540168891700326, 'gamma': 0.8035477527824247, 'reg_alpha': 0.47977178025226597, 'reg_lambda': 4.236758125381375}. Best is trial 27 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:12:14,881] Trial 75 finished with value: 0.7722222222222221 and parameters: {'n_estimators': 445, 'max_depth': 14, 'learning_rate': 0.012739710098444356, 'subsample': 0.7834645366805564, 'colsample_bytree': 0.7987926936698094, 'gamma': 1.1534360641982873, 'reg_alpha': 0.8524600079423563, 'reg_lambda': 3.9677940548297315}. Best is trial 27 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:12:14,960] Trial 76 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 612, 'max_depth': 3, 'learning_rate': 0.016286560341437595, 'subsample': 0.849638612337222, 'colsample_bytree': 0.8396974563116429, 'gamma': 0.9574244601946835, 'reg_alpha': 0.2951467748639843, 'reg_lambda': 3.66346354054345}. Best is trial 27 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:12:15,005] Trial 77 finished with value: 0.4805555555555555 and parameters: {'n_estimators': 240, 'max_depth': 13, 'learning_rate': 0.030490183117472924, 'subsample': 0.8275620473958017, 'colsample_bytree': 0.8170576896725492, 'gamma': 1.2673865063926815, 'reg_alpha': 3.338724619914925, 'reg_lambda': 3.3670053015705896}. Best is trial 27 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:12:15,062] Trial 78 finished with value: 0.75 and parameters: {'n_estimators': 391, 'max_depth': 15, 'learning_rate': 0.01930604059617339, 'subsample': 0.7434285271097811, 'colsample_bytree': 0.8790301689077435, 'gamma': 0.6758247654807482, 'reg_alpha': 2.259805339055646, 'reg_lambda': 3.510114855493193}. Best is trial 27 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:12:15,128] Trial 79 finished with value: 0.45555555555555555 and parameters: {'n_estimators': 541, 'max_depth': 3, 'learning_rate': 0.013989162438471448, 'subsample': 0.8918977478898991, 'colsample_bytree': 0.5232691842008066, 'gamma': 1.4613621943514197, 'reg_alpha': 4.861568095170178, 'reg_lambda': 2.995405042760505}. Best is trial 27 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:12:15,197] Trial 80 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 291, 'max_depth': 10, 'learning_rate': 0.024361982061989904, 'subsample': 0.8132344279732031, 'colsample_bytree': 0.7767468793365924, 'gamma': 1.6696854382920243, 'reg_alpha': 0.12008762178168086, 'reg_lambda': 2.8402211198479748}. Best is trial 27 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:12:15,260] Trial 81 finished with value: 0.8388888888888889 and parameters: {'n_estimators': 569, 'max_depth': 9, 'learning_rate': 0.01749225881296552, 'subsample': 0.8394464411788012, 'colsample_bytree': 0.9598155506993172, 'gamma': 0.9054814401921236, 'reg_alpha': 0.033922241961478444, 'reg_lambda': 3.062535479550966}. Best is trial 27 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:12:15,337] Trial 82 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 598, 'max_depth': 8, 'learning_rate': 0.01857981877704606, 'subsample': 0.8630082209755728, 'colsample_bytree': 0.8726418489866486, 'gamma': 0.8598484806219451, 'reg_alpha': 0.42527834781153484, 'reg_lambda': 3.2697561274904965}. Best is trial 27 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:12:15,402] Trial 83 finished with value: 0.8166666666666667 and parameters: {'n_estimators': 509, 'max_depth': 12, 'learning_rate': 0.021355598310522153, 'subsample': 0.873812433139891, 'colsample_bytree': 0.8285066832108109, 'gamma': 0.4426452647697748, 'reg_alpha': 0.6179494168000962, 'reg_lambda': 2.6004369230038398}. Best is trial 27 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:12:15,467] Trial 84 finished with value: 0.6583333333333333 and parameters: {'n_estimators': 526, 'max_depth': 8, 'learning_rate': 0.016192425012097535, 'subsample': 0.8219421466391976, 'colsample_bytree': 0.8918076975263711, 'gamma': 4.518164832230847, 'reg_alpha': 0.2552625715828304, 'reg_lambda': 3.790373122268807}. Best is trial 27 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:12:15,551] Trial 85 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 929, 'max_depth': 9, 'learning_rate': 0.02270061139120572, 'subsample': 0.8446460688261794, 'colsample_bytree': 0.8539421699462606, 'gamma': 1.0922781206131362, 'reg_alpha': 0.12974009901799563, 'reg_lambda': 2.447248253893031}. Best is trial 27 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:12:15,627] Trial 86 finished with value: 0.8166666666666667 and parameters: {'n_estimators': 667, 'max_depth': 6, 'learning_rate': 0.017788890119245473, 'subsample': 0.7897416709388584, 'colsample_bytree': 0.8063654130997194, 'gamma': 0.59724503594401, 'reg_alpha': 0.02129739093293906, 'reg_lambda': 2.3545109871163223}. Best is trial 27 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:12:15,712] Trial 87 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 864, 'max_depth': 14, 'learning_rate': 0.032542045627304575, 'subsample': 0.8336560072304477, 'colsample_bytree': 0.8395219213889519, 'gamma': 0.7637345844403037, 'reg_alpha': 0.3089885135403006, 'reg_lambda': 4.344977403029922}. Best is trial 27 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:12:15,768] Trial 88 finished with value: 0.7055555555555555 and parameters: {'n_estimators': 409, 'max_depth': 7, 'learning_rate': 0.026136112067318, 'subsample': 0.8027001692844381, 'colsample_bytree': 0.7391203718908324, 'gamma': 1.2981034397752602, 'reg_alpha': 1.7825493909559222, 'reg_lambda': 4.127481462591008}. Best is trial 27 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:12:15,813] Trial 89 finished with value: 0.7722222222222221 and parameters: {'n_estimators': 146, 'max_depth': 13, 'learning_rate': 0.060029945265775216, 'subsample': 0.9082231704013466, 'colsample_bytree': 0.8858224863997747, 'gamma': 0.9907857229485865, 'reg_alpha': 1.122261161424059, 'reg_lambda': 2.1022790269776683}. Best is trial 27 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:12:15,869] Trial 90 finished with value: 0.7722222222222221 and parameters: {'n_estimators': 457, 'max_depth': 15, 'learning_rate': 0.01119304241783496, 'subsample': 0.7691152205442077, 'colsample_bytree': 0.7946169954727309, 'gamma': 1.4851817490502794, 'reg_alpha': 0.7805866437972009, 'reg_lambda': 2.876809157729527}. Best is trial 27 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:12:15,924] Trial 91 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 326, 'max_depth': 10, 'learning_rate': 0.020112307722065664, 'subsample': 0.7817995684186398, 'colsample_bytree': 0.7829341498700553, 'gamma': 1.0534332315166663, 'reg_alpha': 0.4226949154580088, 'reg_lambda': 3.6192856238248177}. Best is trial 27 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:12:15,982] Trial 92 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 369, 'max_depth': 11, 'learning_rate': 0.02073049273975055, 'subsample': 0.8559260217784584, 'colsample_bytree': 0.7630280849702514, 'gamma': 1.2143389705606873, 'reg_alpha': 0.16928676362389267, 'reg_lambda': 3.497896978754073}. Best is trial 27 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:12:16,041] Trial 93 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 349, 'max_depth': 10, 'learning_rate': 0.019050429487597616, 'subsample': 0.8221077209727193, 'colsample_bytree': 0.7935237891003056, 'gamma': 0.8667304523909879, 'reg_alpha': 0.3423510323392179, 'reg_lambda': 3.9627352058597083}. Best is trial 27 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:12:16,100] Trial 94 finished with value: 0.8166666666666667 and parameters: {'n_estimators': 216, 'max_depth': 9, 'learning_rate': 0.014891749035312329, 'subsample': 0.8915478162515151, 'colsample_bytree': 0.7224680382242206, 'gamma': 0.29229655461866233, 'reg_alpha': 0.6039723550132589, 'reg_lambda': 3.3811387752974604}. Best is trial 27 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:12:16,158] Trial 95 finished with value: 0.8388888888888889 and parameters: {'n_estimators': 349, 'max_depth': 10, 'learning_rate': 0.023619215735788287, 'subsample': 0.809334339749047, 'colsample_bytree': 0.8143123946954879, 'gamma': 0.7455853571657525, 'reg_alpha': 0.11208728540829596, 'reg_lambda': 3.1061188743630965}. Best is trial 27 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:12:16,248] Trial 96 finished with value: 0.8194444444444443 and parameters: {'n_estimators': 895, 'max_depth': 14, 'learning_rate': 0.02881751129893077, 'subsample': 0.7902690091804648, 'colsample_bytree': 0.8476264455127214, 'gamma': 1.0624597546889523, 'reg_alpha': 0.9551683127418417, 'reg_lambda': 3.6012861453949965}. Best is trial 27 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:12:16,313] Trial 97 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 484, 'max_depth': 11, 'learning_rate': 0.021420140883406116, 'subsample': 0.8779381035785675, 'colsample_bytree': 0.8280684472966131, 'gamma': 0.5589502841712963, 'reg_alpha': 0.47092825976927044, 'reg_lambda': 3.7558187555287206}. Best is trial 27 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:12:16,390] Trial 98 finished with value: 0.8638888888888889 and parameters: {'n_estimators': 764, 'max_depth': 3, 'learning_rate': 0.016791888352776483, 'subsample': 0.8348261855561081, 'colsample_bytree': 0.8041722869249087, 'gamma': 0.9351690170624294, 'reg_alpha': 0.24458741899708503, 'reg_lambda': 2.7161593505744825}. Best is trial 27 with value: 0.8638888888888889.\n",
      "[I 2025-08-10 20:12:16,447] Trial 99 finished with value: 0.7055555555555555 and parameters: {'n_estimators': 265, 'max_depth': 9, 'learning_rate': 0.026920919342049508, 'subsample': 0.9309808800730519, 'colsample_bytree': 0.8680109008430518, 'gamma': 3.5773641385517805, 'reg_alpha': 0.014116050952756316, 'reg_lambda': 3.981012154280532}. Best is trial 27 with value: 0.8638888888888889.\n",
      "Best params for XGBoost: {'n_estimators': 821, 'max_depth': 3, 'learning_rate': 0.022626999681824245, 'subsample': 0.7970088826168483, 'colsample_bytree': 0.8115427798277244, 'gamma': 1.1231868437826464, 'reg_alpha': 0.4589995116997439, 'reg_lambda': 2.718280580801548}\n",
      "Best accuracy: 0.8639\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "def objective_ada(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 500),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 1.0, log=True),\n",
    "    }\n",
    "    model = AdaBoostClassifier(**params, random_state=42)\n",
    "    return cross_val_score(model, X_scaled_pca, y_encoded, cv=cv, scoring='accuracy', n_jobs=-1).mean()\n",
    "\n",
    "def objective_rf(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 30),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 20),\n",
    "        'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2', None]),\n",
    "    }\n",
    "    model = RandomForestClassifier(**params, random_state=42)\n",
    "    return cross_val_score(model, X_scaled_pca, y_encoded, cv=cv, scoring='accuracy', n_jobs=-1).mean()\n",
    "\n",
    "def objective_catboost(trial):\n",
    "    params = {\n",
    "        'depth': trial.suggest_int('depth', 4, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "        'iterations': trial.suggest_int('iterations', 100, 1000),\n",
    "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1e-3, 10.0, log=True),\n",
    "        'border_count': trial.suggest_int('border_count', 32, 255)\n",
    "    }\n",
    "    model = CatBoostClassifier(**params, verbose=0, random_state=42)\n",
    "    return cross_val_score(model, X_scaled_pca, y_encoded, cv=cv, scoring='accuracy', n_jobs=-1).mean()\n",
    "\n",
    "def objective_gb(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 20),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0)\n",
    "    }\n",
    "    model = GradientBoostingClassifier(**params, random_state=42)\n",
    "    return cross_val_score(model, X_scaled_pca, y_encoded, cv=cv, scoring='accuracy', n_jobs=-1).mean()\n",
    "\n",
    "def objective_xgb(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'gamma': trial.suggest_float('gamma', 0, 5),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0, 5),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0, 5),\n",
    "        'eval_metric': 'logloss',\n",
    "        'random_state': 42\n",
    "    }\n",
    "    model = XGBClassifier(**params)\n",
    "    return cross_val_score(model, X_scaled_pca, y_encoded, cv=cv, scoring='accuracy', n_jobs=-1).mean()\n",
    "\n",
    "# Map model names to objectives\n",
    "objectives = {\n",
    "    'AdaBoost': objective_ada,\n",
    "    'Random Forest': objective_rf,\n",
    "    'CatBoost': objective_catboost,\n",
    "    'Gradient Boosting': objective_gb,\n",
    "    'XGBoost': objective_xgb,\n",
    "}\n",
    "\n",
    "best_params = {}\n",
    "n_trials = 100\n",
    "\n",
    "for model_name, objective in objectives.items():\n",
    "    print(f\"Starting tuning for {model_name} ...\")\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=n_trials, show_progress_bar=True)\n",
    "    best_params[model_name] = study.best_params\n",
    "    print(f\"Best params for {model_name}: {study.best_params}\")\n",
    "    print(f\"Best accuracy: {study.best_value:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f5e79cfdd034f03b78074b8353eb33f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Cross Validating Models ...:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross Validating Random Forest ...\n",
      "Model: Random Forest\n",
      "  Accuracy : 0.9083\n",
      "  Precision: 0.9267\n",
      "  Recall   : 0.9050\n",
      "  F1 Score : 0.9056\n",
      "  ROC AUC  : 0.9375\n",
      "Completed Cross Validating Random Forest\n",
      "----------------------------------------\n",
      "\n",
      "Cross Validating XGBoost ...\n",
      "Model: XGBoost\n",
      "  Accuracy : 0.8639\n",
      "  Precision: 0.8864\n",
      "  Recall   : 0.8600\n",
      "  F1 Score : 0.8574\n",
      "  ROC AUC  : 0.9425\n",
      "Completed Cross Validating XGBoost\n",
      "----------------------------------------\n",
      "\n",
      "Cross Validating Gradient Boosting ...\n",
      "Model: Gradient Boosting\n",
      "  Accuracy : 0.9306\n",
      "  Precision: 0.9467\n",
      "  Recall   : 0.9250\n",
      "  F1 Score : 0.9278\n",
      "  ROC AUC  : 0.9450\n",
      "Completed Cross Validating Gradient Boosting\n",
      "----------------------------------------\n",
      "\n",
      "Cross Validating CatBoost ...\n",
      "Model: CatBoost\n",
      "  Accuracy : 0.9306\n",
      "  Precision: 0.9467\n",
      "  Recall   : 0.9250\n",
      "  F1 Score : 0.9278\n",
      "  ROC AUC  : 0.9450\n",
      "Completed Cross Validating CatBoost\n",
      "----------------------------------------\n",
      "\n",
      "Cross Validating AdaBoost ...\n",
      "Model: AdaBoost\n",
      "  Accuracy : 0.8861\n",
      "  Precision: 0.8967\n",
      "  Recall   : 0.8800\n",
      "  F1 Score : 0.8811\n",
      "  ROC AUC  : 0.9137\n",
      "Completed Cross Validating AdaBoost\n",
      "----------------------------------------\n",
      "\n",
      "Cross Validating Ensemble ...\n",
      "Model: Ensemble\n",
      "  Accuracy : 0.9306\n",
      "  Precision: 0.9467\n",
      "  Recall   : 0.9250\n",
      "  F1 Score : 0.9278\n",
      "  ROC AUC  : 0.9600\n",
      "Completed Cross Validating Ensemble\n",
      "----------------------------------------\n",
      "\n",
      "All Cross Validation Completed.\n",
      "\n",
      "Summary of Hyperparameter Tuned Model Cross Validation Performance:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>ROC AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.930556</td>\n",
       "      <td>0.946667</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.927850</td>\n",
       "      <td>0.94500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.930556</td>\n",
       "      <td>0.946667</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.927850</td>\n",
       "      <td>0.94500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ensemble</td>\n",
       "      <td>0.930556</td>\n",
       "      <td>0.946667</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.927850</td>\n",
       "      <td>0.96000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.908333</td>\n",
       "      <td>0.926667</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.905628</td>\n",
       "      <td>0.93750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.886111</td>\n",
       "      <td>0.896667</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.881097</td>\n",
       "      <td>0.91375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.863889</td>\n",
       "      <td>0.886429</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.857381</td>\n",
       "      <td>0.94250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model  Accuracy  Precision  Recall  F1 Score  ROC AUC\n",
       "0           CatBoost  0.930556   0.946667   0.925  0.927850  0.94500\n",
       "1  Gradient Boosting  0.930556   0.946667   0.925  0.927850  0.94500\n",
       "2           Ensemble  0.930556   0.946667   0.925  0.927850  0.96000\n",
       "3      Random Forest  0.908333   0.926667   0.905  0.905628  0.93750\n",
       "4           AdaBoost  0.886111   0.896667   0.880  0.881097  0.91375\n",
       "5            XGBoost  0.863889   0.886429   0.860  0.857381  0.94250"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_params = {'n_estimators': 423, 'learning_rate': 0.7300608500092896}\n",
    "rf_params = {'n_estimators': 767, 'max_depth': 19, 'min_samples_split': 7, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
    "cat_params = {'depth': 5, 'learning_rate': 0.15262688468040386, 'iterations': 779, 'l2_leaf_reg': 1.1361450198586107, 'border_count': 74}\n",
    "gb_params = {'n_estimators': 810, 'learning_rate': 0.021629091319927143, 'max_depth': 15, 'min_samples_split': 19, 'min_samples_leaf': 4, 'subsample': 0.816685022589326}\n",
    "xgb_params = {'n_estimators': 821, 'max_depth': 3, 'learning_rate': 0.022626999681824245, 'subsample': 0.7970088826168483, 'colsample_bytree': 0.8115427798277244, 'gamma': 1.1231868437826464, 'reg_alpha': 0.4589995116997439, 'reg_lambda': 2.718280580801548}\n",
    "\n",
    "tuned_models = {\n",
    "    'Random Forest': RandomForestClassifier(random_state=42, **rf_params),\n",
    "    'XGBoost': XGBClassifier(eval_metric='logloss', random_state=42, **xgb_params),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=42, **gb_params),\n",
    "    'CatBoost': CatBoostClassifier(random_state=42, verbose=0, **cat_params),\n",
    "    'AdaBoost': AdaBoostClassifier(random_state=42, **ada_params)\n",
    "}\n",
    "\n",
    "tuned_estimators = [(name, model) for name, model in tuned_models.items()]\n",
    "\n",
    "# Stacking classifier with Logistic Regression as meta-learner\n",
    "stacking_model = StackingClassifier(\n",
    "    estimators=tuned_estimators,\n",
    "    final_estimator=LogisticRegression(),\n",
    "    cv=5,  # Cross-validation for meta-learner\n",
    "    n_jobs=-1,  # Use all available cores\n",
    "    passthrough=False  # Do not pass original features to meta-learner\n",
    ")\n",
    "tuned_models['Ensemble'] = stacking_model\n",
    "\n",
    "# Define the number of classes based on y_encoded\n",
    "n_classes = len(np.unique(y_encoded))\n",
    "\n",
    "# Define custom scoring metrics (with macro average and zero_division=0)\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'precision': make_scorer(precision_score, average='macro', zero_division=0),\n",
    "    'recall': make_scorer(recall_score, average='macro', zero_division=0),\n",
    "    'f1': make_scorer(f1_score, average='macro', zero_division=0),\n",
    "}\n",
    "\n",
    "# Add ROC AUC scorer based on number of classes\n",
    "if n_classes == 2:\n",
    "    scoring['roc_auc'] = 'roc_auc'\n",
    "else:\n",
    "    scoring['roc_auc'] = 'roc_auc_ovr'  # One-vs-Rest for multi-class\n",
    "\n",
    "# Define the cross-validation strategy (5-fold stratified)\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "results = []  # List to store performance metrics for each model\n",
    "\n",
    "# Train each model using k-fold CV and evaluate its performance\n",
    "for name, model in tqdm(tuned_models.items(), desc=\"Cross Validating Models ...\"):\n",
    "    print(f\"\\nCross Validating {name} ...\")\n",
    "    cv_results = cross_validate(model, X_scaled_pca, y_encoded, cv=cv, scoring=scoring, n_jobs=-1)\n",
    "    \n",
    "    # Calculate mean performance metrics across folds\n",
    "    accuracy = cv_results['test_accuracy'].mean()\n",
    "    precision = cv_results['test_precision'].mean()\n",
    "    recall = cv_results['test_recall'].mean()\n",
    "    f1 = cv_results['test_f1'].mean()\n",
    "    roc_auc = cv_results['test_roc_auc'].mean() if 'test_roc_auc' in cv_results else np.nan\n",
    "    \n",
    "    # Print performance metrics\n",
    "    print(f\"Model: {name}\")\n",
    "    print(f\"  Accuracy : {accuracy:.4f}\")\n",
    "    print(f\"  Precision: {precision:.4f}\")\n",
    "    print(f\"  Recall   : {recall:.4f}\")\n",
    "    print(f\"  F1 Score : {f1:.4f}\")\n",
    "    if not np.isnan(roc_auc):\n",
    "        print(f\"  ROC AUC  : {roc_auc:.4f}\")\n",
    "    else:\n",
    "        print(\"  ROC AUC  : Not available\")\n",
    "    print(f\"Completed Cross Validating {name}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Append results to list\n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'ROC AUC': roc_auc\n",
    "    })\n",
    "\n",
    "print(\"\\nAll Cross Validation Completed.\")\n",
    "\n",
    "# Store the results in a DataFrame and print\n",
    "results_df_tuned = pd.DataFrame(results).sort_values(by='Accuracy', ascending=False).reset_index(drop=True)\n",
    "print(\"\\nSummary of Hyperparameter Tuned Model Cross Validation Performance:\")\n",
    "results_df_tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_tuned.to_csv('results/t1d_hp_tuned_predictive_model_performance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the performance metrics\n",
    "# Melt the results_df so that each row represents a metric score for a given model\n",
    "results_df_top_tuned = results_df_tuned.nlargest(n=6, columns=['Accuracy'])\n",
    "results_melted_tuned = results_df_top_tuned.melt(id_vars='Model', var_name='Metric', value_name='Score')\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(data=results_melted_tuned, x='Model', y='Score', hue='Metric')\n",
    "plt.title(\"Performance Metrics for Various Models(After Tuning)\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.grid(True, axis='y', linestyle='--')\n",
    "plt.ylim([0, 1])\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig('results/t1d_tuned_predictive_model_performance.png')\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sqi_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
